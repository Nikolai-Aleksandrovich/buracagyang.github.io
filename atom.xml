<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Buracag的博客</title>
  <icon>https://www.gravatar.com/avatar/5d6a8fbb9f799ea7bec71b36b635ce18</icon>
  <subtitle>Beautiful is better than ugly.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://buracagyang.github.io/"/>
  <updated>2019-06-03T06:28:16.590Z</updated>
  <id>https://buracagyang.github.io/</id>
  
  <author>
    <name>Buracag</name>
    <email>15591875898@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分位数回归简介</title>
    <link href="https://buracagyang.github.io/2019/06/03/quantile-regression/"/>
    <id>https://buracagyang.github.io/2019/06/03/quantile-regression/</id>
    <published>2019-06-03T06:24:43.000Z</published>
    <updated>2019-06-03T06:28:16.590Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>最近在做一个比较有意思(难搞…)的项目。大致介绍一下相关背景：根据历史的一个工作情况(历史表现，也就是有多少人做了多少工作量)，以及未来的一个预估工作量(预测值)，我们需要预估一个<strong>合理的</strong>人员投入;一言概之，根据历史表现和预测件量预估人员投入。</p><a id="more"></a><p><strong>时序问题？</strong><br>咋一看，这不就是一个时序问题嘛！人力投入如下：<br>$$<br>Y_t = f(T_t, S_t, C_t, I_t)<br>$$<br>其中$T_t$代表长期趋势特征，$S_t$代表季节性或者季节变动，$C_t$代表周期性或循环波动，$I_t$代表随机性或不规则波动。接下来获取特征和历史人员投入，这不就可以预估得到了未来人力投入嘛。</p><p>但是，我们再仔细考虑一下。事情还不仅仅是如此简单。原因有两点：</p><ul><li>与常见的销量、件量等的预测不同，人力的投入不仅仅是一个时序数据，内生的跟工作量强相关；</li><li>预估人员投入的一个很重要的目标是，求得一个合理的人员投入(范围)。</li></ul><p><strong>常规机器学习问题？</strong><br>或者，再稍微拓展一下，由于人员投入是跟工作量是强相关的，我们可不可以用机器学习的思路来解决这个问题。也即：<br>$$<br>Y_t = f(workload, other_features)<br>$$<br>其实也是存在问题的，在上述的有监督学习中，对于每一个instance我们是需要有一个监督值的。对于该场景下，貌似每个instance都存在一个人力投入值；但是我们的目标是需要预估一个<strong>合理的</strong>人力投入，如果单纯地去拟合当前的人力投入，岂不是认为目前的投入即是最优的了，既然如此就没有做这个任务的必要了。</p><p><strong>经济学模型和其他尝试</strong><br>我们也曾尝试从经典的柯布-道格拉斯生产函数形式、<a href="https://doi.org/10.1080/03610926.2014.1001495" target="_blank" rel="noopener">部分随机人力规划系统</a>以及<a href="https://doi.org/10.1016/j.simpat.2015.07.004" target="_blank" rel="noopener">基于强化学习</a>等的的一些思路进行过分析过，均因效果不甚理想或者业务场景不相符而被pass掉。</p><p>最后，考虑到我们的主要目标是预估一个<strong>合理的</strong>人力投入，我们引入了衡量工作质量的一个变量。通过综合考虑质量和效能的关系，以保证预估出的人员数量，在保证工作量的情况或者说在降低人力投入量后工作质量不至于太差，反之亦然。最后，我们用了一个比较简单的方法来解决这个事情 – 分位数回归（Quantile Regression, QR）。</p><p>在介绍分为数回归的知识点之前，需要简要说一下推导过程不然显得太过突兀：<br>定义工作量为$W$,业务指标准时完成量为$W1$,员工数量为$P$，显然，<br>$$<br> \frac{W1}{W} = \frac{W1}{P}\frac{P}{W}<br>$$<br>这里的$\frac{W1}{W}$用来衡量质量情况，$\frac{P}{W}$的倒数$\frac{W}{P}$用来衡量效能情况。我们可以认为，在同一个类型下(工作场景、工作时间)，实际工作效能$\frac{W1}{P}$是一个相对客观的不变的值，令其为$k$。接下来我们便可以用分位数回归的方法求得系数也即$k$值，然后根据需要的质量情况，得到最终的效能范围，再结合预测件量情况，即可得到一个较为合理的人员投入范围。</p><p>首先，我们知道随机变量X的分布函数为：<br>$$<br>F(x) = P(X\leq x)<br>$$<br>则随机变量X的$\tau$分位数的定义为：<br>$$<br>Q_\tau(X) = arginf{x\in R ; F(x)\geq\tau}(0&lt;\tau&lt;1)<br>$$<br>若将分布函数F(x)的逆定义为：<br>$$<br>F_X^{-1}(\tau) = inf{y\in R ; F(y)\geq\tau}<br>$$</p><p>故：<br>$$<br>Q_\tau(X) = F_X^{-1}(\tau)<br>$$<br>和传统的线性回归估计方法不同的是，分位数回归估计的是一组自变量X与因变量Y的分位数之间线性关系的建模方法，偏向于条件分位数的变化。故OLS在数据出现尖峰(异常值)、长尾分布或者显著异方差等情况时，OLS结果不稳定,但是分位数的估计量确相对稳健。</p><p>设随机向量(X, Y),其中Y在X=x的情况下的条件累积分布函数为$F_{Y|X=x}$(y|x)，则其$\tau$条件分位数定义为：<br>$$<br>Q_\tau(Y|X=x) = arginf{y\in R ; F(y|x)\geq\tau}(0&lt;\tau&lt;1)<br>$$</p><p>这里直接附上对于OLS和分位数回归的相关对比：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">OLS</th><th style="text-align:center">分位数回归估计</th></tr></thead><tbody><tr><td style="text-align:center">原理</td><td style="text-align:center">以平均数为基准，求解最短距离</td><td style="text-align:center">以不同的分位数为基准，求解最短距离</td></tr><tr><td style="text-align:center">前提条件</td><td style="text-align:center">独立、正态、同方差</td><td style="text-align:center">独立</td></tr><tr><td style="text-align:center">假设要求</td><td style="text-align:center">强假设</td><td style="text-align:center">弱假设</td></tr><tr><td style="text-align:center">求解方法</td><td style="text-align:center">OLS</td><td style="text-align:center">加权最小一乘估计</td></tr><tr><td style="text-align:center">检验类型</td><td style="text-align:center">参数检验</td><td style="text-align:center">非参数检验</td></tr><tr><td style="text-align:center">异方差</td><td style="text-align:center">影响大</td><td style="text-align:center">影响小</td></tr><tr><td style="text-align:center">拟合曲线</td><td style="text-align:center">一条拟合曲线</td><td style="text-align:center">一簇拟合曲线</td></tr></tbody></table><p><strong>分位数回归参数估计的思想</strong></p><hr><p>与线性回归不同的是，QR估计量的特点在于，是通过样本到回归曲线的垂直距离的加权和求得；其中权重设置为，在拟合曲线之下的样本权重为$1 - \tau$，拟合曲线之上的样本权重为$\tau$， 即：<br>$$<br>L(\theta) = \min_{\xi\subset{R}}{\sum_{i:Y_i\ge\xi}\tau|Y_i - \xi| + \sum_{i:Y_i\le\xi}(1 - \tau)|Y_i - \xi|}<br>$$</p><p>上式可等价为：<br>$$<br>L(\theta) = \min_{\xi\subset{R}}\sum_{i=1}^n\rho_\tau(Y_i - \xi)<br>$$<br>其中，$\rho_\tau(u)=u(\tau-I(u&lt;0))$, $I(Z)$为示性函数。</p><p>QR的损失函数$L(\theta)$不是对称的，是由两条从原点出发的分别位于第一和第二象限的射线组成，显然其斜率比为$\tau:1-\tau$。</p><p>以上，仅是关于分位数回归知识的大概简介，最主要的部分是关于损失函数的设计。</p><p>最后，应用到该项目中时，我们对原始数据进行了离散化的处理，以及经过斯皮尔曼检验后的数据进行训练。由于其是一个计算密集型的任务，应用到全国众多网点时(数万),可以开多个线程池进行并行处理。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;最近在做一个比较有意思(难搞…)的项目。大致介绍一下相关背景：根据历史的一个工作情况(历史表现，也就是有多少人做了多少工作量)，以及未来的一个预估工作量(预测值)，我们需要预估一个&lt;strong&gt;合理的&lt;/strong&gt;人员投入;一言概之，根据历史表现和预测件量预估人员投入。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>Logistic loss函数</title>
    <link href="https://buracagyang.github.io/2019/05/29/logistic-loss-function/"/>
    <id>https://buracagyang.github.io/2019/05/29/logistic-loss-function/</id>
    <published>2019-05-29T09:16:09.000Z</published>
    <updated>2019-05-29T09:26:53.950Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>前面在浏览sklearn中关于<a href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression" title="Logistic Regression" target="_blank" rel="noopener">Logistic Regression</a>部分，看到关于带正则项的LR目标损失函数的定义形式的时候，对具体表达式有点困惑，后查阅资料，将思路整理如下。</p><a id="more"></a><h1 id="1-sklearn文档中的LR损失函数"><a href="#1-sklearn文档中的LR损失函数" class="headerlink" title="1. sklearn文档中的LR损失函数"></a>1. sklearn文档中的LR损失函数</h1><p>先看sklearn对于LR目标损失函数(带L2)的定义：<br>$$<br>\min_{w, c} \frac{1}{2}w^T w + C \sum_{i=1}^n \log(\exp(- y_i (X_i^T w + c)) + 1)<br>$$</p><p>看到这个表达形式，其实是有两个疑问：</p><ul><li><p>logistic loss的表达形式</p></li><li><p>正则项的惩罚系数</p></li></ul><p>对于第二个问题，其实比较容易解释。通常我们在最小化结构风险时，会给我们的惩罚项乘上一个惩罚系数λ(通常1 &lt; λ &lt; 0)，<br>$$<br>\min_{w, λ} \sum_{i=1}^nloss(y, y_i) + λw^T w<br>$$<br>一般，为方便处理，做一个技巧性地处理，对多项式乘上一个正数 1/2λ, 得到：<br>$$<br>\min_{w, λ} \frac{1}{2λ}\sum_{i=1}^nloss(y, y_i) + \frac{1}{2}w^T w<br>$$<br>令C = 1/2λ即可。</p><p>但是对于第一个形式，当时比较困惑；特意翻看了一下我以前记录的关于<a href="https://blog.csdn.net/buracag_mc/article/details/77620686" title="LR损失函数" target="_blank" rel="noopener">LR以及LR损失函数</a>的一些笔记。</p><h1 id="2-LR损失函数"><a href="#2-LR损失函数" class="headerlink" title="2. LR损失函数"></a>2. LR损失函数</h1><p>为了方便说明笔者当时的疑惑所在，便将当时脑海里存在的logistic loss函数形式 和 sklearn中LR损失函数的推导方法分别记为旧思路和新思路吧。</p><h2 id="2-1-logistic基础知识"><a href="#2-1-logistic基础知识" class="headerlink" title="2.1 logistic基础知识"></a>2.1 logistic基础知识</h2><p>如指数分布、高斯分布等分布一样，logistic是一种变量的分布，它也有自己的概率分布函数和概率密度函数，其中概率分布函数如下：<br>$$<br>F(x) = P(X \leq x) = \frac{1}{1+e^{-(x-\mu)/\gamma}}<br>$$</p><p>对概率分布函数求导，记得到对应的概率密度函数：<br>$$<br>f(x) = \frac{e^{-(x- \mu)/ \gamma}}{\gamma(1+e^{-(x-\mu)/\gamma})^2}<br>$$</p><p>其中，$\mu$就是分布对应的均值，$\gamma$是对应的形状参数。</p><p>下文，为简介方便起见，将$-(x-\mu)/\gamma$ 替换为 $-x$,故记为：<br>$$<br>F(x) = \frac{1}{1+exp(-x)}<br>$$</p><p>对应示例图如下：<br><img src="/2019/05/29/logistic-loss-function/20170827141819860.png" alt="这里写图片描述"></p><p>logistic有一个很重要的性质是：<br>$$<br>F(-x) = \frac{1}{1+exp(x)} = \frac{1}{1+\frac{1}{exp(-x)}} =<br>\frac{exp(-x)}{1+exp(-x)}=1-\frac{1}{1+exp(-x)}=1-F(x)<br>$$</p><p>通常，应用到LR中，有如下形式：</p><blockquote><p><strong>(1)</strong><br>$$<br>P(Y=1|\beta,x) = \frac{1}{1+exp(-\beta x)} = \frac{e^{\beta x}}{1+e^{\beta x}}<br>$$<br>$$<br>P(Y=0|\beta,x) = 1 - \frac{1}{1+exp(-\beta x)} = \frac{1}{1+e^{\beta x}}<br>$$</p></blockquote><blockquote><p>一个事件的几率(odds)，定义为该事件发生与不发生的概率比值，若事件发生概率为p：</p></blockquote><p>$$<br>odds = \frac{p}{1-p}<br>$$</p><p>那么该事件的对数几率（log odds或者logit）如下：<br>$$<br>logit(p)=log\frac{p}{1−p}<br>$$</p><p>那么，对于上述二项，Y=1的对数几率就是：<br>$$<br>log \frac{P(Y=1|\beta,x)}{1−P(Y=1|\beta,x)}=log \frac{P(Y=1|\beta,x)}{P(Y=0|\beta,x)}=\beta x<br>$$</p><p>也就是说，输出Y=1的对数几率是由输入x的线性函数表示的模型，这就是逻辑回归模型。易知，当 $\beta x$的值越大，$P(Y=1|\beta,x)$越接近1；$\beta x$越小,$P(Y=1|\beta,x)$ 越接近0。</p><p>其实，LR就是一个线性分类的模型。与线性回归不同的是：LR将线性方程输出的很大范围的数压缩到了[0,1]区间上；更优雅地说：<strong>LR就是一个被logistic方程归一化后的线性回归</strong>。</p><h2 id="2-2-旧思路"><a href="#2-2-旧思路" class="headerlink" title="2.2 旧思路"></a>2.2 旧思路</h2><p>旧思路要从LR的参数求解过程说起。</p><p>我们知道统计学中一种很常用的方法是根据最大化似然函数的值来估计总体参数。在机器学习领域，我们听到的更多是损失函数的概念，常通过构建损失函数，然后最小化损失函数估计目标参数。在这里，<strong>最大化对数似然函数与最小化对数似然损失函数其实是等价的</strong>，下面我们可以看到。</p><ul><li><p>假设我们有n个独立的训练样本${(x_1,y_1),(x_2,y_2),(x_3,y_3),…,(x_n,y_n)},y={0,1}$,那么每一个观察到的样本$(x_i,y_i)$出现的概率是：<br>$$<br>P(y_i,x_i) = P(y_i=1 | x_i)^{y_i}(1-P(y_i=1 | x_i))^{1-y_i}<br>$$<br>显然，$y_i$为1时，保留前半部分；$y_i$为0时，保留后半部分。</p></li><li><p>构建似然函数：<br>$$<br>L(\beta) = \prod P(y_i=1|x_i)^{y_i}(1-P(y_i=1|x_i))^{1-y_i}<br>$$</p></li><li><p>OK,对似然函数取对数，得到对数似然函数：</p></li></ul><p>$$LL(\beta) = log(L(\beta))= log(\prod P(y_i=1|x_i)^{y_i}(1-P(y_i=1|x_i))^{1-y_i}) $$</p><p> $= \sum_{i=1}^{n}(y_i log P(y_i=1|x_i) + (1-y_i)log(1-P(y_i=1|x_i)))$</p><p> $= \sum_{i=1}^{n}y_i log \frac{P(y_i=1|x_i)}{1-P(y_i=1|x_i)} + \sum_{i=1}^{n}log(1-P(y_i=1|x_i))$</p><p> $= \sum_{i=1}^{n}y_i(\beta x) + \sum_{i=1}^{n}logP(y_i=0|x_i)$</p><p> $= \sum_{i=1}^{n}y_i(\beta x) - \sum_{i=1}^{n}log(1+e^{\beta x})$</p><ul><li><p>用 $LL(\beta)$ 对 $\beta$ 求偏导，得：<br>$\frac{\partial LL(\beta)}{\partial \beta}<br>= \sum_{i=1}^{n}y_ix_i - \sum_{i=1}^{n} \frac{e^{\beta x_i}}{1+e^{\beta x_i}}.x_i$</p><p>$= \sum_{i=1}^{n}(y_i - P(y_i=1|x_i))x_i$<br>该式是无法解析求解，故会用到一些优化算法进行求解(梯度下降、牛顿法等)，这不是本文重点，便不再赘述。</p></li></ul><p>咋一看的确与sklearn中的形式差别有点大，所以请看新思路。</p><h2 id="2-3-新思路"><a href="#2-3-新思路" class="headerlink" title="2.3 新思路"></a>2.3 新思路</h2><p>在式(1)中， $x$表示特征向量，$\beta$表示相应的超参数，此时$y\in({0, 1})$表示样本对应的标签(label)。</p><p>这里，特别要讲的是另一种表达形式，将标签与预测函数在形式上统一了：</p><blockquote><p><strong>(2)</strong><br>$$<br>P(g=\pm1 |\beta, x) = \frac{1}{1+exp(-g\beta x)}<br>$$</p></blockquote><p>此时的样本标签$g\in({1, -1})$。</p><p>虽然式(1)与式(2)看起来似乎不同，但是我们可以有如下证明：<br>$$<br>P(Y=1|\beta,x) = \frac{e^{\beta x}}{1+e^{\beta x}} =  \frac{1}{1+exp(-\beta x)} = P(g=1 |\beta, x)<br>$$<br>同理，我们可以证明$P(Y=0|\beta,x)$ 和 $P(g=-1|\beta,x)$是等价的。</p><p>既然两种形式是等价的，为了适应更加广泛的分类loss最小化的框架，故采用第二种形式来表示LR.毕竟<strong>Simple is better than complex.</strong></p><p>首先定义$x_i$为特征向量，$y_i$为样本标签,则目标损失函数可以表示为：<br>$$<br>arg\min_{\beta}\sum_{i=1}L(y_i, f(x_i))<br>$$<br>其中，f是我们的回归方程，L是目标损失函数。</p><p>对应到LR中，我们有<br>$$<br>f(x) = \beta x<br>$$<br>$$<br>L(y, f(x)) = log(1 + exp(-yf(x)))<br>$$<br>如果将LR的第二种表达形式带入到损失函数L中，可得：<br>$$<br>L(y, f(x)) = log(1 + exp(-yf(x))) = log(\frac{1}{P(y|\beta,x)})<br>$$</p><p>再进一步：<br>$$<br>arg\min_{\beta}\sum_{i=1}L(y_i, f(x_i)) = arg\min_{\beta}\sum_{i=1}log(\frac{1}{P(y_i|\beta,x_i)})<br>$$<br>$$<br>= arg\max_{\beta}\sum_{i=1}log(P(y_i|\beta,x_i))= arg\max_{\beta}\prod_{i=1}P(y_i|\beta,x_i)<br>$$<br><strong>等式最后即为极大似然估计的表达形式。</strong></p><h1 id="3-思考"><a href="#3-思考" class="headerlink" title="3. 思考"></a>3. 思考</h1><p>其实到这儿，我们不难发现在旧思路中，推导极大化对数似然函数中的第二步：<br>$= \sum_{i=1}^{n}(y_i log P(y_i=1|x_i) + (1-y_i)log(1-P(y_i=1|x_i)))$</p><p>与新思路中的：<br>$$<br>=arg\max_{\beta}\sum_{i=1}log(P(y_i|\beta,x_i))<br>$$<br><strong>本质是统一的。</strong></p><p>最后</p><blockquote><p><strong>“Simple is better than complex.”   – The Zen of Python, by Tim Peters</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前面在浏览sklearn中关于&lt;a href=&quot;https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression&quot; title=&quot;Logistic Regression&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Logistic Regression&lt;/a&gt;部分，看到关于带正则项的LR目标损失函数的定义形式的时候，对具体表达式有点困惑，后查阅资料，将思路整理如下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
      <category term="机器学习" scheme="https://buracagyang.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
  </entry>
  
  <entry>
    <title>Python中定义类的相关知识</title>
    <link href="https://buracagyang.github.io/2019/05/29/python-basic-about-class/"/>
    <id>https://buracagyang.github.io/2019/05/29/python-basic-about-class/</id>
    <published>2019-05-29T09:12:54.000Z</published>
    <updated>2019-05-29T09:25:57.967Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>主要介绍了在python中，抽象类的定义、多态的概念、类中属性的封装以及类中常见的修饰器。</p><a id="more"></a><h1 id="1-抽象类"><a href="#1-抽象类" class="headerlink" title="1. 抽象类"></a>1. 抽象类</h1><p>与Java一样，Python也有抽象类的概念，抽象类是一个特殊的类。其特殊之处在于</p><ul><li>只能被继承，不能被实例化；</li><li>子类必须完全覆写(实现)其“抽象方法”和“抽象属性”后才能被实例化。</li></ul><p>可以有两种实现方式: 利用NotImplementedError实现和利用abctractmethod实现</p><h2 id="1-1-NotImplementedError"><a href="#1-1-NotImplementedError" class="headerlink" title="1.1 NotImplementedError"></a>1.1 NotImplementedError</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#########################################</span></span><br><span class="line"><span class="comment"># 利用NotImplementedError</span></span><br><span class="line"><span class="comment">#########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Payment</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildPay</span><span class="params">(Payment)</span>:</span></span><br><span class="line">    <span class="comment"># 必须实现pay方法,否则报错NotImplementedError</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"TestPay pay"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">payed</span><span class="params">(self, money)</span>:</span></span><br><span class="line">print(<span class="string">"Payed: &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">child_pay = ChildPay()</span><br><span class="line">child_pay.payed(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><h2 id="1-2-abctractmethod"><a href="#1-2-abctractmethod" class="headerlink" title="1.2 abctractmethod"></a>1.2 abctractmethod</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABCMeta, abstractmethod</span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># abstractmethod</span></span><br><span class="line"><span class="comment"># 子类必须全部重写父类的abstractmethod方法</span></span><br><span class="line"><span class="comment"># 非abstractmethod方法可以不实现重写</span></span><br><span class="line"><span class="comment"># 带abstractmethod方法的类不能实例化</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Payment</span><span class="params">(metaclass=ABCMeta)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span></span></span><br><span class="line">self.name = name</span><br><span class="line"></span><br><span class="line"><span class="meta">@abstractmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"Payment get &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">total</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"Payment total &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildPay</span><span class="params">(Payment)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"ChildPay pay &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"ChildPay get &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">child_pay = ChildPay(<span class="string">"safly"</span>)</span><br><span class="line">child_pay.pay(<span class="number">100</span>)</span><br><span class="line">child_pay.get(<span class="number">200</span>)</span><br><span class="line">child_pay.total(<span class="number">400</span>)</span><br><span class="line"><span class="comment"># 不能实例化</span></span><br><span class="line"><span class="comment"># TypeError: Can't instantiate abstract class Payment</span></span><br><span class="line"><span class="comment"># with abstract methods get, pay</span></span><br><span class="line"><span class="comment"># a = Payment("safly")</span></span><br></pre></td></tr></table></figure><h1 id="2-多态概念"><a href="#2-多态概念" class="headerlink" title="2. 多态概念"></a>2. 多态概念</h1><p>向不同的对象发送同一条消息(obj.func(): 是调用了obj的方法func, 又称向obj发送了一条消息func)，不同的对象在接受时会产生不同的行为（即不同的处理方法）。</p><p>也就是说，每个对象可以用自己的方式去响应共同的消息。所谓消息，就是调用函数，不同的对象可以执行不同的函数。</p><p>例： 男生.放松了()， 女生.放松了()，男生是打篮球，女生是看综艺，虽然二者消息一样，但是处理方法不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABCMeta, abstractmethod</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">(metaclass=ABCMeta)</span>:</span></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relax</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Boy</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relax</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"playing basketball"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Girl</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relax</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"watching TV"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">boy = Boy()</span><br><span class="line">girl = Girl()</span><br><span class="line">boy.talk()  <span class="comment"># playing basketball</span></span><br><span class="line">girl.talk()  <span class="comment"># watching TV</span></span><br></pre></td></tr></table></figure><h1 id="3-属性封装"><a href="#3-属性封装" class="headerlink" title="3. __属性封装"></a>3. __属性封装</h1><h2 id="3-1-私有静态属性、私有方法"><a href="#3-1-私有静态属性、私有方法" class="headerlink" title="3.1 私有静态属性、私有方法"></a>3.1 私有静态属性、私有方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># __属性封装</span></span><br><span class="line"><span class="comment"># 私有静态属性、私有方法</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 私有静态属性</span></span><br><span class="line">    __kind = <span class="string">"private kind"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用私有静态属性</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_kind</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> Dog.__kind</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 私有方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__func"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用私有方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.__func()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"><span class="comment"># 如下调用错误,因为需要在类内调用</span></span><br><span class="line"><span class="comment"># print(Dog.__kind)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提倡如下调用方式</span></span><br><span class="line">d = Dog()</span><br><span class="line">print(d.get_kind())</span><br><span class="line">print(d.func())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不提倡如下调用方式</span></span><br><span class="line"><span class="comment"># d._Dog__func()</span></span><br><span class="line"><span class="comment"># print(Dog.__dict__)</span></span><br><span class="line"><span class="comment"># print(Dog._Dog__kind)</span></span><br><span class="line"><span class="comment"># print(Dog._Dog__func)</span></span><br></pre></td></tr></table></figure><h2 id="3-2-私有对象属性"><a href="#3-2-私有对象属性" class="headerlink" title="3.2 私有对象属性"></a>3.2 私有对象属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># 私有对象属性</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, weight)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__weight</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">room = Dog(<span class="string">"doggy"</span>, <span class="number">5</span>)</span><br><span class="line">print(room.name)  <span class="comment"># doggy</span></span><br><span class="line">print(room.get_weight())  <span class="comment"># 5</span></span><br><span class="line"><span class="comment"># 不能如下方法调用私有对象属性</span></span><br><span class="line"><span class="comment"># print(room.__weight)</span></span><br></pre></td></tr></table></figure><h2 id="3-3-私有属性不被继承"><a href="#3-3-私有属性不被继承" class="headerlink" title="3.3 私有属性不被继承"></a>3.3 私有属性不被继承</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># 私有属性不能被继承</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogParent</span><span class="params">(object)</span>:</span></span><br><span class="line">__private = <span class="string">'PRIVATE'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.__name = name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__DogParent func"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogChild</span><span class="params">(DogParent)</span>:</span></span><br><span class="line">    <span class="comment"># 如下的方法是错误的</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_private</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> DogParent.__private</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">dog_parent = DogParent(<span class="string">"Tom"</span>)</span><br><span class="line">print(dir(dog_parent))</span><br><span class="line">print(<span class="string">"-------------"</span>)</span><br><span class="line">dog_child = DogChild(<span class="string">"Tommy"</span>)</span><br><span class="line">print(dir(dog_child))</span><br><span class="line"><span class="comment"># 调用报错AttributeError: type object 'DogChild' has no attribute '_DogChild__private'</span></span><br><span class="line"><span class="comment"># print(dog_child.get_private())</span></span><br></pre></td></tr></table></figure><h1 id="4-类中的常见修饰器"><a href="#4-类中的常见修饰器" class="headerlink" title="4. 类中的常见修饰器"></a>4. 类中的常见修饰器</h1><p>主要介绍最常见的装饰器，classmethod, staticmethod和property</p><h2 id="4-1-classmethod"><a href="#4-1-classmethod" class="headerlink" title="4.1 classmethod"></a>4.1 classmethod</h2><p>@classmethod<br>不需要self参数，但是classmethod方法的第一个参数是需要表示自身类的cls 参数；不管是从类本身调用还是从实例化后的对象调用，都用第一个参数把类传进来。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogParent</span><span class="params">(object)</span>:</span></span><br><span class="line">__private = <span class="string">'PRIVATE'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.__name = name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__DogParent func"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类方法</span></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(cls, new_name)</span>:</span></span><br><span class="line">cls.__name = new_name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls.__name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 普通方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_name2</span><span class="params">(self, new_name)</span>:</span></span><br><span class="line">        self.__name = new_name</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_name2</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">DogParent.change_name(DogParent, <span class="string">"Tom2"</span>)</span><br><span class="line">print(DogParent.get_name(DogParent))</span><br><span class="line"></span><br><span class="line">DogParent.change_name2(<span class="string">"Tom3"</span>)</span><br><span class="line">print(DogParent.get_name2())</span><br></pre></td></tr></table></figure></p><h2 id="4-2-staticmethod"><a href="#4-2-staticmethod" class="headerlink" title="4.2 staticmethod"></a>4.2 staticmethod</h2><p>staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用普通的函数一样;这样有一个好处：</p><ul><li>有利于我们代码的优雅，把某些应该属于某个类的函数给放到那个类里去，同时有利于命名空间的整洁</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogParent</span><span class="params">(object)</span>:</span></span><br><span class="line">__private = <span class="string">'PRIVATE'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.__name = name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__DogParent func"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类方法</span></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(cls, new_name)</span>:</span></span><br><span class="line">cls.__name = new_name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls.__name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 普通方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_name2</span><span class="params">(self, new_name)</span>:</span></span><br><span class="line">        self.__name = new_name</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_name2</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 静态方法</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_nickname</span><span class="params">(nickname)</span>:</span></span><br><span class="line">print(<span class="string">"nickname: &#123;&#125;"</span>.format(nickname))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">DogParent.set_nickname(<span class="string">"tom's nickname~"</span>)</span><br></pre></td></tr></table></figure><h2 id="4-3-property"><a href="#4-3-property" class="headerlink" title="4.3 property"></a>4.3 property</h2><p>@property 把一个方法伪装成一个属性,这个属性的值，是这个方法的返回值；这个方法不能有参数，类不能调用，只能对象调用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, height, weight)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.height = height</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bmi</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.weight / (self.height ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"method"</span>)</span><br></pre></td></tr></table></figure></p><p>其实，property的作用不仅于此。简单点讲，@property的本质其实就是实现了get，set，delete三种方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, nickname)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.nickname = nickname</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nickname</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="comment"># 相当于实现了get方法</span></span><br><span class="line">        print(<span class="string">"nickname: &#123;&#125;"</span>.self.nickname)</span><br><span class="line"></span><br><span class="line"><span class="meta">@property.setter</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nickname</span><span class="params">(self, new_nickname)</span>:</span></span><br><span class="line"><span class="comment"># 相当于实现了set方法</span></span><br><span class="line">self.nickname = new_nickname</span><br><span class="line">print(<span class="string">"new nickname: &#123;&#125;"</span>.format(new_nickname))</span><br><span class="line"></span><br><span class="line"><span class="meta">@property.deleter</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nickname</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="comment"># 相当于实现了delete方法</span></span><br><span class="line"><span class="keyword">del</span> Person.nickname</span><br><span class="line">print(<span class="string">"deleted nickname"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">person = Person(<span class="string">"Tom"</span>, <span class="string">'tommmy'</span>)</span><br><span class="line"><span class="comment"># get</span></span><br><span class="line">person.nickname()</span><br><span class="line"></span><br><span class="line"><span class="comment"># setter </span></span><br><span class="line">person.nickname = <span class="string">'new_tommmy'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># deleter</span></span><br><span class="line"><span class="keyword">del</span> person.nickname</span><br><span class="line"></span><br><span class="line"><span class="comment">#删除完毕后,再次调用报如下错误</span></span><br><span class="line"><span class="comment"># AttributeError: type object 'person' has no attribute 'nickname'</span></span><br><span class="line"><span class="comment"># person.nickname</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;主要介绍了在python中，抽象类的定义、多态的概念、类中属性的封装以及类中常见的修饰器。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="Python" scheme="https://buracagyang.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>单层感知器为什么不能解决异或(XOR)问题</title>
    <link href="https://buracagyang.github.io/2019/05/29/single-layer-perceptron/"/>
    <id>https://buracagyang.github.io/2019/05/29/single-layer-perceptron/</id>
    <published>2019-05-29T09:05:20.000Z</published>
    <updated>2019-05-29T09:18:04.966Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>单层感知器为什么不能解决异或问题(XOR)问题？给出两个思路去考虑这个小问题~</p><a id="more"></a><p>最近翻到了自己在印象笔记中学习记录的一些知识点，后续准备系统地整理放在自己的博客上，还请各位不吝指教。</p><h1 id="1-感知器模型"><a href="#1-感知器模型" class="headerlink" title="1. 感知器模型"></a>1. 感知器模型</h1><ul><li><p>感知器模型是美国学者罗森勃拉特（Frank Rosenblatt）为研究大脑的存储、学习和认知过程而提出的一类具有自学习能力的神经网络模型，它把神经网络的研究从纯理论探讨引向了从工程上的实现。</p></li><li><p>Rosenblatt提出的感知器模型是一个只有单层计算单元的前向神经网络，称为单层感知器。</p></li></ul><h1 id="2-单层感知器模型算法概述"><a href="#2-单层感知器模型算法概述" class="headerlink" title="2. 单层感知器模型算法概述"></a>2. 单层感知器模型算法概述</h1><p>在学习基础的NN知识的时候，单个神经元的结构必定是最先提出来的，单层感知器模型算法与神经元结构类似；</p><p>大概思想是：首先把<strong>连接权</strong>和<strong>阈值</strong>初始化为较小的非零随机数，然后把有n个连接权值的输入送入网络，经加权运算处理，得到的输出如果与所期望的输出有较大的差别(对比神经元模型中的激活函数)，就对连接权值参数进行自动调整，经过多次反复，直到所得到的输出与所期望的输出间的差别满足要求为止。</p><p>如下为简单起见，仅考虑只有一个输出的简单情况。设$x_i(t)$是时刻$t$感知器的输入（i=1,2,……,n），$ω_i(t)$是相应的连接权值，$y(t)$是实际的输出，$d(t)$是所期望的输出，且感知器的输出或者为1，或者为0。</p><h1 id="3-线性不可分问题"><a href="#3-线性不可分问题" class="headerlink" title="3. 线性不可分问题 "></a>3. 线性不可分问题 </h1><p>单层感知器不能表达的问题被称为线性不可分问题。 1969年，明斯基证明了“异或”问题是线性不可分问题。</p><h1 id="4-“与”、”或”、”非”问题的证明"><a href="#4-“与”、”或”、”非”问题的证明" class="headerlink" title="4. “与”、”或”、”非”问题的证明"></a>4. “与”、”或”、”非”问题的证明</h1><ul><li>由于单层感知器的输出为：</li></ul><p>$$ y(x1,x2) = f(ω1 <em> x1 + ω2 </em> x2 - θ) $$</p><p>所以，用感知器实现简单逻辑运算的情况如下：</p><ul><li><p>“与”运算（And, x1∧x2）<br>令 ω1 = ω2 = 1，θ = 1.5，则: y = f(1 <em> x1 + 1 </em> x2 - 1.5)<br>显然，当x1和x2均为1时，y的值1；而当x1和x2有一个为0时，y的值就为0.</p></li><li><p>“或”运算（Or, x1∨x2）<br>令ω1 = ω2=1, θ = 0.5，则: y=f(1 <em> x1 + 1 </em> x2 - 0.5)<br>显然，只要x1和x2中有一个为1，则y的值就为1；只有当x1和x2都为0时，y的值才为0。</p></li><li><p>“非”运算（Not, ～X1）<br>令ω1 = -1， ω2 = O， θ = -0.5，则:   y = f((-1) <em> x1 + 1 </em> x2 + 0.5)<br>显然，无论x2为何值，x1为1时，y的值都为0；x1为0时，y的值为1。即y总等于～x1。</p></li><li><p>“异或”运算（x1 XOR x2）</p></li></ul><h1 id="5-“异或”问题的证明"><a href="#5-“异或”问题的证明" class="headerlink" title="5. “异或”问题的证明"></a>5. “异或”问题的证明</h1><h2 id="5-1-单层感知机不能解决”异或”问题证明方法一"><a href="#5-1-单层感知机不能解决”异或”问题证明方法一" class="headerlink" title="5.1 单层感知机不能解决”异或”问题证明方法一"></a>5.1 单层感知机不能解决”异或”问题证明方法一</h2><p>如果“异或”（XOR）问题能用单层感知器解决，则由XOR的真值映射关系如下：</p><table><thead><tr><th style="text-align:center">(x1, x2)</th><th style="text-align:center">y</th></tr></thead><tbody><tr><td style="text-align:center">(0, 0)</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">(0, 1)</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">(1, 0)</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">(1, 1)</td><td style="text-align:center">0</td></tr></tbody></table><p>则ω1、 ω2 和θ 必须满足如下方程组：<br>1). ω1 + ω2 - θ ＜ 0    –&gt;   θ &gt; ω1 + ω2<br>2). ω1 + 0 - θ ≥ 0      –&gt;   0 ≥ θ - ω1<br>3). 0 + 0 - θ ＜ 0      –&gt;   θ &gt; 0<br>4). 0 + ω2 - θ ≥ 0      –&gt;   0 ≥ θ - ω2<br>显然，该方程组是矛盾的，无解！这就说明单层感知器是无法解决异或问题的。</p><h2 id="5-2-单层感知机不能解决”异或”问题证明方法二"><a href="#5-2-单层感知机不能解决”异或”问题证明方法二" class="headerlink" title="5.2 单层感知机不能解决”异或”问题证明方法二"></a>5.2 单层感知机不能解决”异或”问题证明方法二</h2><p>首先需要证明以下定理：</p><blockquote><p>样本集线性可分的充分必要条件是正实例点集所构成的凸壳与负实例点集所构成的凸壳互不相交    </p></blockquote><ul><li><p>必要性：假设样本集T线性可分，则存在一个超平面W将数据集正实例点和负实例点完全正确地划分到超平面两侧。显然两侧的点分别构成的凸壳互不相交；</p></li><li><p>充分性：假设存在两个凸壳A、B相交，且存在超平面W将A和B线性分割，令A在B的凸壳内部的点为a，因为线性可交，则A中不存在两点之间的连线与超平面W相交，而凸壳B中任意一点与A中的点的连线均与超平面W相交，则B内部的点a也与A中任一点之间的连线不与W相交，与B壳中任一点与A中的点的连线均与超平面W相交矛盾。</p></li></ul><p><strong>故：只有正负实例点所构成的两个凸壳不相交时样本集才线性可分。</strong></p><p>显然，对于此例，负实例样本集[(0, 0), (1, 1)] 和 正实例样本集[(0, 1), (1, 0)]是二维中是不能被线性分割的。<br><img src="/2019/05/29/single-layer-perceptron/1.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;单层感知器为什么不能解决异或问题(XOR)问题？给出两个思路去考虑这个小问题~&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
  </entry>
  
  <entry>
    <title>AIC和BIC相关知识</title>
    <link href="https://buracagyang.github.io/2019/05/29/aic-and-bic/"/>
    <id>https://buracagyang.github.io/2019/05/29/aic-and-bic/</id>
    <published>2019-05-29T07:14:58.000Z</published>
    <updated>2019-05-29T09:26:57.292Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>前面在回顾<a href="https://github.com/scikit-learn/scikit-learn" target="_blank" rel="noopener">sklearn</a>时，在广义线性模型中看到选择模型时可以采用AIC和BIC准则，特地复习了下统计学基础，简记如下，以抛砖引玉。</p><a id="more"></a><h2 id="1-模型拟合优度检验"><a href="#1-模型拟合优度检验" class="headerlink" title="1. 模型拟合优度检验"></a>1. 模型拟合优度检验</h2><p>最基础的一个模型拟合优度的检验量就是R square(方程的确定系数)。<br>已知一组样本观测值 $(X_i, Y_i)$,其中i=1,2,3,…,n得到如下样本回归方程：<br>$$<br>\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1}X_i<br>$$<br>而Y的第i个观测值与样本均值的离差 $y_i = Y_i - \bar{Y}$，其可以分解为两部分之和：<br>$$<br>y_i = Y_i - \bar{Y} = (Y_i - \hat{Y_i}) + (\hat{Y_i} - \bar{Y}) = e_i + \hat{y_i}<br>$$<br>其中 $\hat{y_i} = (\hat{Y_i} - \bar{Y})$是样本拟合值与观测值的平均值之差，可认为是由回归直线解释的部分，通常称之为”离差”；</p><p>$e_i = (Y_i - \hat{Y_i})$是实际观测值与回归拟合值之差，是回归直线不能解释的部分，通常称之为”残差”。</p><p>如果 $Y_i = \hat{Y_i}$,即实际观测值落在样本回归”线”上，则拟合最好。</p><p>对于所有样本点，<strong>可以证明</strong>：<br>$$<br>\sum{y_i}^2 = \sum{\hat{y_i}^2} + \sum{e_i^2} + 2\sum{\hat{y_i}^2e_i} = \sum{\hat{y_i}^2} + \sum{e_i^2}<br>$$<br>记:<br>$TSS = \sum{y_i^2} = \sum{(Y_i - \bar{Y})^2}$为总体平方和(Total Sum of Squares)<br>$ESS = \sum{\hat{y_i}^2} = \sum{(\hat{Y_i} - \bar{Y})^2}$为回归平方和(Explained Sum of Squares, <strong>注意有的教材又称之为Regression Sum of Squares</strong>)<br>$RSS = \sum{e_i^2} = \sum{(Y_i - \hat{Y_i})^2}$为残差平方和(Residual Sum of Squares, <strong>注意有的教材又称之为Error Sum of Squares</strong>)<br>$$<br>TSS = ESS + RSS<br>$$<br>所以Y的观测值围绕其均值的总离差(total variation)可分解为两部分：一部分来自回归线(ESS)，另一部分则来自与随机误差(RSS)</p><blockquote><p>在给定样本中，TSS不变，如果实际观测点离样本回归线越近，则ESS在TSS中占的比重越大，因此定义<strong>拟合优度：回归平方和ESS与TSS的比值。</strong></p></blockquote><p>记 $R^2 = \frac{ESS}{TSS} = 1 - \frac{RSS}{TSS}$，称 $R^2$为(样本)可决系数/判定系数</p><p>对于回归方程来说，$R^2$有以下几个意义：</p><ol><li>R square可以作为选择不同模型的标准。在拟合数据之前，不能确定数据的确定模型关系，可以对变量的不同数学形式进行拟合，再看R square的大小。</li><li>在数据的关系存在非线性可能情况下：<br>a) R squared越大不一定拟合越好；<br>b) 如何一个模型的R square很小，不一定代表数据之间没有关系，而很有可能是选择的模型不对，或者存在有其他的函数关系。</li><li><strong>当自变量个数增加时，尽管有的自变量与的线性关系不显著，其R square也会增大</strong>，对于这种情况需采用Adjusted R squared进行调整。</li></ol><h2 id="2-调整R-square"><a href="#2-调整R-square" class="headerlink" title="2. 调整R square"></a>2. 调整R square</h2><p>由于在模型中增加变量时，$R^2$没有下降，所以存在一种过度拟合模型的内在趋势，即向模型中增加变量固然可以改善数据拟合程度，但这样也会导致预测的方差正大，这时就需要用到调整 $R^2$。<br>$$<br>\bar{R_2} = 1 - \frac{n-1}{n-k}(1-R^2)<br>$$<br>调整$R^2$用作拟合优度的度量，它能够适当消除在模型中增加变量所导致的自由度损失。</p><p>调整 $R^2$对模型扩张时自由度的损失进行了弥补，但又存在一个问题，随着样本容量的增大，这种弥补是否足以保证该准则肯定能让分析者得到正确的模型，所以提出了另外两个拟合度量指标，一个是赤池信息准则(Akaike Information Criterion, AIC)，另一个是施瓦茨或贝叶斯信息准则(Bayesian Information Criterion,BIC)。</p><h2 id="3-AIC和BIC"><a href="#3-AIC和BIC" class="headerlink" title="3. AIC和BIC"></a>3. AIC和BIC</h2><p>$$<br>AIC(K) = s_y^2(1-R^2)e^{2k/n}<br>$$</p><p>$$<br>BIC(K) = s_y^2(1-R^2)n^{k/n}<br>$$</p><p>$s_y^2$中没有对自由度进行修正，虽然随着$R^2$的提高，这两个指标都有所改善(下降),但在其他条件不变的情况下，模型规模扩大又会使这两个指标恶化。与$\bar{R^2}$一样，实现同样的拟合程度，这些指标在平均每次观测使用参数个数(K/n)较少时更有效。使用对数通常更方便，多数统计软件报告度量指标是：<br>$$<br>AIC(K) = ln(\frac{e^{\prime}e}{n}) + \frac{2K}{n}<br>$$</p><p>$$<br>BIC(K) = ln(\frac{e^{\prime}e}{n}) + \frac{Kln{n}}{n}<br>$$</p><p><u><strong>更一般地：</strong></u><br>$$<br>AIC(K) = 2K - 2ln(L)<br>$$<br>其中k是模型参数个数，L为似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。</p><p>当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上市第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。</p><p>一般而言，当模型复杂度提高(k增大)时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。目标是选取AIC最小的模型，AIC不仅要提高模型拟合度(极大似然)，而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。<br>$$<br>BIC(K) = Kln{n} - 2ln(L)<br>$$<br>其中k是模型参数个数，n为样本数量，L为似然函数。与AIC类似地，引入了模型参数个数作为惩罚项，但是<strong>BIC的惩罚项比AIC的大</strong>，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高；其中 $kln{n}$惩罚项在维度过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前面在回顾&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sklearn&lt;/a&gt;时，在广义线性模型中看到选择模型时可以采用AIC和BIC准则，特地复习了下统计学基础，简记如下，以抛砖引玉。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>利用numpy.vectorize提升计算速度</title>
    <link href="https://buracagyang.github.io/2019/05/09/numpy-vectorize/"/>
    <id>https://buracagyang.github.io/2019/05/09/numpy-vectorize/</id>
    <published>2019-05-09T09:11:56.441Z</published>
    <updated>2019-05-29T09:26:50.637Z</updated>
    
    <content type="html"><![CDATA[<hr><p>同步于<a href="https://blog.csdn.net/buracag_mc/article/details/88748607" title="https://blog.csdn.net/buracag_mc/article/details/88748607" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/2019/03/18/increase-calculation-speed-with-numpy-vectorize/" target="_blank" rel="noopener">音尘杂记</a></p><p>在实际项目中，对超大矩阵进行计算或者对超大的DataFrame进行计算是一个经常会出现的场景。这里先不考虑开发机本身内存等客观硬件因素，仅从设计上讨论一下不同实现方式带来的性能差异，抛砖引玉。</p><a id="more"></a><p>项目中有这样一个需求，需要根据历史销量数据计算SKU(Stock Keeping Unit)之间的相似度，或者更通俗一点说是根据历史销量数据求不同SKU之间出现的订单交集以及并集大小(注:SKU数量大概15k左右，订单数大概1000k左右)。</p><p>这里给几条示例数据，可以更直观形象地理解这个需求：</p><p><img src="/2019/05/09/numpy-vectorize/1.png" alt="1"></p><p>然后需要根据这些历史的orderno-sku(订单-商品)数据求解出sku的相似度矩阵。其中SKU1和SKU2之间的相似度定义为:</p><p><img src="/2019/05/09/numpy-vectorize/2.png" alt="2"></p><p>可以很快速地想到几种解决方案：</p><ul><li><p>直接for loops；</p></li><li><p>for loops稍微改进采用列表生成器；</p></li><li><p>采用多进程并行计算；</p></li><li><p><strong>采用numpy.vectorize</strong></p></li></ul><h1 id="1-for-loops计算相似度矩阵"><a href="#1-for-loops计算相似度矩阵" class="headerlink" title="1.for loops计算相似度矩阵"></a>1.for loops计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_for_loops</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    for loops计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    <span class="keyword">del</span> order_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    l = len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    corr_matrix_arr = np.ones((l, l))</span><br><span class="line"></span><br><span class="line">    tbar = trange(l)</span><br><span class="line">    tbar.set_description(<span class="string">"compute corr matrix"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tbar:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, l):</span><br><span class="line">            corr_matrix_arr[j, i] = corr_matrix_arr[i, j] = len(df.iloc[i, <span class="number">1</span>] &amp; df.iloc[j, <span class="number">1</span>]) / len(</span><br><span class="line">                df.iloc[i, <span class="number">1</span>] | df.iloc[j, <span class="number">1</span>])</span><br><span class="line">    corr_matrix_df = pd.DataFrame(columns=sku_series, index=sku_series, data=corr_matrix_arr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> corr_matrix_df</span><br></pre></td></tr></table></figure><p>计算耗时：2000s+<br><img src="/2019/05/09/numpy-vectorize/3.png" alt="3"></p><h1 id="2-list-generator计算相似度矩阵"><a href="#2-list-generator计算相似度矩阵" class="headerlink" title="2.list generator计算相似度矩阵"></a>2.list generator计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_generator</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    列表生成器计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    <span class="keyword">del</span> order_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    l= len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    corr_matrix_arr = np.ones((l, l))</span><br><span class="line"></span><br><span class="line">    l1 = df.orderno</span><br><span class="line">    l2 = np.array(df[<span class="string">'orderno'</span>].apply(len), dtype=np.int8)</span><br><span class="line"></span><br><span class="line">    result_list = [[i, j, len(l1[i] &amp; l1[j])] <span class="keyword">for</span> i <span class="keyword">in</span> range(l)</span><br><span class="line">                   <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, l) <span class="keyword">if</span> len(l1[i] &amp; l1[j]) &gt; <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, j, k <span class="keyword">in</span> result_list:</span><br><span class="line">        corr_matrix_arr[j, i] = corr_matrix_arr[i, j] = k * <span class="number">1.0</span> / (l2[i] + l2[j] - k)</span><br><span class="line">    corr_matrix_df = pd.DataFrame(columns=sku_series, index=sku_series, data=corr_matrix_arr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> corr_matrix_df</span><br></pre></td></tr></table></figure><p>计算耗时：1296s<br><img src="/2019/05/09/numpy-vectorize/4.png" alt="4"></p><h1 id="3-多进程计算相似度矩阵"><a href="#3-多进程计算相似度矩阵" class="headerlink" title="3.多进程计算相似度矩阵"></a>3.多进程计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_multiprocessing</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    多进程计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    <span class="keyword">del</span> order_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    l = len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    </span><br><span class="line">    l1 = df.orderno</span><br><span class="line">    l2 = np.array(df[<span class="string">'orderno'</span>].apply(len), dtype=np.int8)</span><br><span class="line">    <span class="keyword">del</span> df</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    arr2 = np.zeros((l, l), dtype=np.float32)</span><br><span class="line">    pairs = [[i, j] <span class="keyword">for</span> i <span class="keyword">in</span> range(l - <span class="number">1</span>) <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, l)]</span><br><span class="line"></span><br><span class="line">    loops = int(math.ceil((l ** <span class="number">2</span> - l) / <span class="number">10</span> ** <span class="number">6</span> / <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    tbar = trange(loops)</span><br><span class="line">    tbar.set_description(<span class="string">"compute corr matrix"</span>)</span><br><span class="line">    pool = Pool(<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> loop <span class="keyword">in</span> tbar:</span><br><span class="line">        temp_lists = [[i, j, l1[i], l1[j]] <span class="keyword">for</span> i, j <span class="keyword">in</span> pairs[(<span class="number">10</span> ** <span class="number">6</span> * loop): (<span class="number">10</span> ** <span class="number">6</span> * (loop + <span class="number">1</span>))]]</span><br><span class="line">        temp_results = pool.map(cal, temp_lists)</span><br><span class="line">        <span class="keyword">for</span> i, j, k <span class="keyword">in</span> temp_results:</span><br><span class="line">            arr2[i, j] = k</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br><span class="line">    arr1 = l2 + l2.reshape((l, <span class="number">1</span>))</span><br><span class="line">    arr2 = arr2 + arr2.T  <span class="comment"># 变对称阵</span></span><br><span class="line">    arr3 = arr2 / (arr1 - arr2) + np.eye(l)</span><br><span class="line">    <span class="keyword">del</span> arr1</span><br><span class="line">    <span class="keyword">del</span> arr2</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    corr_matrix_df = pd.DataFrame(columns=sku_series, index=sku_series, data=arr3)</span><br><span class="line">    <span class="keyword">return</span> corr_matrix_df</span><br></pre></td></tr></table></figure><p>计算耗时：1563s<br><img src="/2019/05/09/numpy-vectorize/5.png" alt="5"></p><h1 id="4-numpy-vectorize计算相似度矩阵"><a href="#4-numpy-vectorize计算相似度矩阵" class="headerlink" title="4.numpy.vectorize计算相似度矩阵"></a>4.numpy.vectorize计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_vectorize</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    numpy.vectorice计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    l = len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    arr = df.orderno.values</span><br><span class="line">    corr_matrix_arr = np.zeros((l, l))</span><br><span class="line">    f_vec = np.vectorize(len)</span><br><span class="line">    arr1 = f_vec(arr)</span><br><span class="line"></span><br><span class="line">    tbar = trange(l - <span class="number">1</span>)</span><br><span class="line">    tbar.set_description(<span class="string">"compute corr matrix"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tbar(l - <span class="number">1</span>):</span><br><span class="line">        corr_matrix_arr[i, (i + <span class="number">1</span>): l] = f_vec(arr[(i + <span class="number">1</span>): l] &amp; arr[i])</span><br><span class="line">    corr_matrix_arr1 = np.add.outer(arr1, arr1)</span><br><span class="line">    temp = corr_matrix_arr / (corr_matrix_arr1 - corr_matrix_arr)</span><br><span class="line">    temp = temp + temp.T + np.eye(l)</span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(columns=sku_series, index=sku_series, data=temp)</span><br></pre></td></tr></table></figure><p>计算耗时：72s<br><img src="/2019/05/09/numpy-vectorize/6.png" alt="6"></p><p>可以看到，使用numpy.vectorize提升了20倍左右！</p><p><strong>思考：</strong><br>结合到实际业务中，其实有很多可以改进的地方：1. 并不需要计算所有SKU之间的相似度（提速）; 2. 可以只保存上三角阵或保存有效的相似SKU数据(降低内存)。这块儿就不展开赘述了。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc/article/details/88748607&quot; title=&quot;https://blog.csdn.net/buracag_mc/article/details/88748607&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/2019/03/18/increase-calculation-speed-with-numpy-vectorize/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在实际项目中，对超大矩阵进行计算或者对超大的DataFrame进行计算是一个经常会出现的场景。这里先不考虑开发机本身内存等客观硬件因素，仅从设计上讨论一下不同实现方式带来的性能差异，抛砖引玉。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="Python" scheme="https://buracagyang.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>SVM推导过程注解</title>
    <link href="https://buracagyang.github.io/2019/05/08/svm-proving-process/"/>
    <id>https://buracagyang.github.io/2019/05/08/svm-proving-process/</id>
    <published>2019-05-08T09:51:18.299Z</published>
    <updated>2019-06-03T07:20:43.718Z</updated>
    
    <content type="html"><![CDATA[<hr><p>同步于<a href="https://blog.csdn.net/buracag_mc/article/details/76762249" title="https://blog.csdn.net/buracag_mc/article/details/76762249" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/2019/03/18/svm-process/" target="_blank" rel="noopener">音尘杂记</a></p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>支持向量机(Support Vector Machine)的原理其实比较简单，它是基于结构风险最小化理论之上在特征空间中建构最优分割超平面。在二维中就是线，在三维中就是面，但我们统称为超平面。</p><a id="more"></a><p>就我所看到的相关书本、论文以及网上博文情况来看，其一般步骤通常如下：</p><ul><li>在二维平面中的线性可分情况开始讲解，求解硬间隔最优化</li><li>随后放宽条件，这时可以引入松弛向量，然后求解软间隔最优化</li><li>再后面拓展到线性不可分的情况，这时引入核函数方法（kernel trick），将低维数据映射到高维特征空间，在高维特征空间中，这些训练样本便是线性可分的了。</li></ul><p>SVM在数据挖掘与统计机器学习的书中是必讲的，网上优秀的教程也很多；故这里我只是将某些一笔带过或者模棱两可的推导步骤结合自己学习过程做一些补充，错误与不尽之处还望大家不吝指教！欢迎大家使劲儿拍砖耶！</p><h1 id="求解硬间隔最优化时的相关注解"><a href="#求解硬间隔最优化时的相关注解" class="headerlink" title="求解硬间隔最优化时的相关注解"></a>求解硬间隔最优化时的相关注解</h1><ul><li><p>首先我们回忆一下初中所学的知识,两条平行线的方程分别为：<br>$ax + by = c1$<br>$ax + by = c2$           (1)<br>两条平行线的距离d为：<br>$ d = \frac{|c_1-c_2|}{\sqrt(a^2+b^2)} $ (2)</p></li><li><p>范数(norm)相关知识：<br>p-范数 $||X||_p = (|x_1|^p + |x_2|^p+…+ |x_n|^p)^{1/p}$;也即:</p><ul><li><p>1-范数 =$|x_1| + |x_2|+…+ |x_n|$</p></li><li><p>2-范数 =$ (|x_1|^2 + |x_2|^2 + …+|x_n|^2)^{1/2}$</p></li><li><p>$\infty-范数 = MAX(|x_1|, |x_2|, …, |x_n|)$</p></li></ul></li></ul><p>跟博文<a href="http://blog.csdn.net/buracag_mc/article/details/75159437" title="http://blog.csdn.net/buracag_mc/article/details/75159437" target="_blank" rel="noopener">http://blog.csdn.net/buracag_mc/article/details/75159437</a>中所讲的闵可夫斯基距离是否有些似曾相识；的确是这样的，p-范数确实满足范数的定义。其中三角不等式的证明不是平凡的，这个结论通常称为闵可夫斯基不等式。</p><p>其中2-范数简单记为||X||,也就是我们通常意义上所说的欧式距离！</p><p>先描述一下，假设我们有N个训练样本${(x_1, y_1),(x_1, y_1), …, (x_n, y_n)}$，x是2维向量，而$y_i \in {+1, -1}$是训练样本的标签，分别代表两个不同的类。这里我们需要用这些样本去训练学习一个线性分类器：$f(x)=sgn(w^Tx + b)$，sgn函数就是一个符号函数，也就是说$w^Tx+ b$大于0的时候，输出f(x) = 1，小于0的时候，f(x) = -1。而$w^Tx + b=0$就是我们要寻找的分类超平面，如下图所示：<br><img src="http://img.blog.csdn.net/20170806110734659?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>我们需要这个超平面分隔这两类的效果最好，也就是说让这个超平面到这两个类的最近的那个样本的距离相同且最大。为了更好的说明，找到两个和这个超平面平行和距离相等的超平面，其实在平面几何中我们知道这就是平行线的移动，OK,如果各移动m个单位就达到要求，即：</p><p>$H_1: y = w^Tx + b=m$<br>$H_2: y = w^Tx + b=-m$</p><p>形式是不跟教材中的不一样？没关系，这里我们只是需要方程两边同时除以一个m即可：</p><p>$H_1: y = (\frac{w}{m})^Tx + \frac{b}{m}=1$<br>$H_2: y = (\frac{w}{m})^Tx + \frac{b}{m}=-1$(4)</p><p>这里为了统一起见，我们令w = w/m, b=b/m，注意与前面所说的$w^Tx + b=0$中的w和b是有区别的。(其实对于$w^Tx + b=0$,我们可以进行同样处理$H_1: y = (\frac{w}{m})^Tx + \frac{b}{m}=\frac{0}{m}$,再令w=w/m, b=b/m,即可完全统一了)</p><p>在H1左侧的函数值大于1，所有其分类为+1；在H2右侧的函数值小于1，所有其分类为-1，<br>可以统一记为记为$y_i(W^T.x_i + b) \geq 1$<br>这样便是我们熟悉的形式了！</p><hr><p>下面大家便可以猜想到了，求$H_1$和$H_2$之间的最大距离。当然如果是在二维平面中(当然，这里是以二维特征来说的，当然就是二维平面了)，易知便是两条平行线之间的距离，根据前面所所述平行线的距离即可求出，这里我们称之为margin。<br>即：margin = 2/||W||<br>这里对于二维特征$W^T = (w_1,w_2)$，||W||便是参数W的二范数(有的教科书又称之“模”)，将上式展开表示我们熟悉的平行线的距离了$margin = \frac{2}{\sqrt(w_1^2 + w_2^2)}$</p><p>但是，在统计机器学习中，我们要让它符合更多一般的情况，美其名曰便是“泛化能力”。将特征空间拓展到多维的情况，便是用向量来进行表示了，故在多维特征空间中，我们同样求margin= 2/||W||。</p><p>要使margin最大，即需W最小，故我们设我们的目标函数：<br>$min \frac{1}{2}||W||^2$<br>$s.t. yi(W^Tx_i + b) \geq 1, \forall x_i$                                              (5)</p><p>很多人会纠结W前面的系数1/2，这里加不加1/2其实没关系，这是为了求导时消去。其实在机器学习中， 我们常见的平方损失函数便是进行了同样的处理，在前面加了个常数系数1/2。</p><p>对于(5)式，准确的讲这是一个带有不等式约束的条件极值问题，根据高等数学和基础运筹学内容可以知道，我们可以用<strong>拉格朗日方法求解</strong>。</p><p>这里我必须要补充的一点是：通过查阅教科书以及在阅读网上的优秀教程，我发现不同教科书和网上不同的教程都有不同的说法，虽然实质是不变的，但当时我遇到的坑必须给大家给填了。</p><p>首先带不等式约束的条件极值问题中会有大于号约束、小于号约束两种(这里我们暂且先不说带等号，下文将KKT条件的时候一并补充)</p><ul><li><p>第一种说法如下：将所有不等式约束条件<strong>统一为小于号约束</strong>，然后拉格朗日方程的构建规则是用约束方程乘以非负的拉格朗日系数，然后再<strong>加上</strong>目标函数即可。</p></li><li><p>第二种说法如下：将所有不等式约束条件<strong>统一为大于号约束</strong>，然后拉格朗日方程的构建规则是用约束方程乘以非负的拉格朗日系数，然后再从目标函数中<strong>减去</strong>即可。</p></li></ul><p>其实我们可以发现这两种说法是等价的！事实确实如此，但是很多博文在讲解拉格朗日函数的构建时要么说用目标函数加上约束方程乘以非负的拉格朗日系数，要么说用目标函数减去约束方程乘以非负的拉格朗日系数。</p><p>可能某些文章作者完全没有申明大前提，他们准确的说法应该是，<strong><em>当统一成小于号约束时，拉格朗日函数的构建时是用目标函数加上约束方程乘以非负的拉格朗日系数；当统一成大于号约束时，拉格朗日函数的构建时是用目标函数减去约束方程乘以非负的拉格朗日系数。</em></strong>在不提前申明不同的大前提下，可能会误导不细心以及课程学的不仔细的读者(当时包括我=_=！)，导致某些人纳闷了，咦，这个拉格朗日咋一会儿是加上约束约束乘以拉格朗日系数，一会儿又是减去约束方程乘以拉格朗日系数啊？？？</p><p>为了统一与方便说明起见，故下文我们运用的第一种规则，将不等式约束条件统一成小于号约束。于是得到拉格朗日方程如下：<br>$L(w,b,a) = \frac{1}{2}||W||^2 + \sum_{i=1}^{n}a_i(1-y_i(wx_i+b)) = \frac{1}{2}||W||^2 - \sum_{i=1}^{n}a_i(y_i(wx_i+b)) + \sum_{i=1}^{n}a_i $<br>(6)</p><p>拉格朗日函数构建好后接下来便是简单的求解问题了，分别对W和b求偏导数并令其为零，得到如下结果：<br>$W = \sum_{i=1}^{n}a_iy_ix_i$                                    (7)<br>$\sum_{i=1}^{n}a_iy_i = 0$                                                 (8)    </p><p>带入(6)式即可得到:<br>$Max.W(a) =\sum_{i=1}^{n}a_i - \frac{1}{2}\sum_{i=1,j=1}^{n}a_ia_jy_iy_jx_i^Tx_j$<br>$s.t. a_i \geq 0, \sum_{i=1}^{n}a_iy_i = 0$(9)</p><p>为什么$min \frac{1}{2}||W||^2$问题变成了<br>$Max.W(a) =\sum_{i=1}^{n}a_i - \frac{1}{2}\sum_{i=1,j=1}^{n}a_ia_jy_iy_jx_i^Tx_j$<br>当然是对偶问题的求解了！对偶问题是怎么推导过来的？很多文章仅仅只是一笔带过了这么重要的推导内容。。。导致很多人有些小困惑哈~，为什么构建拉格朗日函数后就将求最小化问题变成求最大化问题？OK，既然本文的定位是SVM推导过程中的解析及注解，必定是要把这个问题完整给推导清楚的。</p><h2 id="SVM中对偶问题的注解"><a href="#SVM中对偶问题的注解" class="headerlink" title="SVM中对偶问题的注解"></a>SVM中对偶问题的注解</h2><p>再回看(6)式，<br>$L(w,b,a) = \frac{1}{2}||W||^2 + \sum_{i=1}^{n}a_i(1-y_i(W^Tx_i+b)) = \frac{1}{2}||W||^2 - \sum_{i=1}^{n}a_i(y_i(W^Tx_i+b)) + \sum_{i=1}^{n}a_i $<br>$s.t. a_i \geq 0$</p><p>我们要处理的最优化问题最正确的表达形式其实为：<br>        <img src="http://img.blog.csdn.net/20170806113012070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">            (10)<br>上式才是严格带有不等式约束条件下的拉格朗日条件极值的表达式。我读的很多介绍SVM的文章(包括我看的书本)都是没说的！(10)式便是一个凸规划问题。</p><p>其意义是先对a求偏导，令其等于0消掉a，然后再对W和b求L的最小值。</p><p>要直接求解(10)式是有难度的，幸好这个问题可以通过拉格朗日对偶问题来解决。常说对偶问题对偶问题，现在就是真正发挥这把利器的时候了。对(10)式做一个简单的等价变换：<br>                        <img src="http://img.blog.csdn.net/20170806113254715?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">(11)</p><p><strong>上式即为对偶变换</strong>，这样就把这个凸规划问题转换成了对偶问题</p><p>其意义是：原凸规划问题可以转化为先对W和b求偏导，令两个偏导数都等于0消掉W和b，然后再对a求L的最大值。与(10)的意义是相反的，或者说是对偶的！不知我讲到这步，大家是否对对偶问题有了一个豁然开朗的感觉——啊！原来对偶问题就是这啊！！</p><p>然后将求得的(7)式和(8)式带入(6)式，得：<br>                            <img src="http://img.blog.csdn.net/20170806113534514?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">        (12)<br>将(12)式带入(11)式得：<br>                <img src="http://img.blog.csdn.net/20170806113608420?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">            (13)<br>再考虑到(8)式，对偶问题的完整表达为：<br><img src="http://img.blog.csdn.net/20170806113656054?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">                            (14)</p><p>到了这一步，我们便可以直接用数值方法计算求解拉格朗日乘数a了。求得a过后根据(7)式可以得到W，然后根据超平面方程可以求出b。最终便得到了我们想要的超平面和分类决策函数，也就是我们训练好的SVM分类器。那么对于待分类样本X，其分类为为：<br>                                      <img src="http://img.blog.csdn.net/20170806113836750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">    (15)</p><p>我们根据(15)式可以发现，对于一个待分类样本，我们先计算待分类样本和训练样本的内积然后加权就和再加上b值即可。训练样本特别大的情况下，如果对所有训练样本做运算是否太耗时了啊？很多教科书以及网上教程都是直接说根据KKT条件可知，只有支持向量的乘子(拉格朗日乘数)$a_i$不等于0，其他训练样本的乘子都为0，这样便会大大减少运算量，也是后面SVM引入核函数(kernel)的铺垫。这又会引起新的疑惑，为什么只有支持向量对应的乘子不为0呢？</p><h2 id="SVM中KKT条件注解"><a href="#SVM中KKT条件注解" class="headerlink" title="SVM中KKT条件注解"></a>SVM中KKT条件注解</h2><p>这里还是继续讨论一下带等式和不等式约束的条件极值问题。任何极值问题的约束条件不外乎3种：等式、大于号和小于号，为了统一起见，我们将不等式约束统一为小于号。<br>例如：<br>$min(max)    f(x) $<br>$s.t.     g_i(x) \leq0,i=1,2…n_1$<br>$     h_j(x) = 0,j=1,2…n_2$</p><p>那么一个极值优化问题我们转化为：<br><img src="http://img.blog.csdn.net/20170806114231142?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li>KKT条件就是函数的最优值必须满足以下条件：<ul><li>L对各个x的偏导为零</li><li>h(x) = 0</li><li>$\sum_{i=1}^{n_1}a_ig_i(x) =0 , a_i\geq0$</li></ul></li></ul><p>假设一个目标函数，3个不等式约束条件把自变量约束在一定范围，而目标函数是在这个范围内寻找最优解。<br><img src="http://img.blog.csdn.net/20170806114343592?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><p>1.函数开始也不知道该取哪一个值是吧，假设某一次取得自变量集合为x1*，发现不满足约束，然后再换呀换；</p></li><li><p>2.假设到x2<em>满足约束条件，但是这个时候函数值不是最优的，并且x2</em>使得g1(x)与g2(x)等于0了，而g3(x)还是小于0。这个时候，我们发现在x2*的基础上再寻找一组更优解要靠谁呢？当然是要靠约束条件g1(x)与g2(x)，因为他们等于0了，很极限呀，一不小心，走错了就不满足这两个约束的条件了，这个时候我们会选择g1(x)与g2(x)的梯度方向往下走，以寻找最优值解。</p></li><li><p>3.这个时候需不需要管约束条件g3(x)呢？正常来说管不管都可以，如果管，也取g3在x2<em>处的梯度的话，由于g3已经满足小于0的条件，这时候再取在x2</em>处的梯度，有可能更快得到结果，也有可能适得其反；如果不管g3，由于g1和g2已经在边缘了，只取g1和g2的梯度，是肯定会让目标函数接近解的；故我们这时候是不用考虑g3的；</p></li><li><p>4.再往下走，到了x3*处发现g2和g3等于0了，也就是说走到边了，而g1是满足约束小于0的，这时候我们重复上一步，取g2和g3的梯度方向作为变化方向，而不用管g1.</p></li><li><p>5.一直循环3(4)步，直到找到最优解。</p></li></ul><p>可以看到的是，如果如果g1、g2=0时，由于他们本身的条件是小于0的，我们是需要优化他们的，操作上便是乘以一个正常数a作为他们梯度增长的倍数(或者说学习效率)，那些暂且不需要考虑的约束，例如这里说的g3，我们可以乘以系数0，即在下一次的优化中是不用考虑这些约束的。综上所述的话：<br>$\sum_{i=1}^{n_1}a_ig_i(x) = 0, a_i\geq0$</p><p>如上，简单直观地说便是KKT条件中第三个式子的意义了。</p><p>回到SVM的推导上来，对于(6)式，我们知道其KKT条件中的第三个式子为:<br>$\sum_{i=1}^{n_1}a_i(1-y_i(W^T.x_i+b)) = 0$，</p><p>我们知道除了支持向量，对于其他训练样本有：</p><ul><li><p>$y_i(W^T.x_i + b) &gt; 1$ 也即$1 - y_i(W^T.x_i + b) &lt;0$根据前面所述的内容知道，其对应的乘子为0。</p></li><li><p>对于支持向量来说：$y_i(W^T.x_i + b) =1$ 也即$1 - y_i(W^T.x_i + b) =0$，其对应的乘子不为0。</p></li></ul><p>也就是说，新来的待分类样本只需与支持向量求内积即可，这便大大减少了计算量！这便是KKT条件在SVM关键推导中的应用。</p><p>这里我再补偿一下另外一种思路，其实本质还是KKT条件：<br>由于(5)式与(10)式等价，即：<br><img src="http://img.blog.csdn.net/20170806114946494?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">        (16)</p><p>故要使(16)式成立，只有令$a_i(1-y_i(W^T.x_i+b)) = 0$成立，由此得到KKT的第三个条件：<br>$\sum_{i=1}^{n_1}a_i(1-y_i(W^T.x_i+b)) = 0$<br>同样可出结论：支持向量对应的乘子为正系数；如果一个样本不是支持向量，则其对应的乘子为0。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc/article/details/76762249&quot; title=&quot;https://blog.csdn.net/buracag_mc/article/details/76762249&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/2019/03/18/svm-process/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;支持向量机(Support Vector Machine)的原理其实比较简单，它是基于结构风险最小化理论之上在特征空间中建构最优分割超平面。在二维中就是线，在三维中就是面，但我们统称为超平面。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
  </entry>
  
</feed>
