<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Buracag的博客</title>
  <icon>https://www.gravatar.com/avatar/5d6a8fbb9f799ea7bec71b36b635ce18</icon>
  <subtitle>Beautiful is better than ugly.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://buracagyang.github.io/"/>
  <updated>2020-01-05T04:03:37.825Z</updated>
  <id>https://buracagyang.github.io/</id>
  
  <author>
    <name>Buracag</name>
    <email>15591875898@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【Graph Embedding】node2vec</title>
    <link href="https://buracagyang.github.io/2020/01/05/graph-embedding-node2vec/"/>
    <id>https://buracagyang.github.io/2020/01/05/graph-embedding-node2vec/</id>
    <published>2020-01-05T11:36:25.000Z</published>
    <updated>2020-01-05T04:03:37.825Z</updated>
    
    <content type="html"><![CDATA[<p>关于Graph Embedding系列的论文翻译解读文章：</p><p><a href="https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/">【Graph Embedding】DeepWalk</a></p><p><a href="https://buracagyang.github.io/2019/12/21/graph-embedding-line/">【Graph Embedding】line</a></p><p><a href="https://buracagyang.github.io/2019/12/26/graph-embedding-node2vec/">【Graph Embedding】node2Vec</a></p><p>…</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>paper: <a href="https://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf" target="_blank" rel="noopener">https://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf</a></p><p>code: <a href="https://github.com/aditya-grover/node2vec" target="_blank" rel="noopener">https://github.com/aditya-grover/node2vec</a></p><a id="more"></a><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>网络中节点和边上的预测任务的特征工程比较麻烦。最近在更广泛的表征学习领域的研究已经导致了通过学习特征本身来自动预测的重大进展。然而，目前的特征学习方法不足以表达网络中观察到的连接模式的多样性。</p><p>在此，我们提出node2vec，这是一个学习网络中节点的连续特征表示的算法框架。在node2vec中，我们学习了如何将节点映射到低维特征空间，从而最大限度地保留节点的邻域信息。我们定义了一个灵活的节点网络邻居概念，并设计了一个有偏差的随机游走程序，有效地探索了不同的邻居。我们的算法推广了以前的工作，这些工作基于严格的网络邻域概念，我们认为增加了探索邻域的灵活性。</p><p>我们证明了node2vec在多个不同领域的真实网络中，在多标签分类和链路预测方面优于现有的先进技术。综上所述，我们的工作代表了一种在复杂网络中有效学习独立于任务的状态的新方法。</p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>网络分析中的许多重要任务都涉及对节点和边缘的预测。例如，</p><ul><li>在社交网络中，我们可能对预测用户的兴趣感兴趣，或者在蛋白-蛋白交互网络中，我们可能对预测蛋白质的功能标签感兴趣[25,37]。</li><li>同样，在链路预测中，我们希望预测网络中的一对节点是否应该有一条连接它们的边[18]。链路预测在很多领域都很有用;在基因组学中，它帮助我们发现基因之间的新相互作用，在社会网络中，它可以识别现实世界中二人是否是朋友[2,34]。</li></ul><p>任何监督机器学习算法都需要一组信息丰富的、有区别的和独立的特征。在网络预测问题中，这意味着必须为节点和边构造一个特征向量表示。典型的解决方案包括基于domain knowledge和手动的特征工程。即使不考虑特征工程所需的繁琐工作，这些特征通常是针对特定任务设计的，不会泛化到不同的预测任务中。</p><p>另一种方法是通过解决优化问题[4]来学习特征表示。特征学习的挑战是定义一个目标函数，它涉及计算效率和预测精度之间的平衡。虽然这种监督过程有较高的准确性，但其代价是由于需要估计的参数数量激增，导致训练时间复杂性很高。</p><p>然而，目前的技术并不能令人满意地定义和优化网络中可伸缩的无监督特征学习所需的合理目标。经典方法基于线性和非线性降维技术，如主成分分析、多维扩展[3, 27, 30, 35]使数据表示的方差最大化。因此，这些方法总是涉及到适当的数据矩阵的特征分解，这对于大型的真实网络是昂贵的。此外，由此产生的潜在表示在网络上的各种预测任务中表现较差。</p><p>或者，我们可以设计一个目标来保护节点的局部邻域。利用类似于单隐层前馈神经网络反向传播的随机梯度下降法可以有效地优化目标。最近在这方面的尝试[24,28]提出了有效的算法，但依赖于网络邻域的严格概念，这导致这些方法在很大程度上对网络特有的连接模式不敏感。特别是网络中的节点可以根据他们所属的社区来组织（同质性)。例如，在图1中，我们观察到节点$u$和$s_1$属于同一个紧密结合的节点社区，而两个不同的社区中的节点$u$和$s_6$共享一个hub节点的相同结构角色。现实世界的网络通常表现出这种等价的混合。因此,它是必要的,以便灵活的算法,可以学习节点表示遵守两个原则: 能够紧密地学习来自同一网络社区的嵌入节点的表示,以及学习共享相似角色的节点具有相似的embeddings。这将允许特征学习算法泛化各种领域和预测任务</p><p><strong>现在的工作</strong>。提出了一种用于网络中可伸缩特征学习的半监督算法node2vec。在自然语言处理[21]的基础上，我们使用SGD优化了一个自定义的基于图的目标函数。直观地说，我们的方法返回的特征表示能够最大限度地在d维特征空间中保留节点的网络邻域。我们使用二阶随机游走的方法来生成(样本)节点的网络邻域。</p><p>我们的主要贡献在于定义了一个灵活的节点网络邻居概念。通过选择适当的邻域概念，node2vec可以学习基于节点的网络角色和/或它们所属的社区组织节点的表示形式。我们通过开发一组有偏随机游走来实现这一点，它有效地探索了给定节点的不同邻域。得到的算法是灵活的，通过可调参数控制搜索空间，这与之前工作中严格的搜索过程形成对比[24,28]。因此，我们的方法可以推广先前的工作，并且可以对网络中观察到的全谱等价进行建模。控制我们的搜索策略的参数有一个直观的解释，并倾向于不同的网络探索策略。这些参数也可以通过使用一小部分标记数据以半监督的方式直接学习。</p><p>我们还展示了如何将单个节点的特性表示扩展到成对的节点(即,边)。为了生成边的特征表示，我们使用简单的二元操作符来组合单个节点的学习特征表示。这种组合性使node2vec可以用于涉及节点和边的预测任务</p><p>我们的实验集中在两个网络中常见的预测任务上:一个是多标签分类任务，其中每个节点被分配一个或多个类标签;另一个是链路预测任务，其中我们预测给定一对节点的边的存在。我们将node2vec的性能与最先进的特征学习算法进行了对比[24,28]。我们实验了几个来自不同领域的真实世界的网络，如社交网络、信息网络，以及系统生物学的网络。实验表明，node2vec在多标签分类和链路预测方面的性能比最先进的方法分别高出26.7%和12.6%。即使是10%的标记数据，该算法也表现出了很好的竞争性能，并且对噪声或缺失边缘形式的扰动具有很强的鲁棒性。在计算上，node2vec的主要阶段是可并行的，它可以在几个小时内扩展到具有数百万节点的大型网络。</p><p>我们的论文做出了以下贡献:</p><ol><li>我们提出node2vec，这是一种高效的可扩展的网络特征学习算法，它利用SGD有效地优化了一个新的网络感知、邻域保持的目标。</li><li>我们展示了node2vec如何符合网络科学中已建立的原则，为发现符合不同等价的表示提供了灵活性。</li><li>我们扩展了node2vec和其他基于邻域保留目标的特征学习方法，从节点扩展到基于边的预测任务。</li><li>我们对node2vec在多个真实数据集上的多标签分类和链路预测进行了经验评估。</li></ol><h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h1><p>特征工程已经被机器学习社区在不同的标题下进行了广泛的研究。在网络中，为节点生成特征的传统范式是基于特征提取技术的，该技术通常涉及一些基于网络属性的人工设计的种子特征[8,11]。相反，我们的目标是通过将特征提取转换为表示学习问题来自动化整个过程，在这种情况下，我们不需要任何人工设计的特征。</p><p>无监督特征学习方法通常利用图的各种矩阵表示的谱特性，特别是<strong>拉普拉斯矩阵</strong>和<strong>邻接矩阵</strong>。从线性代数的角度来看，这些方法可以看作是降维技术。一些线性的(如主成分分析)和非线性的(例如，IsoMap)降维技术已经被提出[3, 27, 30, 35]。这些方法在计算和统计性能上都存在缺陷。在计算效率方面，矩阵的特征分解是昂贵的，除非解决方案的质量在很大程度上受到近似的影响，因此，这些方法很难扩展到大型网络。其次，这些方法针对网络中观察到的不同模式(如同质性和结构等价性)不具有鲁棒性的目标进行优化，并对底层网络结构与预测任务之间的关系进行假设。例如，光谱聚类做了一个强有力的同质性假设，即图割将有助于分类[29]。这样的假设在许多情况下都是合理的，但在有效地将其推广到不同的网络上时却不能令人满意。</p><p>自然语言处理的表征性学习的最新进展为离散对象(如单词)的特征学习开辟了新途径。特别是，跳跃图模型[21]旨在通过优化邻域保留似然目标来学习单词的连续特征表示。算法如下：它扫描文档中的单词，并将每个单词嵌入文档中，这样单词的特征就可以预测附近的单词(例如:，一些上下文窗口中的单词)。特征表示是通过负抽样[22]的SGD似然目标来学习的。跳跃图的目标是基于分布假设，即在相似的上下文中，单词往往具有相似的含义。也就是说，相似的单词往往出现在相似的词域中。</p><p>受跳跃图模型的启发，最近的研究通过将网络表示为“文档”，为网络建立了一个类比(24、28)。就像文档是一个有序的单词序列一样，我们可以从底层网络中采样节点序列，并将网络转换为有序的节点序列。然而，有许多可能的节点抽样策略，导致不同的学习特征表示。事实上，正如我们将要展示的，没有一个清晰的抽样策略可以适用于所有的网络和所有的预测任务。这是以前工作的一个主要缺点，不能提供任何灵活的抽样节点从网络[24,28]。我们的算法<code>node2vec</code>克服了这一限制，它设计了一个灵活的目标，不依赖于特定的采样策略，并提供参数来调整搜索空间(参见第3节)。</p><p>最后，对于基于节点和边缘的预测任务，有大量基于现有的和新的特定于图的深度网络架构的监督特征学习的最新工作[15,16,17,31,39]。这些体系结构使用多层非线性转换直接最小化下游预测任务的损失函数，从而获得较高的准确性，但由于需要较高的训练时间，因此以可扩展为损失。</p><h1 id="3-特征学习框架"><a href="#3-特征学习框架" class="headerlink" title="3. 特征学习框架"></a>3. 特征学习框架</h1><p>我们将网络中的特征学习描述为一个极大似然优化问题。设$G = (V, E)$是一个给定的网络。我们的分析是一般性的，适用于任何(非)定向的(非)加权网络。设$f: V \to \Bbb{R}^d$是从节点到特征表征物的映射函数，我们的目标是学习下游预测任务。这里$d$是一个参数，指定特征表示的维数。同样，$f$是一个参数大小为$|V| \times d$的矩阵。对于每个节点$u \in V$， 我们定义$N_{S}(u)  \subset V$ 作为通过邻域采样策略$S$生成节点$u$的网络邻域</p><p>我们将Skip-gram结构扩展到网络[21,24]。我们试图优化以下目标函数，使观察网络邻域的似然概率最大化:<br>$$<br>\max_{f} \, \, \, \, \, \, \, \sum_{u \in V}logPr(N_S(u) | f(u)). \tag{1}<br>$$<br>为了使优化问题易于处理，我们做了两个标准假设:</p><ul><li><p>有条件的独立。我们通过假设观察邻域节点的可能性独立于观察任何其他邻域节点的可能性来因式分解可能性，给定源数据的特征表示:<br>$$<br>Pr(N_S(u) | f(u)) = \prod_{n_i \in N_S(u)}Pr(n_i|f(u)).<br>$$</p></li><li><p>特征空间的对称性。在特征空间中，源节点与邻节点之间存在对称效应。因此，我们将每个源邻节点对的条件似然建模为一个softmax单元，并由它们的特征点积进行参数化:<br>$$<br>Pr(n_i|f(u)) =  \frac{exp(f(n_i).f(u))} {\sum_{v \in V}exp(f(v).f(u))}.<br>$$</p></li></ul><p>根据上述假设，式(1)中的目标简化为:<br>$$<br>\max_{f} \, \, \, \, \, \, \, \sum_{u \in V}[-log Z_u + \sum_{n_i \in N_{S}(u)}f(n_i).f(u)]. \tag{2}<br>$$<br>每个节点的分配函数，$Z_u = \sum_{v \in V}exp(f(u).f(v))$，对于大型网络计算是很昂贵的，我们使用负采样[22]来近似它。我们使用定义特征的模型参数$f$上的随机梯度上升来优化等式（2）。</p><p>基于Skip-gram结构的特征学习方法最初是在自然语言[21]环境下发展起来的。考虑到文本的线性特性，邻域的概念可以通过在连续的单词上使用滑动窗口来自然地定义。然而，网络不是线性的，因此需要一个更丰富的邻域概念。为了解决这个问题，我们提出了一个随机过程，对给定源节点$u$的许多不同的邻域进行采样。邻域$N_S(u)$不仅限于相邻的邻域，而且根据采样策略$S$可以有非常不同的结构。</p><h2 id="3-1-经典搜索策略"><a href="#3-1-经典搜索策略" class="headerlink" title="3.1 经典搜索策略"></a>3.1 经典搜索策略</h2><p><img src="/2020/01/05/graph-embedding-node2vec/figure1.png" alt="这里写图片描述"></p><p>我们将源节点的邻域采样问题视为一种局部搜索形式。图1显示了一个图，给定一个源节点$u$，我们的目标是生成(样本)它的邻域$N_S (u)$。重要的是，为了能够公平地比较不同的采样策略$S$，我们将邻域集$N_S$的大小限制为$k$个节点，然后对单个节点$u$进行多个集的采样。一般来说，生成$k$个节点的邻域集$N_S$有两种极端的采样策略:</p><ul><li><strong>宽度优先抽样(BFS)</strong> 邻居的$N_S$被限制在与源相邻的节点上。例如，在图1中，对于大小为$k = 3$的邻域，BFS示例节点$s1、s2、s3$。</li><li><strong>广度优先抽样(DFS)</strong> DFS对$s4、s5、s6$进行了采样。</li></ul><p>广度优先和深度优先的抽样代表了他们所探索的搜索空间的极端情况，这对学习表征产生了有趣的影响。特别是，网络节点上的预测任务往往在两类相似性之间穿梭:同质性和结构等价性[12]。根据<strong>同质性假设</strong>[7,36]，高度互联且属于相似网络集群或社区的节点应紧密嵌入在一起(如图1中的节点$s_1$和$u$属于同一网络社区)。相反，在<strong>结构等价</strong>假设下，在网络中具有相似结构角色的[10]节点应该紧密嵌入在一起(如图1中的节点$u$和$s_6$作为其对应社区的枢纽)。重要的是，与同质性不同，结构等价并不强调连接性;节点可能在网络中相隔很远，但仍然具有相同的结构角色。在现实世界中，这些等价概念并不是排他的;网络通常表现出这两种行为，一些节点表现出同质性，而另一些则表现出结构等价性。</p><p>我们观察到，BFS和DFS策略在生成反映上述任一等价的表示方面起着关键作用。特别是，BFS采样的邻域导致了与结构等价性紧密对应的嵌入。直观地说，我们注意到，为了确定结构上的等价性，通常只需要准确地描述局部邻域就足够了。例如，基于网络角色(如桥接器和集线器)的结构等价性可以通过观察每个节点的直接邻域来推断。通过限制搜索到附近的节点，BFS实现了这种特性，并获得了每个节点邻居的微观视图。此外，在BFS中，采样的邻近节点往往重复许多次。这一点也很重要，因为它减少了描述1跳节点相对于源节点分布的方差。然而，对于任意给定的$k$，图中只有很小一部分被探索。</p><p>相反，DFS可以探索更大的网络部分，因为它可以远离源节点u(样本容量$k$固定)。在DFS中，采样的节点更准确地反映了邻居的宏观视图，这在基于同质性的社区推断中是必不可少的。然而，DFS的问题是，不仅要推断网络中存在哪些节点到节点的依赖关系，而且还要确定这些依赖关系的确切性质。这是困难的，因为我们有一个约束的样本大小和一个大的邻居去探索，导致高方差。其次，移动到更大的深度会导致复杂的依赖关系，因为采样的节点可能离源很远，而且可能不太具有代表性。</p><h2 id="3-2-node2vec"><a href="#3-2-node2vec" class="headerlink" title="3.2 node2vec"></a>3.2 node2vec</h2><p>在此基础上，我们设计了一个灵活的邻域采样策略，使我们能够在BFS和DFS之间进行平滑插值。我们通过开发一种灵活的有偏随机游走程序来实现这一点，该程序可以同时探索a中的邻域 BFS和DFS。</p><h3 id="3-2-1-随机游走"><a href="#3-2-1-随机游走" class="headerlink" title="3.2.1 随机游走"></a>3.2.1 随机游走</h3><p>在形式上，给定一个源节点$u$，我们模拟一个固定长度$l$的随机游走，让$c_i$表示游动中的第$i$个节点，从$c_0 = u$开始，节点$c_i$由以下分布产生:<br>$$<br>P(c_i = x | c_{i-1} = v) =<br>    \begin{cases}<br>    \frac{\pi v x}{Z} &amp; if (v, x) \in E \\<br>    0 &amp; otherwise<br>    \end{cases}<br>$$<br>其中$\pi v x$为节点$v$与$x$之间的未归一化转移概率，$Z$为归一化常数。</p><h3 id="3-2-2-搜索偏差-alpha"><a href="#3-2-2-搜索偏差-alpha" class="headerlink" title="3.2.2 搜索偏差$\alpha$"></a>3.2.2 搜索偏差$\alpha$</h3><p><img src="/2020/01/05/graph-embedding-node2vec/figure2.png" alt="这里写图片描述"></p><p>使随机游走产生偏差的最简单的方法是根据静态边权值$w_{vx}$对下一个节点进行抽样。例如，$\pi_{vx} = w_{vx}$。(对于未加权图$w_{vx} = 1$)。然而，这并不允许我们考虑网络结构，并指导我们的搜索过程探索不同类型的网络邻居。另外，与BFS和DFS不同的是，BFS和DFS是分别适用于结构等价性和同质性的极端抽样范式，我们的随机游走应该适应这样的事实，即这些等价的概念不是竞争的或排他的，而现实世界的网络通常是两者的混合。</p><p>我们定义了一个二阶随机游走，它有两个参数$p$和$q$来引导这个游动:考虑一个只穿过边$(t, v)$，现在驻留在节点$v$上(图2)。现在，需要决定下一步走哪个节点，所以计算了从$v$出发在边$(v, x)$上的转移概率$\pi_{vx}$。我们将未归一化的转移概率设为$\pi_{vx} = \alpha_{pq}(t, x).w_{vx}$，其中<br>$$<br>\alpha_{pq}(t, x) =<br>    \begin {cases}<br>    \frac{1}{p} &amp; if \,\,d_{tx} = 0 \\<br>    1 &amp; if \,\,d_{tx} = 1 \\<br>    \frac{1}{q} &amp; if \,\,d_{tx} = 2 \\<br>    \end {cases}<br>$$<br>$d_{tx}$表示节点$t$与$x$之间的最短路径距离。注意，$d_{tx}$必须是{0, 1, 2}中的一个。因此，这两个参数对于引导行走是必要且充分的。</p><p>直观地看，参数$p$和$q$控制行走探索和离开起始节点$u$附近的速度。特别是，参数允许我们的搜索过程(近似地)在BFS和DFS之间插入。</p><p><strong>返回参数</strong>，p。参数p控制了在遍历中重新访问一个节点的可能性。将它设置为一个高值(&gt; max(q, 1)确保我们不太可能在以下两个步骤中采样一个已经访问过的节点(除非遍历中的下一个节点没有其他邻居)。这种策略鼓励适度的探索，避免了采样中的两跳冗余。另一方面，如果p低(&lt; min(q，1))，它将导致walk回溯一个步骤(图2)，这将使walk接近起始节点u。</p><p><strong>向内向外参数</strong>，q。参数q允许搜索区分“向内”和“向外”节点。回到图2，如果 q &gt; 1，则随机游走偏向于靠近节点t的节点。这样的遍历获得了底层图相对于遍历中的起始节点的局部视图，以及近似的BFS行为，因为我们的样本包含了一个小区域内的节点。</p><p>而当q &lt; 1时，walk更倾向于访问距离$t$较远的节点。这种行为反映了DFS鼓励向更外处探索。然而，这里的一个本质区别是我们在random walk框架中实现了类似于dfs的探索。因此，采样节点与给定源节点$u$的距离不是严格递增的，但反过来，我们受益于可处理的预处理和随机游走的优越采样效率。请注意，通过将$\pi_{v,x}$设为$t$中前边节点的函数，随机游走是2阶马尔可夫过程。</p><p><strong>随机游走的好处</strong>。在纯BFS/DFS方法上进行随机游走有几个好处。随机游走在空间和时间要求方面都具有很高的计算效率。存储图中每个节点的近邻的空间复杂度为$O(|E|)$。对于二阶随机游动，存储每个节点的邻居之间的相互连接是有帮助的，这导致了$O(a^2|V |)$的空间复杂度，其中a是图的平均度，对于真实世界的网络通常是很小的。与传统的基于搜索的抽样策略相比，随机游走的另一个关键优势是它的时间复杂度。特别是，通过在样本生成过程中增加图连通，随机游动提供了一种方便的机制，通过跨不同源节点重用样本来提高有效采样率。由于随机漫步的马尔可夫链的性质，通过模拟的随机游走长度$l &gt; k$一次可以从$l -k$个节点中生成k个样品。这里，我们对每个样本采集的有效复杂度是$O(\frac{l}{k(l-k)})$。例如，在图1中我们抽样一个随机游走${u, S_4, S_5, S_6, S_8, S_9}$的长度$l = 6$，得到$N_S(u) = {S_4, S_5, S_6}, N_S(S_4) = {S_5, S_6, S_8}$和$N_S(S_5) = {S_6, S_8, S_9}$。请注意，样本复用可能会在整个过程中引入一些偏差。然而，我们注意到它大大提高了效率。</p><h3 id="3-2-3-node2vec算法"><a href="#3-2-3-node2vec算法" class="headerlink" title="3.2.3 node2vec算法"></a>3.2.3 node2vec算法</h3><p><img src="/2020/01/05/graph-embedding-node2vec/alg1.png" alt="这里写图片描述"></p><p>node2vec的伪代码在算法1中给出。在任意一个随机游走中，由于起始节点$u$的选择，都存在一个隐式偏差。由于我们学习了所有节点的表示，我们通过模拟从每个节点开始的固定长度$l$的随机游走来抵消这个偏差。在每一步中，采样都是基于转移概率$\pi_{vx}$来完成的。该算法可以预先计算二阶马尔可夫链的转移概率$\pi_{vx}$，从而利用别名采样(alias sampling)在O(1)时间内有效地模拟随机游走时的节点采样。node2vec的三个阶段，即，预处理计算转移概率，随机漫步模拟和优化使用SGD，依次执行。每个阶段都可以并行化并异步执行，这有助于提高node2vec的整体可伸缩性。<br>node2vec延伸资料: <a href="http://snap.stanford.edu/node2vec" target="_blank" rel="noopener">http://snap.stanford.edu/node2vec</a></p><h2 id="3-3-学习边的特征"><a href="#3-3-学习边的特征" class="headerlink" title="3.3 学习边的特征"></a>3.3 学习边的特征</h2><p><img src="/2020/01/05/graph-embedding-node2vec/table1.png" alt="这里写图片描述"></p><p>node2vec算法为学习网络中节点的丰富特征表示提供了一种半监督方法。然而，我们通常对涉及成对节点而不是单个节点的预测任务感兴趣。例如，在链路预测中，我们预测网络中两个节点之间是否存在链路。由于我们的随机游走自然基于底层网络中节点之间的连接结构，所以我们使用自举方法在单个节点的特性表示上将它们扩展到节点对。</p><p>给出了两个节点$u$和$v$，定义了对应特征向量$f(u)$和$f(v)$上的一个二元算子$\omicron$，以生成一个表示$g(u, v)$类似$g: V \times V \to \Bbb{R}^{d’}$，其中$d’$为对$(u, v)$的表示大小。我们希望对任意一对节点定义操作符，即使这对节点之间不存在边，因为这样做可以使表示对链接预测有用，其中我们的测试集包含真边和假边(即，不存在)。我们考虑了几个操作符$\omicron$的选择，如表1中总结的$d’ = d$。</p><h1 id="4-试验"><a href="#4-试验" class="headerlink" title="4. 试验"></a>4. 试验</h1><p>等式（2）的目标是独立于任何下游任务的，node2vec提供的灵活性使得学习到的特征表示可以用于下面讨论的各种网络分析设置。</p><h2 id="4-1-案列分析：《悲惨世界》网络-Les-Miserables-network"><a href="#4-1-案列分析：《悲惨世界》网络-Les-Miserables-network" class="headerlink" title="4.1 案列分析：《悲惨世界》网络(Les Misérables network)"></a>4.1 案列分析：《悲惨世界》网络(Les Misérables network)</h2><p><img src="/2020/01/05/graph-embedding-node2vec/figure3.png" alt="这里写图片描述"></p><p>在3.1节中，我们观察到，基于同质性原则，BFS和DFS策略代表了嵌入节点频谱上的两个极端(即，网络社区)以及结构上的对等(即，节点的结构角色)。我们现在的目标是通过经验来证明这个事实，并证明node2vec实际上可以发现符合这两个原则的嵌入。</p><p>我们使用一个网络，其中节点对应于小说《悲惨世界》[13]中的人物，边缘连接共同出现的人物。该网络有77个节点和254条边。我们设置$d = 16$并运行node2vec来学习网络中每个节点的特征表示。使用k- means对特征表示进行聚类。然后，我们在二维空间中可视化原始网络，现在节点根据它们的集群分配颜色。</p><p>图3(顶部)显示了我们设置$p = 1, q = 0.5$时的示例。注意网络的区域(即，网络社区)使用相同的颜色。在这个场景中，node2vec发现了在小说的主要情节中经常相互作用的角色集群/社区。由于字符之间的边缘是基于共现的，我们可以得出结论，这种特征与同质性密切相关。</p><p>为了发现哪些节点具有相同的结构角色，我们使用相同的网络，但设$p = 1, q = 2$，使用node2vec获取节点特征，然后根据获得的特征对节点进行聚类。在这里，node2vec获得了一个节点到集群的互补分配，这样颜色就对应于结构等价性，如图3(底部)所示。例如，node2vec将蓝色的节点嵌入在一起。这些节点代表了小说中不同次要情节之间的桥梁。类似地，黄色节点主要表示位于外围的字符，它们之间的交互作用有限。可以为这些节点集群分配不同的语义解释，但关键是node2vec并不与特定的等价概念相关联。我们的实验表明，这些等价概念通常出现在大多数真实网络中，并且对预测任务的学习表示的性能有显著影响。</p><h2 id="4-2-试验设置"><a href="#4-2-试验设置" class="headerlink" title="4.2 试验设置"></a>4.2 试验设置</h2><p>我们的实验评估了通过node2vec获得的标准监督学习任务的特征表示:节点的多标签分类和边缘的链接预测。对于这两个任务，我们评估了node2vec相对于以下特征学习算法的性能:</p><ul><li>谱聚类[29]: 这是一种矩阵分解方法，我们取归一化的d个特征向量图G的拉普拉斯矩阵作为节点的特征向量表示。</li><li>DeepWalk[24]: 该方法通过模拟均匀随机游动来学习d维特征表示。DeepWalk中的采样策略可以看作是node2vec的一个特例，即$p = 1, q = 1$。</li><li>LINE[28]: 这种方法在两个独立的阶段学习$d$维特征表示。在第一个阶段，它通过bfs风格的对节点近邻的模拟来学习d=2维。在第二阶段，它通过严格在距离源节点2跳距离处采样节点来学习下一个d=2维。</li></ul><p>我们排除了其他矩阵分解方法，这些方法已经被证明不如DeepWalk[24]。我们也排除了最近的一种方法，GraRep[6]，它概括了LINE来合并超过2跳的网络邻居的信息，但是不能有效地扩展到大型网络。</p><p>与之前评估基于采样的特征学习算法的设置不同，我们为每种方法生成相同数量的样本，然后在预测任务中评估获得的特征的质量。在这样做的过程中，我们忽略了纯粹因为实现语言(C/ C++/Python)而观察到的性能提高，因为它是算法的次要部分。因此，在采样阶段，将DeepWalk、LINE和node2vec的参数设置为在运行时生成相同数量的样本。例如，如果$\cal K$是总体的采样设定，那么node2vec参数满足$\cal K = \mit r.l.|V|$。在优化阶段，所有这些基准测试都使用SGD进行优化，其中有两个关键的差异需要我们进行校正。首先，DeepWalk使用分层抽样来近似softmax概率，其目标类似于node2vec使用的目标。然而，与负采样[22]相比，分层softmax是低效的。因此，在保持其他一切不变的情况下，我们切换到DeepWalk中的负采样，这也是node2vec和LINE中的实际近似。其次，node2vec和DeepWalk都有一个用于优化上下文邻居节点数量的参数，并且节点数量越大，需要进行的优化轮数就越多。这个参数被设置为和LINE一致的，但是LINE比其他方法更快地完成一个epoch，我们让它运行k个epoch。</p><p>node2vec使用的参数设置与DeepWalk和LINE使用的典型值一致。具体地，我们设置$d = 128, r = 10, l = 80, k = 10$，并且优化运行一个epoch。我们对10个随机种子初始化重复实验，我们的结果具有统计学意义，p值小于0.01。通过在$p,q \in \{0.25, 0.50, 1, 2, 4\}$上进行网格搜索，对10%标记数据进行10次交叉验证，获得最佳的向内-向外和返回超参数。</p><h2 id="4-3-多分类"><a href="#4-3-多分类" class="headerlink" title="4.3 多分类"></a>4.3 多分类</h2><p>在多标签分类设置中，每个节点从一个有限集$\cal L$中分配一个或多个标签。在训练阶段，我们观察一定比例的节点及其所有标签。任务是预测剩余节点的标签。这是一个具有挑战性的任务，尤其是当$\cal L$很大的时候。我们利用以下数据集:</p><ul><li><strong>BlogCatalog[38]</strong>: 这是BlogCatalog网站上列出的博客作者的社会关系网络。标签代表博主的兴趣，这些兴趣是通过博主提供的元数据推断出来的。网络有10,312个节点，333,983条边，39个不同的标签。</li><li><strong>蛋白质-蛋白质相互作用(PPI)[5]</strong>: 我们使用PPI网络的一个子图来研究智人。该子图对应由节点诱导的图，我们可以从标志基因集[19]中获得标记，并表示生物状态。该网络有3,890个节点，76,584条边，以及50个不同的标签。</li><li><strong>Wikipedia[20]</strong>: 这是一个由出现在Wikipedia转储的前一百万字节中的单词组成的并发网络。这些标签表示使用Stanford POS - Tagger[32]推断的词性(POS)标记。该网络有4,777个节点、184,812条边和40个不同的标签。</li></ul><p>所有这些网络都表现出相当程度的同质性和结构等价性。例如，我们期望博客的社交网络表现出强烈的基于同质性的关系；然而，也可能有一些“熟悉的陌生人”，即，博客不互动，但有共同的兴趣，因此在结构上是等同的节点。蛋白质-蛋白质相互作用网络中蛋白质的生物学状态也表现出这两种等价性。例如，当蛋白质执行与邻近蛋白质互补的功能时，它们表现出结构上的等价性;而在其他时候，它们以同质性为基础组织起来，协助邻近蛋白质执行类似的功能。摘要在维基百科语料库的2- length窗口中，由于单词间的边界存在，所以单词间的关联网络比较密集。因此，具有相同POS标签的单词并不难找到，它们具有高度的同质性。同时，由于语法模式的不同，如名词跟在限定词后面，标点跟在名词后面等，我们希望POS标签在结构上能有一定的对等。</p><p><img src="/2020/01/05/graph-embedding-node2vec/figure4.png" alt="这里写图片描述"></p><p><strong>实验结果。</strong>将节点特征表示输入到一个具有L2正则化的one-vs-rest逻辑回归分类器中。训练和测试数据平均分配在10个随机实例中。我们使用Macro-F1（宏观F1）分数来比较表2中的性能，相对性能增益超过了最接近的基准。Micro-F1（微观F1）和准确性的趋势是相似的。</p><p>从结果可以明显看出，我们可以看到在探索邻近区域时增加的灵活性如何使node2vec超越其他基准算法。在BlogCatalog中，我们可以通过将参数$p$和$q$设置为较低的值来发现同质性和结构等价性的正确组合，从而在Macro-F1分数上获得比DeepWalk高22.3%和比LINE高229.2%的增益。LINE的性能比预期的差，这可以解释为它无法重用样本，而使用随机游走方法可以轻松完成这一壮举。即使在我们的其他两个网络中，我们也有相当的混合，node2vec的半监督性质可以帮助我们推断特征学习所需的适当探索程度。在PPI网络的情况下,最好的探索策略($p = 4, q = 1$)与DeepWalk($p = 1, q = 1$)几乎没有区别，通过使用高p值避免已经访问过的节点的冗余，对比DeepWalk只有一个微弱优势，但是一个令人信服的Macro-F1得分超出LINE23.8%。然而，一般来说，均匀随机游动可能比node2vec学习的探索策略差很多。正如我们在维基百科上看到的，均匀游动不能将搜索过程导向最佳样本，因此，我们获得了收益超过DeepWalk21.8%，超过LINE33.2%。</p><p>为了进行更细粒度的分析，我们还比较了性能，同时将训练测试从10%更改为90%，同时像以前一样对10%的数据学习参数p和q。为简洁起见，我们用图形化的方式总结了微观F1和宏观F1得分的结果，如图4所示。这里我们做了类似的观察。所有的方法都明显优于谱聚类，DeepWalk优于LINE, node2vec始终优于LINE，并且在跨域上都比DeepWalk有较大的改进。例如，我们在BlogCatalog  70%的标签数据上取得了最大的进步，超过DeepWalk26.7%。在最坏的情况下，搜索阶段对表示学习几乎没有影响，在这种情况下node2vec相当于DeepWalk。同样，与LINE相比，这些改进更加显著，除了BlogCatalog上的显著提高(超过200%)，我们还观察到其他数据集(如PPI)上的显著提高（仅对10%的标记数据进行训练）高达41.1%。</p><h2 id="4-4-参数敏感度"><a href="#4-4-参数敏感度" class="headerlink" title="4.4 参数敏感度"></a>4.4 参数敏感度</h2><p><img src="/2020/01/05/graph-embedding-node2vec/figure5.png" alt="这里写图片描述"></p><p>node2vec算法涉及许多参数，在图5a中，我们使用带标记和未带标记的数据各占一半的比例来研究不同参数的选择如何影响BlogCatalog数据集上node2vec的性能。除了要测试的参数外，其他所有参数都采用默认值。$p$和$q$的默认值设置为一致的。</p><p>我们将宏观F1分数作为参数$p$和$q$的函数进行测量，node2vec的性能随着向内-向外参数$p$和返回参数$q$的降低而提高。性能的提高可以基于我们期望在BlogCatalog中看到的同质性和结构等价性。当低$q$值时鼓励向外探索时，它被低$p$值所平衡，这确保了行走不会离起始节点太远。</p><p>我们还研究了特征数$d$和节点的邻域参数(步数$r$、步长$l$和邻域大小$k$)如何影响性能。我们观察到，一旦表示的维度达到100左右，性能就趋于饱和。类似地，我们观察到增加每个源的遍历次数和长度可以提高性能，这并不奇怪，因为我们有更大的总体抽样集$\cal K$来学习表示。这两个参数对该方法的性能都有较大的影响。有趣的是，上下文大小，$k$也提高了性能，代价是增加了优化时间。但是在这种情况下，性能差异不是很大。</p><h2 id="4-5-扰动分析"><a href="#4-5-扰动分析" class="headerlink" title="4.5 扰动分析"></a>4.5 扰动分析</h2><p>对于许多真实的网络，我们无法获得关于网络结构的准确信息。我们进行了一个扰动研究，分析了node2vec在两个与BlogCatalog网络中的边缘结构相关的不完全信息场景下的性能。在第一个场景中，我们将性能作为缺失边的分数(相对于整个网络)的函数来度量。根据网络中连通分量数量不变的约束条件，随机选取缺失的边。从图5b(top)可以看出，随着缺失边比例的增加，宏观F1分数的下降大致呈线性，且斜率较小。在图数据随时间变化的情况下(例如，引文网络)，对网络中缺失边的鲁棒性尤其重要，或者网络建设成本高的地方(如生物网络)。</p><p>在第二个扰动设置中，我们在网络中随机选择的节点对之间有噪声边。如图5b所示(下图)，与缺失边设置相比，node2vec的初始下降速度略快，但随着时间的推移，宏观F1分数的下降速度逐渐放缓。同样，node2vec对假边的鲁棒性在一些情况下是有用的，例如用于构建网络的测量是有噪声的传感器网络。</p><h2 id="4-6-可扩展性-Scalability"><a href="#4-6-可扩展性-Scalability" class="headerlink" title="4.6 可扩展性(Scalability)"></a>4.6 可扩展性(Scalability)</h2><p><img src="/2020/01/05/graph-embedding-node2vec/table3.png" alt="这里写图片描述"></p><p>为了测试可扩展性，我们使用node2vec学习节点表示，该节点表示具有Erdos-Renyi图的默认参数值，其大小从100个节点增加到100万个节点，平均度数为10。在图6中，我们根据经验观察到，node2vec随着节点数量的增加而线性扩展，在不到4小时的时间内为100万个节点生成表示。抽样程序包括计算我们的步行(可忽略的小)的转移概率的预处理和随机步行的模拟。利用负采样[22]和异步SGD[26]使优化阶段变得有效。</p><p>以前工作中的许多想法可以作为使抽样过程计算效率的有用指导。我们展示了在DeepWalk[24]中使用的随机漫步如何允许采样的节点被重用为漫步中出现的不同源节点的邻居。别名采样允许我们的散步推广到加权网络，很少预处理[28]。虽然我们可以根据底层任务和域自由地设置搜索参数，但学习搜索参数的最佳设置会增加开销。然而，正如我们的实验所证实的，这个开销是最小的，因为node2vec是半监督的，因此，可以用很少的标记数据有效地学习这些参数。</p><h2 id="4-7-链路预测"><a href="#4-7-链路预测" class="headerlink" title="4.7 链路预测"></a>4.7 链路预测</h2><p><img src="/2020/01/05/graph-embedding-node2vec/table4.png" alt="这里写图片描述"></p><p>在链路预测中，我们给定一个删除了一定比例边的网络，我们希望预测这些缺失边。我们生成边的标签数据集如下:获得正样本,我们除去50%的边缘随机选择从网络同时确保获得的残余网络边缘删除连接后,产生负样本,我们随机样本同等数量的节点对网络没有边缘连接。</p><p>由于之前没有一个特征学习算法被用于链接预测，我们根据一些流行的启发式分数对node2vec进行了额外的评估，这些分数在链接预测中获得了良好的性能。我们考虑的分数是根据构成这一对的节点的邻域集来定义的(见表3)。我们在以下数据集测试我们的基准:</p><ul><li>Facebook[14]: 在Facebook网络中，节点代表用户，边代表任意两个用户之间的友谊关系。该网络有4,039个节点和88,234条边。</li><li>蛋白-蛋白相互作用(PPI)[5]: 在PPI网络中，节点表示蛋白质，边表示一对蛋白质之间的生物相互作用。该网络有19,706个节点和390,633条边。</li><li>arXiv ASTRO-PH[14]:这是一个协作网络，由提交给e-print arXiv的论文生成，其中节点代表科学家，如果两名科学家合作过一篇论文，则存在一条边。网络已经18,722个节点和198,110条边。</li></ul><p><strong>实验结果。</strong>我们在表4中总结了链接预测的结果。为了便于表示，省略了每个node2vec条目的最佳$p$和$q$参数设置。从结果中我们可以得出一个普遍的观察结果，即节点对的学习特征表示显著优于启发式基准评分，其中node2vec对arXiv数据集的AUC提升最好，比性能最佳的基线(Adamic-Adar[1])提高了12.6%。</p><p>在特征学习算法中，node2vec在所有网络中都优于DeepWalk和LINE，增益高达3.8%和6.5%。当我们单独查看操作符时(表1)，node2vec的性能优于DeepWalk和LINE，除非涉及到几个带加权L1和加权L2操作的案例LINE会表现得更好。总的来说，当与node2vec一起使用时，Hadamard操作符是非常稳定的，并且在所有网络中平均提供了最好的性能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Graph Embedding系列的论文翻译解读文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/&quot;&gt;【Graph Embedding】DeepWalk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/21/graph-embedding-line/&quot;&gt;【Graph Embedding】line&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/26/graph-embedding-node2vec/&quot;&gt;【Graph Embedding】node2Vec&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;h1 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h1&gt;&lt;p&gt;paper: &lt;a href=&quot;https://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code: &lt;a href=&quot;https://github.com/aditya-grover/node2vec&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/aditya-grover/node2vec&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="图计算" scheme="https://buracagyang.github.io/tags/%E5%9B%BE%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Embedding" scheme="https://buracagyang.github.io/tags/Embedding/"/>
    
  </entry>
  
  <entry>
    <title>【Graph Embedding】DeepWalk</title>
    <link href="https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/"/>
    <id>https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/</id>
    <published>2019-12-26T08:16:26.000Z</published>
    <updated>2020-01-05T03:51:36.553Z</updated>
    
    <content type="html"><![CDATA[<p>关于Graph Embedding系列的论文翻译解读文章：</p><p><a href="https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/">【Graph Embedding】DeepWalk</a></p><p><a href="https://buracagyang.github.io/2019/12/21/graph-embedding-line/">【Graph Embedding】line</a></p><p><a href="https://buracagyang.github.io/2019/12/26/graph-embedding-node2vec/">【Graph Embedding】node2Vec</a></p><p>…</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>paper: <a href="http://www.perozzi.net/publications/14_kdd_deepwalk.pdf" target="_blank" rel="noopener">http://www.perozzi.net/publications/14_kdd_deepwalk.pdf</a></p><p>code: <a href="https://github.com/phanein/deepwalk" target="_blank" rel="noopener">https://github.com/phanein/deepwalk</a></p><a id="more"></a><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p><img src="/2019/12/26/graph-embedding-deepwalk/figure1.png" alt="这里写图片描述"></p><p>DeepWalk将图形作为输入，将生成的潜在表示作为输出。应用我们的结果深入研究空手道网络的方法如图1。该图通常由力导向的布局表示（1a）。图1b显示了我们方法两个潜在维度的输出。除了惊人的相似之外，我们注意到(1b)的线性可分部分对应于通过输入图(1a)中的模块最大化发现的集群(以顶点颜色显示)。为了展示DeepWalk在现实世界场景中的潜力，我们在具有挑战性的多标签上评估其性能，大型异构图中的网络分类问题。在关系分类问题中，特征向量违反了传统的i.i.d.假设（独立同分布假设）。 为了解决这个问题，通常使用近似值推理技术[32]以利用依赖信息改善分类效果。 通过学习与标签无关的图形表示，我们与这些方法保持距离。表示质量没有影响的选择标记顶点,所以他们之间可以共享任务。</p><p>在创造社交维度方面，DeepWalk的表现优于其他潜在的表现方法[39，41]，尤其是当标记的节点很少。 我们使用非常简单的线性分类器的表现非常出色（例如逻辑回归）。 我们的陈述是一般性的，并且可以与任何分类方法（包括迭代推理方法）。 DeepWalk实现了所有这些目标同时是可以并行化的在线算法。</p><p>我们的贡献如下：</p><ul><li><p>我们引入深度学习作为分析图形的工具，以构建适合于统计建模的健壮表示。DeepWalk学习短随机漫步中出现的结构规律。</p></li><li><p>我们广泛地评估了我们在几个社交网络上的多标签分类任务的表现。我们发现，在标签稀疏性存在的情况下，分类性能显著提高，并得到了改进Micro-F1的5%-10%，我们考虑的最稀疏的问题。在某些情况下，即使训练数据减少60%，DeepWalk的表现也能超越竞争对手。</p></li><li><p>我们通过构建web级图的表示来演示我们的算法的可伸缩性使用并行实现。此外，我们还描述了构建我们的方法的流版本所需的最小变动。</p></li></ul><h1 id="2-问题定义"><a href="#2-问题定义" class="headerlink" title="2. 问题定义"></a>2. 问题定义</h1><p>我们考虑将社交网络成员划分为一个或多个类别的分类问题。定义$G=(V,E)$，$V$是网络节点的集合，$E$是节点之间的边的集合。$E \subseteq (V \times V)$。给定一个有标签的社交网络$G_L=(V,E,X,Y)$,它有属性$X \in \Bbb R^{|V| \times S}$，其中$S$是每个属性的特征空间大小，$Y \in \Bbb R^{|V| \times \cal Y}$是标签的集合。</p><p>在传统的机器学习分类任务中，我们需要学习一个$H$假设，使它可以把$X$映射到$Y$集合中。现在，我们可以利用嵌入到图$G$结构中的样本关系获得有意义的信息，进而获得更好的表现。</p><p>在文献中，这被称为关系分类。传统的方法把这个问题看作无向马尔可夫网络的推理问题，并且在给定网络结构的情况下，运用迭代近似推理算法取计算标签的后验分布。</p><p>我们提出一种不同的方法去获取网络的拓扑信息。而不是混合标签空间作为特征空间的一部分，我们提出一种无监督的方法可以得到具有捕捉网络结构能力的特征，并且它们与标签的分布是相关独立的。</p><p>我们的目标是学习$X_E \in \Bbb R^{|V| \times d}$，这里的$d$是潜在维数的一个小小的子集。这些低维表示是分布式的，意味着每种社交现象被这些维度的子集所表示，并且每个维度都贡献了空间所表达的社会概念的子集。</p><p>使用这些结构化的属性，我们就可以扩充特征空间，帮助进行分类决策。这些特征是通用的，可以用作任何分类算法（包括迭代算法）。因此，这些特征的最大好处就是易与简单的机器学习算法整合起来。</p><h1 id="3-学习社交表示"><a href="#3-学习社交表示" class="headerlink" title="3. 学习社交表示"></a>3. 学习社交表示</h1><p>我们试图学习具有以下特征的社会表征:</p><ul><li><strong>适应性</strong> – 真实的社交网络是不断进化的;新的社会关系不应该要求重新学习过程。</li><li><strong>社区感知</strong> – 潜在维度之间的距离应该代表一个度量标准，用于评估网络中相应成员之间的社会相似性。这使得具有同质性的网络可以泛化。</li><li><strong>低维</strong> – 当标记数据不足时，低维模型能更好地推广，并加速收敛和推理。</li><li><strong>连续</strong> – 我们需要潜在的表现来在连续空间中模拟部分社区成员。除了提供社区成员的细致视图外，一个连续的表示在社区之间有平滑的决策边界，这允许更健壮的分类。</li></ul><p>我们的方法通过学习短随机游动流中的顶点表示法，使用最初为语言建模设计的优化技术来满足这些要求。在这里，我们回顾了随机游动和语言建模的基础知识，并描述了它们的组合如何满足我们的需求。</p><h2 id="3-1-随机游走"><a href="#3-1-随机游走" class="headerlink" title="3.1 随机游走"></a>3.1 随机游走</h2><p>我们定义随机游走的根节点$v_i$为$\cal W_{v_i}$。它是一个由$\cal W^1_{v_i},\cal W^2_{v_i},…,\cal W^k_{v_i}$组成的随机过程，$\cal W^{k+1}_{v_i}$是被随机选出的节点$v_k$的邻居。随机游走作为一种相似度度量的方式应用于内容推荐和社区发现。正是这种与本地结构的连接促使我们使用短随机游动流作为从网络中提取信息的基本工具。使用随机游走不仅可以获取社区信息，还有两个理想特性。<strong>首先</strong>，局部探索很容易并行化。几个随机的行人(在不同的线程、进程或机器中)可以同时探索同一图的不同部分。<strong>其次</strong>，依靠短随机游动获得的信息，可以适应图结构的微小变化，而不需要全局重新计算。我们可以用新的随机游动来迭代地更新所学习的模型，这对比更新整个图来说是次线性的。</p><h2 id="3-2-连接：幂律"><a href="#3-2-连接：幂律" class="headerlink" title="3.2 连接：幂律"></a>3.2 连接：幂律</h2><p><img src="/2019/12/26/graph-embedding-deepwalk/figure2.png" alt="这里写图片描述"></p><p>在选择在线随机游走作为我们主要捕捉图结构的方法之后，我们现在需要一个合适的方法去捕捉这些信息。如果一个连接图的度分布服从幂律定律，我们观测得到节点在短随机游走出现的频率也会服从<strong>幂律分布</strong></p><p>我们工作的核心贡献是提出，过去用于自然语言建模的方法（符号频率服从幂律分布）也可以用于网络的社区结构建模。接下来将介绍自然语言建模，然后将其转化为学习节点表示，并使之满足我们的标准。</p><h2 id="3-3-语言建模"><a href="#3-3-语言建模" class="headerlink" title="3.3 语言建模"></a>3.3 语言建模</h2><p>语言建模的目标是估计一串特殊的词出现在全集的可能性。正式地说，给定一串词$W^n_1=(w_0,w_1,…,w_n)$，其中$w_i \in \cal V$($\cal V$是词汇表)，我们要在所有训练的集合中求出$Pr(w_n|w_0,w_1,…,w_{n-1})$的最大值。最近关于表示学习的工作聚焦在使用概率神经网络去建立通用的词汇表示，这超出了语言建模的原始目标的范围。</p><p>在这项工作中，我们通过短随机游走探索图，这展示了一种语言建模的一般化。这种直接的类比是在给定随机游走之前访问过的节点情况下，估计下一次要访问节点$v_i$的可能性。<br>$$<br>Pr(v_i|(v_1,v_2,…,v_{i-1})) \tag{1}<br>$$<br>我们的目标是学习一种潜在的表示，而不是一个节点再现的概率分布，因此我们引入一个映射函数$\Phi:v \in V \to \Bbb R^{|V| \times d}$。这个映射函数$\Phi$表示图中每个节点$V$之间潜在的社交表示。然后这个问题就变成估计以下可能性：<br>$$<br>Pr(v_i|(\Phi(v_1),\Phi(v_2),…,\Phi(v_{i-1}))) \tag{2}<br>$$<br>然而，随着游走的距离增大，计算这个目标函数变得不是那么容易。</p><p>一个在语言建模的最新的放松(relaxation)考虑到了这个预测问题。首先，不是用上下文去预测缺失的单词，而是用单词去预测它的上下文。其次，这里的上下文同时包括该单词的右边的词汇和左边的词汇。最后，它去除了这个问题的顺序约束。取而代之的是，这个模型需要最大化上下文出现的各个单词的概率，而无需知道其偏离给定单词的知识。在节点表示建模方面，这产生了如下优化问题：<br>$$<br>\underset{\Phi}{minimize}-logPr(\lbrace v_{i-w},…,v_{i-1},v_{i+1},…,v_{i+w} \rbrace / v_i | \Phi(v_i)) \tag{3}<br>$$<br>我们发现这些放松在社交表示学习上尤其可取。首先，顺序独立假设很好地获取了随机游走所提供的“接近”。另外，这个放松可以在某个时间给出一个节点的情况下，通过构建更小的模型加速训练时间。</p><p>解决上面式子的优化问题构建了局部图结构的节点之间的共享相似度表示。具有相似邻居的节点会获得相似的表示，可以在机器学习任务上一般化。</p><p>通过结合缩短的随机游走和神经语言模型我们建立一种可以满足我们所有期望特性的方法。这种方法生成了社交网络的低维表示，并且在向量空间连续。它表示了社区成员的潜在形式，并且由于这种方法输出有用的中间表示，它可以适应变化的网络拓扑。</p><h1 id="4-方法"><a href="#4-方法" class="headerlink" title="4. 方法"></a>4. 方法</h1><p>在本节中，我们将讨论算法的主要组成部分。我们也提出了几种不同的方法，并讨论了它们的优点。</p><h2 id="4-1-概况"><a href="#4-1-概况" class="headerlink" title="4.1 概况"></a>4.1 概况</h2><p>在其他所有语言建模算法中，需要的输入仅为一个全集和一个词汇表$\cal V$。DeepWalk把随机游走作为自己的全集，图的节点作为自己的词汇表$(\cal V$ = $V)$。然而，最好在训练之前知道随机游走的$V$和节点的频率分布，不过这不是必须要的。</p><h2 id="4-2-算法：-DeepWalk"><a href="#4-2-算法：-DeepWalk" class="headerlink" title="4.2 算法： DeepWalk"></a>4.2 算法： DeepWalk</h2><p>算法主要包括两个主要成分；第一是一个随机游走的生成器，第二是更新程序。<strong>随机游走生成器</strong>把图$G$作为输入，随机挑选一个节点$v_i$作为随机游走$\cal W_{v_i}$的根节点。每一步需要从上一个节点的邻居节点中随机挑选一个作为当前节点，直到达到最大长度$t$。在实验中我们把这个长度固定，但是并没有规定$t$必须取某个相同的值。这些游走可能重新回到起点，但是我们之前的结果并没有显示重新开始的任何优势。在实践过程中，我们在每个节点进行了$\gamma$次长度为$t$的随机游走。</p><p><img src="/2019/12/26/graph-embedding-deepwalk/alg1.png" alt="这里写图片描述"></p><p>算法1中的3-9行显示了我们方法的核心。外循环指定次数，$\gamma$，我们应该在哪个点开始随机游走。 我们认为每次迭代都是对数据进行一次“传递”，并在此传递过程中对每个节点进行一次抽样。在每次遍历的开始，我们都会生成一个随机的遍历顶点的顺序。这不是严格要求，但众所周知可以加快收敛的随机梯度下降。  </p><p>在内部循环中，我们遍历图上的所有顶点。对于每个顶点$v_i$，我们生成一个随机游走$|\cal W_{v_i}| = t$，然后用它来更新我们的表示。我们根据目标函数，使用<strong>SkipGram</strong>算法进行表示的更新。</p><h3 id="4-2-1-SkipGram"><a href="#4-2-1-SkipGram" class="headerlink" title="4.2.1 SkipGram"></a>4.2.1 SkipGram</h3><p><img src="/2019/12/26/graph-embedding-deepwalk/alg2.png" alt="这里写图片描述"></p><p>SkipGram是一种语言模型，它使出现在窗口$w$中的单词在句子中的共现概率最大化。它使用如下独立假设近似方程3中的条件概率<br>$$<br>Pr\left(\{v_{i-w}, …, v_{i+w}\}/v_i | \Phi(v_i) \right) = \prod_{j=i-w \&amp; j\neq i}^{i+w}Pr(v_j | \Phi(v_i)) \tag{4}<br>$$<br>算法2 遍历出现在窗口$w$中的所有可能的随机配置遍历（第1-2行）中的dom步行。对于</p><p>每一个顶点，我们将每个顶点$v_j$映射到其当前表示向量$\Phi(v_j) \in \Bbb R^d$（见图3b）。给定$v_j$的表示，我们想要最大化它的邻居在这条线上的概率(第3行)。我们可以用几种分类器来学习这种后验分布。例如，使用逻辑回归对前面的问题进行建模，将产生大量的标签(即$|V|$)，其数量可能是数百万或数十亿。这些模型需要大量的计算资源，这些资源可以跨越整个计算机集群[4]。为了避免这种必要性，加快训练时间，我们使用层次结构来近似概率分布。</p><p><img src="/2019/12/26/graph-embedding-deepwalk/figure3.png" alt="这里写图片描述"></p><h3 id="4-2-2-分层SoftMax"><a href="#4-2-2-分层SoftMax" class="headerlink" title="4.2.2 分层SoftMax"></a>4.2.2 分层SoftMax</h3><p>给定$u_k \in V$,计算$Pr(u_k|\Phi(v_j))$不是可取的。计算分区函数（归一化因子）是代价高的。如果我们把顶点分配给二叉树的叶节点，将预测问题转化为最大化层次结构中特定路径的概率(参见图3c)。如果到顶点$u_k$的路径由一系列树节点$(b_0, b_1, …, b_{[log|V|]})$，$(b_0=root, b_{[log|V|]}=u_k)$，那么：<br>$$<br>Pr(u_k | \Phi(v_j)) = \prod_{l=1}^{[log|V|]}Pr(b_l | \Phi(v_j)) \tag{5}<br>$$<br>现在，$Pr(b_l | \Phi(v_j))$可由分配给节点$b_l$父节点的二进制分类器建模，如式6所示，<br>$$<br>Pr(b_l | \Phi(v_j)) = 1 / (1+e^{-\Phi(v_j).\Psi(b_l)}) \tag{6}<br>$$<br>其中$\Psi(b_l) \in \Bbb R^d$是分配给树节点$b_l$的父节点的表示形式。这减少了计算$Pr(u_k | \Phi(v_j)) $的复杂性，复杂度从$O(|V|)$降低到$O(log|V|)$。</p><p>通过为随机游动中频繁出现的顶点分配较短的路径，可以进一步加快训练过程。人工编码是为了减少树中频繁元素的访问时间。</p><h3 id="4-2-3-最优化"><a href="#4-2-3-最优化" class="headerlink" title="4.2.3 最优化"></a>4.2.3 最优化</h3><p>这个模型的参数集合是$\theta = \lbrace \Phi,T \rbrace$，其大小都为$O(d|V|)$。随机梯度下降被用来优化这些参数。微分用后向传播算经进行计算。学习率$\alpha$初始化为2.5%，然后随着目前发现的节点的增加线性减小。</p><h2 id="4-3-并行性"><a href="#4-3-并行性" class="headerlink" title="4.3 并行性"></a>4.3 并行性</h2><p>如图2所示，社交网络中随机游走的顶点的频率分布和语言中的单词都遵循幂律。这就导致了一条罕见顶点的长尾，因此，影响$\Phi$的更新在本质上是稀疏的。在有多个worker的情况下允许我们使用异步版本的随机梯度下降（ASGD）。鉴于我们的更新是稀疏的，并且我们没有获得访问模型共享参数的锁，因此ASGD将实现最佳收敛速度[36]。当我们在一台使用多线程的机器上运行实验时，已证明该技术具有高度的可扩展性，并且可以用于超大规模的机器学习[9]。图4展示了并行化DeepWalk的效果。它表明，随着我们将worker数量增加到8个，处理BlogCatalog和Flickr网络的速度是一致的（图4a）。它还表明，相对于串行运行DeepWalk而言，不会降低预测性能（图4b）。<br><img src="/2019/12/26/graph-embedding-deepwalk/figure4.png" alt="这里写图片描述"></p><h2 id="4-4-算法变体"><a href="#4-4-算法变体" class="headerlink" title="4.4 算法变体"></a>4.4 算法变体</h2><p>在这里，我们将讨论我们所提议的方法的一些变体，我们相信这些变体可能会很有趣。</p><h3 id="4-4-1-Streaming"><a href="#4-4-1-Streaming" class="headerlink" title="4.4.1 Streaming"></a>4.4.1 Streaming</h3><p>这种方法的一个有趣的变体是流式处理处理，哪些可以在不了解整个图的情况下实现。在这种变体中，图的小遍历被直接传递给表示学习代码，并直接更新模型。 对学习过程进行一些修改也是必要的。 首先，使用衰减的学习率可能不再是可取的，因为它假定了总语料库大小的知识。反而，我们可以将学习率$\alpha$初始化为一个小的常数值。这将需要更长的学习时间，但在某些应用程序中值得。其次，我们不一定要建立任何参数树。 如果$V$的基数已知（或可以有界），我们可以为该最大值构建Hierarchical Softmax树。 可以将顶点分配给其余叶子之一<br>当他们第一次见到。 如果我们有能力预先估计顶点频率，我们还可以使用人工编码(Huffman coding)来减少频繁的元素访问时间。</p><h3 id="4-4-2-非随机游走"><a href="#4-4-2-非随机游走" class="headerlink" title="4.4.2 非随机游走"></a>4.4.2 非随机游走</h3><p>有些图是代理与一系列元素交互的副产品(例如，用户在网站上的页面导航)。当这样一个非随机游动流创建一个图时，我们可以使用这个过程来直接支持建模阶段。以这种方式采样的图不仅可以捕获与网络结构相关的信息，还可以捕获路径遍历的频率。</p><p>在我们看来，这种变体还包括语言建模。句子可以被看作是经过适当设计的语言网络的有目的的散步，而像SkipGram这样的语言模型就是为了捕捉这种行为而设计的。</p><p>这种方法可以与流变体相结合(第4.4.1节)在一个不断演化的网络中训练特征，而不需要显式地构造整个图。使用这种技术维护表示可以实现web级别的分类，而不需要处理web级别的图。</p><p><img src="/2019/12/26/graph-embedding-deepwalk/table1.png" alt="这里写图片描述"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Graph Embedding系列的论文翻译解读文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/&quot;&gt;【Graph Embedding】DeepWalk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/21/graph-embedding-line/&quot;&gt;【Graph Embedding】line&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/26/graph-embedding-node2vec/&quot;&gt;【Graph Embedding】node2Vec&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;h1 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h1&gt;&lt;p&gt;paper: &lt;a href=&quot;http://www.perozzi.net/publications/14_kdd_deepwalk.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.perozzi.net/publications/14_kdd_deepwalk.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code: &lt;a href=&quot;https://github.com/phanein/deepwalk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/phanein/deepwalk&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="图计算" scheme="https://buracagyang.github.io/tags/%E5%9B%BE%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Embedding" scheme="https://buracagyang.github.io/tags/Embedding/"/>
    
  </entry>
  
  <entry>
    <title>【Graph Embedding】line</title>
    <link href="https://buracagyang.github.io/2019/12/21/graph-embedding-line/"/>
    <id>https://buracagyang.github.io/2019/12/21/graph-embedding-line/</id>
    <published>2019-12-21T09:12:54.000Z</published>
    <updated>2020-01-05T03:51:27.095Z</updated>
    
    <content type="html"><![CDATA[<p>关于Graph Embedding系列的论文翻译解读文章：</p><p><a href="https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/">【Graph Embedding】DeepWalk</a></p><p><a href="https://buracagyang.github.io/2019/12/21/graph-embedding-line/">【Graph Embedding】line</a></p><p><a href="https://buracagyang.github.io/2019/12/26/graph-embedding-node2vec/">【Graph Embedding】node2Vec</a></p><p>…</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>paper: <a href="https://arxiv.org/pdf/1503.03578.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1503.03578.pdf</a></p><p>code: <a href="https://github.com/tangjianpku/LINE" target="_blank" rel="noopener">https://github.com/tangjianpku/LINE</a></p><a id="more"></a><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文研究了大型信息网络如何嵌入到低维向量空间的问题，应用于可视化，节点分类，和链路预测上。大多已存在的嵌入图方法并不适用于现有的包含百万个节点的信息网络。在本文中，我们提出了一个新型网络表征方法称为LINE，适用于任意类型的信息网络(有向的，无向的，以及无权的有权的)。该方法优化了一个精心设计的目标函数，保留了局部以及全局的网络结构。提出了一种边采样算法，该算法解决了经典随机梯度下降的局限性，并提高了推理的有效性和效率。经过实验验证了LINE在多种真实世界的信息网络（语言、社会，引文）的有效性，该算法非常有效，能够在典型的单台机器上学习在几小时内嵌入具有数百万个顶点和数十亿个边缘的网络。LINE的源代码可在线获取。</p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>本文研究了将信息网络嵌入到低维向量空间中，其中网络中的每个顶点都表示为低维的向量。这样一个低维的嵌入有助于可视化，节点分类，链路预测的应用。</p><p>为了更好的在嵌入过程中保留网络中的拓扑结构信息（保留节点之间的关联关系）。提出了一阶相似度和二阶相似度的概念。</p><p>一阶相似度指顶点之间直接连接信息。在真实网络数据中不足以用于保留全局的网络结构。故补充了二阶相似度的概念(即具有共享的邻居节点的顶点可能是相似的)。在社会学和文本语库中可以找到这样的推论。社交网络中，两个人的好友关系的重复度越高，两个人的相关性就越高。文本语料库中，我们可以通过一句话的其他内容来了解单个单词的意思。事实上，有许多共同好友的两个人大概率有相似的爱好并可能成为朋友，而常与同样的语句组合使用的单词更可能具有相同的意思。</p><p>在本文中，提出了一种保留了一阶相似度和二阶相似度的精心设计的目标函数。找到这个健全的目标函数后，如何优化该函数使得其可以应用于大规模的网络中是一个具有挑战性的问题。近年来，一个解决方案是使用随机梯度下降进行优化。因为许多网络中的边是带权的，且权重呈现了高度的差异性，，所以直接对真实信息网络使用随机梯度下降是不可取的。</p><p>对于一个单词共现网络，单词对的权重变化可能从一到百到千，边的权重乘以梯度会引起梯度爆炸，进而影响性能。为了解决这个问题，我们提出了一个可以提升推理的有效性和效率的新的边取样方法。我们用与其权重成比例的概率对边进行采样，并将采样边视为二进制边以进行模型更新。在这样的取样过程下，目标函数不会发生变化， 且边的权重不再影响梯度。</p><p>经过实验验证了LINE在多种真实世界的信息网络（语言、社会，引文）的有效性和效率都优于其他方法，该算法能够在典型的单台机器上学习在几小时内嵌入具有数百万个顶点和数十亿个边缘的网络。</p><p>总结本文的贡献可分为以下三点：</p><ul><li>我们提出了一种网络嵌入模型称为LINE,适用于任意类型的信息网络，并能够轻易拓展到百万个节点。它拥有一个可以保留一阶相似度和二阶相似度的目标函数。</li><li>我们提出了一种边采样算法以优化目标函数。该算法解决了经典随机梯度下降的局限性，提高了推理的有效性和效率。</li><li>我们在真实的信息网络中继续了广泛的实验。实验结果证明了LINE模型的有效性和效率。</li></ul><h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h1><p>经典的图表征方法和降维方法使用数据点的特征向量来创建亲和图。此类算法依赖于解决亲和矩阵的主要特征向量。</p><p>最近的文献介绍了图矩阵分解方法，使用优化的随机梯度下降方法进行了矩阵分解。该方法不能保留网络全局结构，并且只能应用于无向图。最近与我们工作最相关的工作是DeepWalk。它对社交网络嵌入使用了一个截断的随机漫步。但该方法没有提供一个明确的说明网络所保留的属性的目标函数。DeepWalk期望具有更高二阶接近度的节点产生相似的低维表示。它使用类似于深度优先搜索的随机漫步来拓展节点的邻居。而我们使用了广度优先的策略，能够得到更合理的二阶相似度。实际应用上，DeepWalk只能应用到无权的网络，而LINE可以应用于包含有权/无权的边的网络。</p><h1 id="3-问题定义"><a href="#3-问题定义" class="headerlink" title="3. 问题定义"></a>3. 问题定义</h1><p><strong>定义1  信息网络</strong></p><p>信息网络被定义为$G = (V, E)$，其中$V$表示节点集合，每个节点表示一个数据对象。$E$表示节点间的边。每一个$e \in E$都是一个有序对 $e = (u, v)$且都有一个关联的权重$w_{uv} &gt; 0$。如果$G$是无向图，那么有$(u, v) \equiv (v, u)$且$w_{uv} \equiv w_{vu}$。如果$G$是无向图，则$(u, v) \not\equiv (v, u)$且$w_{uv} \not\equiv w_{vu}$。</p><p><strong>定义2  一阶相似度</strong></p><p>一阶相似度：一阶相似度是网络中两个节点的局部相似度。若节点u和v之间有边$(u,v)$，则$w_{uv}$表示u和v之间的一阶相似度。如果u和v之间没有可以观察的边，一阶相似度则为0。</p><p><strong>定义3  二阶相似度</strong></p><p>二阶相似度：网络中一对节点$(u, v)$之间的二阶相似度是他们相邻网络结构的相似度。数学化的定义，使$[p_{u} = (w_{u,1},… ,w_{u,|V|})$ 描述节点$u$与其他节点的一阶相似度，那么$u$与$v$的二阶相似度取决于$p_u$与$p_v$之间的相似度。如果没有从$u$到$v$连接（或从$v$到$u$）的中间节点。则$u$和$v$之间的二阶相似度为0。</p><p><strong>定义4  大规模信息网络嵌入</strong></p><p>大规模信息网络嵌入: 给定一个大型网络$G=(V, E)$，大规模信息网络嵌入的目标是把每个节点$u \in V$ 嵌入到低维向量空间$R^{d}$中。如：学习一个函数$f_{G}:V\to R^{d},d\ll |V|$.在$R^{d}$空间内，节点间的一阶相似度和二阶相似度都被保留。</p><p>需要注意：本文仅研究边的权重为非负值的情况，在引用网络和社交网络中，权重只取二进制值(0/1)。在单词共现网络中，边的权重可能会分散，因为部分单词共同出现很多次，而部分单词可能只共同出现几次。</p><h1 id="4-LINE：大规模信息网络嵌入"><a href="#4-LINE：大规模信息网络嵌入" class="headerlink" title="4. LINE：大规模信息网络嵌入"></a>4. LINE：大规模信息网络嵌入</h1><p>真实世界网络下的一个理想的嵌入模型必须满足如下几个条件：1.保留一阶相似度和二阶相似度。2.能够支持含有百万节点和亿万边的大型网络的规模。3.能够处理任意类型的边(有无向，有无权重)。</p><h2 id="4-1-模型描述"><a href="#4-1-模型描述" class="headerlink" title="4.1 模型描述"></a>4.1 模型描述</h2><p>分别描述了保持一阶近似和二阶近似的线性模型，然后介绍了一种将两种近似结合起来的简单方法。</p><h3 id="4-1-1-LINE的一阶相似度"><a href="#4-1-1-LINE的一阶相似度" class="headerlink" title="4.1.1 LINE的一阶相似度"></a>4.1.1 LINE的一阶相似度</h3><p>对于无向边$(i, j)$， 我们定义$v_i$和$v_j$的相连的可能性如下：<br>$$<br>p_{1}(v_{i},v_{j})=\frac{1}{1+exp(-\vec u_i^{T}\cdot\vec u_j)} \tag{1}<br>$$<br>其中，$\vec u_i\in R^d$ 是$v_i$ 节点的低维向量表示。$p(.,.)$是 $V*V$ 的向量空间下的一个分布，它所验证的概率可以被定义为$\hat p_1(i,j)=\frac{w_{ij}}{W}$，其中$W=\sum_{i,j\in E}w_{ij}$</p><p>为了保留一阶相似度，可以直接最小化以下目标函数：<br>$$<br>O_{1}=d(\hat p_1(.,.),p_1(.,.)) \tag{2}<br>$$<br>其中d是两个分布的距离，我们选择最小化两个可能分布的<a href="https://buracagyang.github.io/2019/06/21/information-theory-2/">KL距离</a> (KL距离：$KL(p||q)=-\int p(x)ln\frac{q(x)}{p(x)}dx$ 用于衡量两个概率分布的差异情况, 其值越大说明两个分布的差异越大)。使用KL距离来替换d(.,.)并忽略一些约束。我们得到了：<br>$$<br>O_1=-\sum_{i,j\in E}w_{ij}logp_1(v_i,v_j) \tag{3}<br>$$<br>需要注意的是该一阶相似度仅应用于无向图，而非有向图。通过寻找能够使（3）式最小化的$\{\vec u_i\}_{i=1..|V|}$ 。我们可以在d维的空间里表示每个节点。</p><h3 id="4-1-2-LINE的二阶相似度"><a href="#4-1-2-LINE的二阶相似度" class="headerlink" title="4.1.2 LINE的二阶相似度"></a>4.1.2 LINE的二阶相似度</h3><p>二阶相似度可以应用于有向图以及无向图。给定一个网络，为了不失一般性，我们假设它是有向的（无向边可以被视为两个方向相反、权重相等的有向边）。每个顶点既是顶点本身，也是其他顶点的上下文。<br>$$<br>p_2(v_j|v_i)=\frac{exp(\vec u_j\prime^T \cdot \vec u_i)}{\sum_{k=1}^{|V|}exp(\vec u_k\prime^T \cdot \vec u_i)} \tag{4}<br>$$</p><p>其中，$|V|$是顶点或上下文的数量。对于每个顶点$v_i$,（4）式定义了一个上下文的条件分布$p_2(\cdot|v_i)$，例如网络中节点的完整集合。为了保留二阶相似度，我们应该使用低维表征的上下文条件分布$p_2(\cdot|v_i)$ 接近于经验分布$\hat p_2(\cdot|v_i)$ 。这样，我们最小化了以下目标函数：<br>$$<br>O_2=\sum_{i\in V}\lambda_id(\hat p_2(\cdot|v_i),p_2(\cdot|v_i)) \tag{5}<br>$$</p><p>其中$d(.,.)$是两个分布之间的距离。由于顶点在网络中的重要性不同，我们引入了$\lambda_i$ 到目标函数中来表示网络中顶点$i$的重要性，可以通过度来计算得到或者通过PageRank算法来评估。经验分布$\hat p_2(\cdot|v_i)$ 被定义为$\hat p_2(v_j|v_i)=\frac{w_{ij}}{d_i}$ ,其中$w_{ij}$是边$(i, j)$的权重，且$d_i$是顶点$i$的出度。即，$d_i=\sum_{k\in N(i)}w_{ik}$ . 其中$N(i)$是$v_i$节点的“出”邻居（从$i$节点出发的邻节点），在本文中，为了方便，我们设置$\lambda_i$ 作为顶点$i$的出度。$\lambda_i=d_i$，我们还采用KL散度作为距离函数，使用KL距离代替d(.,.).设置$\lambda_i=d_i$并忽略约束，我们得到了：<br>$$<br>O_2 = -\sum_{(i,j)\in E}w_{ij}logp_2(v_j|v_i) \tag{6}<br>$$<br>通过学习能够使以上目标函数最小化的$\{\vec u_i\}_{i=1..|V|}$ 和 $\{\vec u_i\prime\}_{i=1..|V|}$，我们能够通过一个d维的向量$\vec u_i$表示每个顶点$v_i$。</p><h3 id="4-1-3-结合一阶相似度和二阶相似度"><a href="#4-1-3-结合一阶相似度和二阶相似度" class="headerlink" title="4.1.3 结合一阶相似度和二阶相似度"></a>4.1.3 结合一阶相似度和二阶相似度</h3><p>为了在嵌入过程中保留一阶相似度和二阶相似度，我们在实践中发现的一种简单而有效的方法是训练LINE模型，分别保留一阶接近度和二阶接近度，然后，为每个顶点连接由两种方法训练得到的嵌入。 更有原则的方法是结合两个相似度来联合训练目标函数（3）和（6），我们将其留作未来的工作。</p><h2 id="4-2-模型优化"><a href="#4-2-模型优化" class="headerlink" title="4. 2 模型优化"></a>4. 2 模型优化</h2><p>优化目标函数（6）的计算代价昂贵，在计算条件概率$p2(\cdot|v_i)$ 时需要对整个顶点集求和。为了解决该问题，我们采用了论文[13]中提出的负采样方法，根据每个边$(i,j)$的一些噪声分布对多个负边进行采样。 更具体地说，它为每个边指定了以下目标函数：<br>$$<br>log\sigma(\vec u_j\prime^T\cdot\vec u_i)+\sum_{i=1}^KE_{v_n~P_n(v)}[log\sigma(-\vec u_n\prime^T\cdot \vec u_i)] \tag{7}<br>$$<br>其中$\sigma(x)= 1/exp(-x)$ 是sigmoid函数。第一项对观察到的边进行建模，第二项对从噪声分布中绘制的负边进行建模，而$K$是负边的数量。我们根据[13]，设置$p_n(v)\propto d_v^{3/4}$ ，其中$d_v$是$v$节点的出度。</p><p>为了（3）式的目标函数。存在一个平凡解：$u_{ik}=\infty$。其中$i=1,…,|V|$且 $k=1…,d$。为了避免平凡解，我们仍然可以使用负采样方法，仅将$\vec u_{j}\prime^T$变成$\vec u_j^T$。</p><p>我们采用了异步随机梯度算法(ASGD)来优化等式（7）。在每一步，ASGD算法取样了一小部分的边并更新了模型的参数，如果边$(i,j)$被取样，那么关于$i$节点的嵌入向量$\vec u_i$的梯度可以被计算：<br>$$<br>\frac{\partial O_2}{\partial \vec u_i}=w_{ij}\cdot \frac{\partial logp_2(v_j|v_i)}{\partial \vec u_i} \tag{8}<br>$$<br>这样的梯度将乘以边的权重。当边的权重具有高方差时，这将成为问题。举个例子，在单词共现网络中，有些单词共现的次数上千，有些次数非常少。在这样的网络中，梯度的规模偏差太大，难以寻找一个好的学习比例。如果我们根据有较小权重的边来选择一个大的学习比率，权重较大的边的梯度会爆炸。如果根据较大权重的来选择一个小的学习比率，权重较小的边的梯度会太小。</p><h3 id="4-2-1-边采样算法优化"><a href="#4-2-1-边采样算法优化" class="headerlink" title="4.2.1 边采样算法优化"></a>4.2.1 边采样算法优化</h3><p>如果每个边的权重相等（类似于二进制边的网络），上述内容的问题将得以解决，也能够选择一个合适的学习比率。一个简单的方法是将一条带权的边展开为多种二进制边。例如，一个权重为$w$的边展开为$w$个二进制边。这样能够解决问题但增加了内存需求，尤其是在边的权重值非常大时。为了进一步解决问题，我们可以从原始边进行取样，并将取样的边视为二进制边。采样概率与原始边的权重成比例。通过这种边采样处理，总体目标函数保持不变，问题归结为如何根据权重对边进行采样。</p><p>令$W=(w_1,w_2,w_3,…,w_{|E|})$表示边的权重的顺序。一种简单的方法是可以直接计算权重的总和 $w_{sum}=\sum_{i=1}^{|E|}w_i$，然后在$[0,w_{sum}]$中取一个随机值来看随机值落入的区间$[\sum_{j=0}^{i-1}w_j,\sum_{j=0}^iw_j]$。这个方法得到样本的时间复杂度时$O(|E|)$。当边的数量$|E|$较大时开销较大。我们根据边的权重使用了从相同的离散分布中重复绘制样本时时间复杂度仅为O(1)的alias table（别名表）[9]方法来取样。</p><p>从alias table中取样一条边的时间O(1),优化一个负采样需要$O(d(K+1))$的时间，其中$K$是负样本的数量。因此，总体每一步骤都需要$O(dK)$时间。在实践中，我们发现用于优化的步骤数量与边的数量$O(|E|)$成比例。因此，LINE的总的时间复杂度是$O(dK|E|)$,与边$|E|$的数量呈线性关系的，且不依赖于顶点数量$|V|$。这种边取样方法在不影响效率的情况下提升了随机梯度下降算法的有效性。</p><h2 id="4-3-讨论"><a href="#4-3-讨论" class="headerlink" title="4.3 讨论"></a>4.3 讨论</h2><p>我们讨论了LINE模型的几个实际问题。</p><p><strong>低度顶点</strong></p><p>第一个问题：如何精确嵌入具有较低度数的顶点？由于这类顶点的邻居数量很少，所以难以得到它所对应的精确表征，尤其是严重依赖上下文的二阶相似度。一种推论是，通过增加其高阶的邻居（如邻居的邻居）来拓展这些顶点的邻居。在本论文中，我们仅讨论增加二级邻居。即对每个顶点，增加其邻居的邻居。顶点$i$和其二级邻居节点$j$之间的距离可以被计算为：<br>$$<br>w_{ij}=\sum _{k\in N(i)}w_{ik}\frac{w_{kj}}{d_k} \tag{9}<br>$$<br>实际上，我们可以仅为具有较低度数的顶点$i$增加一个有最大相似度$w_{ij}$的顶点子集${j}$。</p><p><strong>新的顶点</strong></p><p>第二个问题：如何得到新顶点的表征？对于一个新顶点$i$,如果已知它与已存在的顶点之间连接。我们可以根据已存在的顶点获得经验分布$\hat p_1(\cdot ,v_i)$和$\hat p_2(\cdot|v_i)$。为了获取新顶点的嵌入，根据目标函数（3）式和（6）式。一个直接的方法通过更新新顶点的嵌入并保持已存在顶点的嵌入来最小化以下任意一个目标函数：<br>$$<br>-\sum_{j\in N(i)}w_{ji}logp_1(v_j,v_i),   or   -\sum_{j\in N(i)}w_{ji}logp_2(v_j|v_i) \tag{10}<br>$$<br>如果新顶点和已有节点之间有可观察的连接，我们必须求助于其他信息，例如顶点的文本信息，我们将其作为未来的工作。</p><h1 id="5-试验"><a href="#5-试验" class="headerlink" title="5. 试验"></a>5. 试验</h1><p>我们经验地评估LINE的有效性和效率。我们将该方法应用到多种不同类型的大规模真实世界网络，包括一个语言网络，两个社交网络，和两个引用网络。</p><h2 id="5-1-试验设置"><a href="#5-1-试验设置" class="headerlink" title="5.1 试验设置"></a>5.1 试验设置</h2><p><strong>数据集</strong></p><ol><li>语言网络</li><li>社交网络</li><li>引用网络</li></ol><p><strong>算法比较</strong></p><p>我们没有将LINE算法与无法处理此规模网络的算法进行比较（如MDS,IspMap,Laplacian eigenmap）,而是与一些可以处理大规模网络的几种图嵌入方法进行比较。</p><ul><li>Graph Factorization(GF): 一个信息网络可以被表示为一个相似矩阵（affinity matrix），通过矩阵分解可以得到每个顶点的低维向量表示。图分解算法经过随机梯度下降的优化可以用于处理大规模网络，但它仅应用于无向网络。</li><li>DeepWalk:  DeepWalk是一个近期为社交网络嵌入提出的方法，仅应用于边是二进制的网络。对于每个顶点，使用从顶点开始的截断的随机游走来获得上下文信息，因此仅使用了二阶相似度。</li><li>LINE-SGD: 通过随机梯度下降优化了等式(3)和(6)的LINE模型。该方法中模型更新时取样的边的权重直接与梯度相乘。该方法有两个变量：LINE-SGD(1st)和LINE-SGD(2nd),分别使用了一阶相似度和二阶相似度。</li><li>LINE：经过了边取样处理优化后的LINE模型。在每一个随机梯度下降的步骤，边会根据与权重成比例的可能性被取样，然后取样所得到的边在模型更新中按二进制边处理。与GF类似，LINE(1st)和LINE-SGD(1st)仅应用于无向图。LINE(2nd)和LINE-SGD(2nd)可以应用于有、无向图。</li><li>LINE(1st+2nd): 为了同时利用一阶相似度和二阶相似度，一种简单直接的方法是将通过LINE(1st)和LINE(2nd)学习到的表征向量串联得到一个长向量。串联之后，维度应该被重新加权以平衡两种表征。在一个有监督的学习任务中，维度的权重可以基于训练数据被自动得到。在无监督的学习任务重，很难去设置权重值，因此我们仅将LINE(1st+2nd)应用到有监督任务的场景下。</li></ul><p><strong>参数设置</strong></p><p>所有方法的小批量随机梯度算法（mini-batch SGD）的规模被设置成1。（每次只用总训练集的一小部分来训练，loss的下降更稳定，占用资源更少）。与论文[13]相同，学习速率的初始值被设置成$\rho _0=0.025$且$\rho _t=\rho _0(1-t/T)$.其中$T$是mini-batch或边样本的数量，为了公平的对比，语言网络的嵌入维数设置为200，与单词嵌入时使用的一样。对于其他网络，默认的维数是128，与论文[16]中使用的一样。其他默认设置包含：LINE和LINE-SGD的负样本数量$K=5$。LINE(1st)和LINE(2nd)的样本总数T=100亿，GF的T=200亿，窗口大小win=10,步长t=40。DeepWalk中每个节点的步数$\gamma=40$。所有嵌入向量通过令$||\vec w||_2=1$最终正则化。</p><h2 id="5-2-定量结果"><a href="#5-2-定量结果" class="headerlink" title="5.2 定量结果"></a>5.2 定量结果</h2><h3 id="5-2-1-语言网络"><a href="#5-2-1-语言网络" class="headerlink" title="5.2.1 语言网络"></a>5.2.1 语言网络</h3><p>单词分析和文本分类的应用场景被用于评估学习嵌入的有效性。</p><p>（一）单词分析</p><p><img src="/2019/12/21/graph-embedding-line/word-analogy.png" alt="这里写图片描述"></p><p> 给定单词对$(a,b)$和单词$c$，目标是找到一个$d$使得$ab$之间的关系与$cd$之间的关系是相同的。给定一个单词的嵌入，目标是找到一个单词$d^{*}$，其嵌入与向量$\vec u_b-\vec u_a+\vec u_c$余弦接近。即，$d^{*}=argmax_dcos((\vec u_b - \vec u_a+ \vec u_c), \vec u_d)$。任务中的单词分析包括语义分析和句法分析。表2展示了对维基百科网络应用网络嵌入的单词分析结果。对于GF，单词对之间的权重被定义为共现次数的对数，比直接定位为共现次数的性能表现更好。对于DeepWalk,将语言网络转换为二进制网络过程中尝试使用不同的截断门槛，当所有的边都保留在网络中时能够获得最好的性能。我们还与最先进的单词嵌入模型Skip-Gram做了对比，该模型直接从原始维基百科页面中学习嵌入，也是隐式的矩阵分解方法。窗口大小被设置为5，与创建语言网络时使用的一样。</p><p>我们可以看到LINE(2nd)的表现优于其他方法，包括Skip-Gram。这表示了二阶相似度能够比一阶相似度更好的获取单词语义。这并不意外，高的二阶相似度意味着两个单词能够在同样的上下文中相互替换。意外的是，LINE(2nd)的表现甚至优于在原始文集上训练的最先进的单词嵌入模型（Skip-Gram）。原因可能是语言网络比单词序列能够更好的捕获全局的单词共现结构。其他方法中,GF和LINE(1st)表现显著优于DeepWalk即使Deepwalk拓展了二阶相似度,这可能是因为Deepwalk需要忽略在语言网络中非常重要的边权重。通过SGD优化的LINE模型表现比较差，因为，语言网络的边的权重的偏差范围较大，可能从1-1万，影响了学习进程。使用经过边取样处理优化的LINE模型能够较好处理以上问题，使用了一阶相似度和二阶相似度的表现的尤其好。</p><p>所有的方法都运行在一个单个机器（1T内存，40个20Ghz、16个线程的CPU内核）。LINE(1st)和LINE(2nd)都非常有效，处理2百万节点和十亿条边的网络仅需要不到3个小时。两者都比图分解方法快至少10%，比DeepWalk方法快了5倍。LINE-SGD的速度较慢可以归因于其需要通过阈值切割技术来防止梯度爆炸。</p><p>（二）文件分类</p><p><img src="/2019/12/21/graph-embedding-line/page-classification.png" alt="这里写图片描述"></p><p>另一种评估单词嵌入的质量的方法是使用单词向量去计算文件表征，来评估文件分类任务。为了获取文件表征，由于我们的目标是比较不同单词嵌入方法在文件分类中的应用表现以找到最好的方法，我们选择通过计算文本中所有单词向量表征的均值来简单获取文件的表征。读者们可以在参考文献7中找到先进的文件表征方法。我们下载了维基百科的摘要和分类。我们选择了7个类别应用于分类过程，包括艺术，历史，人文，数学，自然，科技，运动。对于每个目录，我们随机选择了10000文章，并且出去了那些属于多个目录下的文章。我们随机按照不同的百分比来取样已标记的文件用于训练过程中，并将剩下的用于评估。所有的文件向量都用于训练一个使用LibLinear package的一对多的线性回归分类器，我们使用micro-F1和macro-F1作为分类指标，通过对不同的训练数据进行采样，将结果平均在10次不同的运行中。</p><p>表三展示了维基百科页面分类结果。与单词分析任务可以得到相同的结论。由于Deepwalk忽视边的权重，图分解方法比DeepWalk的表现更好。LINE-SGD由于边的权重偏差过大表现较差。经过边取样处理优化后的LINE比直接应用SGD的表现略好。LINE(2nd)表现优于LINE(1st)，且轻微优于图分解。在有监督的学习任务中，将通过LINE(1st)LINE(2nd)学习的嵌入串联起来是可行的。作为结果，LINE(1st)和LINE(2nd)表现显著优于其他方法。这表明了一阶相似度和二阶相似度之间是互补的。</p><p>为了读者能更好的了解一阶相似度和二阶相似度，表4展示了给定单词使用一阶相似度和二阶相似度得到的最相似的单词。我们可以看到，根据上下文相似度，我们使用二阶相似度得到的最相似的单词都是语义相关的单词。而一阶相似度得到的最相似的单词是语义和句法混合相关的单词。</p><p><img src="/2019/12/21/graph-embedding-line/table4.png" alt="这里写图片描述"></p><h3 id="5-2-2-社交网络"><a href="#5-2-2-社交网络" class="headerlink" title="5.2.2 社交网络"></a>5.2.2 社交网络</h3><p>社交网络比语言网络更加稀疏，尤其是Youtube.我们通过多重分类任务（将顶点分配到一个或多个社区）来评估顶点的嵌入。顶点按照不同的百分比被随机取样，并将其余顶点用于评估。结果被平均到10个不同的运行中。<br>（一）Flickr network</p><p><img src="/2019/12/21/graph-embedding-line/table5.png" alt="这里写图片描述"></p><p>我们选取5个最广泛的社区作为多标签分类节点的目录。又一次的，LINE(1st+2nd)表现显著优于其他方法。与语言网络相反的是，LINE(1st)表现略微优于LINE(2nd),原因可能有两个（1）在社会网络中1阶相似度比2阶相似度要更加重要，因为他表示更强的链接，（2）当网络过于稀疏，且节点的邻节点数量平均值较低时，二阶相似度可能会不太准确。LINE(1st)表现优于图分解方法，表示它在建模一阶相似度上具有更好的能力。LINE(2nd)表现优于DeepWalk方法，证明了它在建模二阶相似度上具有更强的能力。根据LINE(1st+2nd)的卓越表现，可以证明两种相似度之间是互补的。<br>（二）Youtube 网络</p><p><img src="/2019/12/21/graph-embedding-line/table6.png" alt="这里写图片描述"></p><p>表6展示了Youtube网络（很稀疏，且平均度数低至5）上的结果。在使用不同百分比的训练数据得到的所有情况下，LINE(1st)表现优于LINE(2nd)，与FLICKR网络中一样。由于其巨大稀疏性，LINE(2nd)的表现低于DeepWalk。但LINE(1st+2nd)的性能不论是在128还是256维度上都表现得很好，证明了两种相似度是互补的。</p><p>Deepwalk 使用截断的随机漫步来应对网络的稀疏性，这种随机漫步类似于深度优先搜索。这样通过引入非直接邻节点来消除稀疏性，可能会导致引入远距离的节点。更可靠的方法是使用广度优先策略来拓展每个节点的邻居。即递归的增加邻居的邻居。为了验证，我们拓展了所有度数低于1000的节点的邻居节点直到它的邻节点的数量达到1000，但这并没有进一步提高性能。</p><p>这样重建的网络的结果在表6中括号中展示。GF, LINE(1st)和LINE(2nd)都得到了提升，尤其是LINE(2nd)。在这个重建网络中，LINE(2nd)在所有情况下的表现都优于DeepWalk.LINE(1st+2nd)在重建后的网络上的表现没有太大的提升。这表示原始网络中的一阶相似度和二阶相似度已经捕获了大部分的原始网络中的信息，更加证明了LINE(1st+2nd)的方法在网络（密集/稀疏）嵌入中非常有效。</p><h3 id="5-2-3-引用网络"><a href="#5-2-3-引用网络" class="headerlink" title="5.2.3 引用网络"></a>5.2.3 引用网络</h3><p>我们在两个引用网络中表示了结果，两个都是有向的。使用一阶相似度的GF和LINE不能应用于有向网络，所以我们只比较了Deepwalk和LINE(2nd).我们还通过多标签分类任务评估了顶点嵌入。我们选择7个流行的会议AAAI, CIKM, ICML, KDD, NIPS,SIGIR, and WWW作为分类的目录。假定在会议中发布的论文或会议中发表的作者属于与会议相对应的类别。<br>（一） DBLP（作者引用）网络<br>表7展示了结果。由于网络非常稀疏，DeepWalk表现优于LINE(2nd).然而通过对度数小于500的顶点递归增加邻节点的邻节点来重建网络，LINE(2nd)的表现得到显著的提升并赶超Deepwalk。直接通过随机梯度下降优化的LINE模型表现并没有像期望一样好。<br>（二）DBLP(论文引用)网络<br> 表8展示了结果，LINE(2nd)表现显著优于DeepWalk。这是因为论文引用网络使用随机漫步只能沿着引用路径寻找论文。（即，更早的论文），而不能到达其他的参考文献。而LINE(2nd)根据论文的引用来表示每个论文的方式更加合理。结合对低度数的节点（度数&lt;200）进行填充处理的重构网络的LINE(2nd)方法具有进一步的性能提升。</p><p><img src="/2019/12/21/graph-embedding-line/table7.png" alt="这里写图片描述"></p><p><img src="/2019/12/21/graph-embedding-line/table8.png" alt="这里写图片描述"></p><h2 id="5-3-网络布局"><a href="#5-3-网络布局" class="headerlink" title="5.3 网络布局"></a>5.3 网络布局</h2><p>我们将网络嵌入到二维空间进行可视化。从DBLP数据中分离了共著网络进行了可视化。我们从三个不同的搜索领域中选取了几个会议，数据挖掘（WWW,KDD），机器学习(NIPS,ICML)，计算机视觉(CVPR,ICCV)。过滤掉度数小于3的节点，最后网络包含18561个作者和207074条边。由于这三个领域非常相近，所以可视化共著者网络的难度较大。首先，我们使用多种嵌入方法把共著者网络映射到低维向量空间，然后进一步把低维向量使用t-SNE方法映射到2D空间中。图2比较了不同嵌入方法的可视化结果，图分解方法的可视化结果没有太大的意义，相同社团的作者并没有聚集在一起。Deepwalk的效果更好一些。然而，许多属于不同社团的作者被紧密聚合在中心区域，其中大多数都是在原网络中具有高度数的顶点。这是因为Deepwalk使用一个基于随机漫步的方法补充顶点的邻居，由于随机性带来了大量的噪声，尤其是在具有更高度数的顶点。LINE(2nd)的表现相当好且产生了有意义的网络布局。（相同颜色的节点分布的更近）</p><p><img src="/2019/12/21/graph-embedding-line/figure2.png" alt="这里写图片描述"></p><h2 id="5-4-网络稀疏与性能相关性"><a href="#5-4-网络稀疏与性能相关性" class="headerlink" title="5.4 网络稀疏与性能相关性"></a>5.4 网络稀疏与性能相关性</h2><p>在该子节中，我们形式化的分析了以上模型性能如何受网络稀疏性影响。我们首先研究了网络稀疏性如何影响LINE(1st)和LINE(2nd)。图3a展示了FLICKR网络下关于连接百分比的结果。我们选择了比Youtube更稠密的FLICKR网络。我们可以看到，刚开始，在网络非常稀疏的情况下，LINE(1st)比LINE(2nd)表现更好，当逐渐增加链路百分比时，LINE(2nd)表现比LINE(1st)更强。这说明了二阶相似度在网络十分稀疏的情况下是表现不良的，但当节点有足够多的邻节点时，表现会优于一阶相似度。图3b展示了在原始Youtube网络和经过重建的Youtube网络上顶点度数的与性能的关系。我们把顶点根据它们度数所在的区间分类到不同目录下(0，1]， [2，3]， [4，6]， [7， 12]，[13，30]，[31，+<img src="https://math.jianshu.com/math?formula=%5Cinfty" alt="\infty">)。然后评估了不同组顶点的性能。总的来说，当节点度数增加时，不同模型的性能也会有所提升。在原始网络中，除了第一组，LINE(2nd)的表现优于LINE(1st)，证明了二阶相似度在度数较低的情况下不能更好的被利用。在重建后的稠密网络。LINE(1st)和LINE(2nd)的性能都优素提升，尤其是保留了二阶相似度的LINE(2nd)。我们还可以看到LINE(2nd)在重建网络上的表现每一组都优于Deepwalk。</p><p><img src="/2019/12/21/graph-embedding-line/figure3.png" alt="这里写图片描述"></p><h2 id="5-5-参数敏感性"><a href="#5-5-参数敏感性" class="headerlink" title="5.5 参数敏感性"></a>5.5 参数敏感性</h2><p>接下来，我们研究了维度d参数与性能的相关性和在重建后的Youtube网络下不同模型的收敛性与样本数量的相关性。图4a记录了LINE模型与维度d的关系。我们可以发现LINE(1st)和LINE(2nd)的性能在维度过大时性能骤减。图4b展示了LINE和Deepwalk与优化过程中的样本数量的相关性。LINE(2nd)表现始终优于LINE(1st)和DeepWalk。LINE(1st)和LINE(2nd)都比Deepwalk的收敛速度要快。</p><p><img src="/2019/12/21/graph-embedding-line/figure4.png" alt="这里写图片描述"></p><h2 id="5-6-可拓展性"><a href="#5-6-可拓展性" class="headerlink" title="5.6 可拓展性"></a>5.6 可拓展性</h2><p>最后我们通过部署多个线程进行优化来研究了LINE模型经过边取样处理和异步梯度下降优化后的LINE模型的可拓展性。。图5a展示了在Youtube数据集上线程数量与速率的关系。关系相当接近于线性关系。图5b展示了在模型更新时使用多个线程下的分类性能保持平稳。这两个图共同展示了LINE模型的推理算法是可拓展的。</p><p><img src="/2019/12/21/graph-embedding-line/figure5.png" alt="这里写图片描述"></p><h1 id="6-结论"><a href="#6-结论" class="headerlink" title="6. 结论"></a>6. 结论</h1><p>本论文研究了一个新颖的网络嵌入模型称为LINE，它精心设计的目标函数是能够保留了一阶相似度和二阶相似度（两者是互补的）。也可以轻松应用于百万节点和上亿边的网络，一个有效的边取样算法被应用于模型推理，在不影响效率的情况下解决了随机梯度下降算法对于边权重的限制。在真实网络上的实验结果展示了LINE的有效性以及效率。未来我们将研究网络中更高级的相似度。此外，我们还将研究含有多种定点类型的异构信息网络上的图嵌入。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Graph Embedding系列的论文翻译解读文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/26/graph-embedding-deepwalk/&quot;&gt;【Graph Embedding】DeepWalk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/21/graph-embedding-line/&quot;&gt;【Graph Embedding】line&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://buracagyang.github.io/2019/12/26/graph-embedding-node2vec/&quot;&gt;【Graph Embedding】node2Vec&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;h1 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h1&gt;&lt;p&gt;paper: &lt;a href=&quot;https://arxiv.org/pdf/1503.03578.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1503.03578.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code: &lt;a href=&quot;https://github.com/tangjianpku/LINE&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/tangjianpku/LINE&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="图计算" scheme="https://buracagyang.github.io/tags/%E5%9B%BE%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Embedding" scheme="https://buracagyang.github.io/tags/Embedding/"/>
    
  </entry>
  
  <entry>
    <title>利用numpy.vectorize提升计算速度</title>
    <link href="https://buracagyang.github.io/2019/09/25/numpy-vectorize/"/>
    <id>https://buracagyang.github.io/2019/09/25/numpy-vectorize/</id>
    <published>2019-09-25T13:23:06.465Z</published>
    <updated>2019-06-12T12:45:42.710Z</updated>
    
    <content type="html"><![CDATA[<hr><p>同步于<a href="https://blog.csdn.net/buracag_mc/article/details/88748607" title="https://blog.csdn.net/buracag_mc/article/details/88748607" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/2019/03/18/increase-calculation-speed-with-numpy-vectorize/" target="_blank" rel="noopener">音尘杂记</a></p><p>在实际项目中，对超大矩阵进行计算或者对超大的DataFrame进行计算是一个经常会出现的场景。这里先不考虑开发机本身内存等客观硬件因素，仅从设计上讨论一下不同实现方式带来的性能差异，抛砖引玉。</p><a id="more"></a><p>项目中有这样一个需求，需要根据历史销量数据计算SKU(Stock Keeping Unit)之间的相似度，或者更通俗一点说是根据历史销量数据求不同SKU之间出现的订单交集以及并集大小(注:SKU数量大概15k左右，订单数大概1000k左右)。</p><p>这里给几条示例数据，可以更直观形象地理解这个需求：</p><p><img src="/2019/09/25/numpy-vectorize/1.png" alt="1"></p><p>然后需要根据这些历史的orderno-sku(订单-商品)数据求解出sku的相似度矩阵。其中SKU1和SKU2之间的相似度定义为:</p><p><img src="/2019/09/25/numpy-vectorize/2.png" alt="2"></p><p>可以很快速地想到几种解决方案：</p><ul><li><p>直接for loops；</p></li><li><p>for loops稍微改进采用列表生成器；</p></li><li><p>采用多进程并行计算；</p></li><li><p><strong>采用numpy.vectorize</strong></p></li></ul><h1 id="1-for-loops计算相似度矩阵"><a href="#1-for-loops计算相似度矩阵" class="headerlink" title="1.for loops计算相似度矩阵"></a>1.for loops计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_for_loops</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    for loops计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    <span class="keyword">del</span> order_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    l = len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    corr_matrix_arr = np.ones((l, l))</span><br><span class="line"></span><br><span class="line">    tbar = trange(l)</span><br><span class="line">    tbar.set_description(<span class="string">"compute corr matrix"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tbar:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, l):</span><br><span class="line">            corr_matrix_arr[j, i] = corr_matrix_arr[i, j] = len(df.iloc[i, <span class="number">1</span>] &amp; df.iloc[j, <span class="number">1</span>]) / len(</span><br><span class="line">                df.iloc[i, <span class="number">1</span>] | df.iloc[j, <span class="number">1</span>])</span><br><span class="line">    corr_matrix_df = pd.DataFrame(columns=sku_series, index=sku_series, data=corr_matrix_arr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> corr_matrix_df</span><br></pre></td></tr></table></figure><p>计算耗时：2000s+<br><img src="/2019/09/25/numpy-vectorize/3.png" alt="3"></p><h1 id="2-list-generator计算相似度矩阵"><a href="#2-list-generator计算相似度矩阵" class="headerlink" title="2.list generator计算相似度矩阵"></a>2.list generator计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_generator</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    列表生成器计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    <span class="keyword">del</span> order_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    l= len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    corr_matrix_arr = np.ones((l, l))</span><br><span class="line"></span><br><span class="line">    l1 = df.orderno</span><br><span class="line">    l2 = np.array(df[<span class="string">'orderno'</span>].apply(len), dtype=np.int8)</span><br><span class="line"></span><br><span class="line">    result_list = [[i, j, len(l1[i] &amp; l1[j])] <span class="keyword">for</span> i <span class="keyword">in</span> range(l)</span><br><span class="line">                   <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, l) <span class="keyword">if</span> len(l1[i] &amp; l1[j]) &gt; <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, j, k <span class="keyword">in</span> result_list:</span><br><span class="line">        corr_matrix_arr[j, i] = corr_matrix_arr[i, j] = k * <span class="number">1.0</span> / (l2[i] + l2[j] - k)</span><br><span class="line">    corr_matrix_df = pd.DataFrame(columns=sku_series, index=sku_series, data=corr_matrix_arr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> corr_matrix_df</span><br></pre></td></tr></table></figure><p>计算耗时：1296s<br><img src="/2019/09/25/numpy-vectorize/4.png" alt="4"></p><h1 id="3-多进程计算相似度矩阵"><a href="#3-多进程计算相似度矩阵" class="headerlink" title="3.多进程计算相似度矩阵"></a>3.多进程计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_multiprocessing</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    多进程计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    <span class="keyword">del</span> order_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    l = len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    </span><br><span class="line">    l1 = df.orderno</span><br><span class="line">    l2 = np.array(df[<span class="string">'orderno'</span>].apply(len), dtype=np.int8)</span><br><span class="line">    <span class="keyword">del</span> df</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    arr2 = np.zeros((l, l), dtype=np.float32)</span><br><span class="line">    pairs = [[i, j] <span class="keyword">for</span> i <span class="keyword">in</span> range(l - <span class="number">1</span>) <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, l)]</span><br><span class="line"></span><br><span class="line">    loops = int(math.ceil((l ** <span class="number">2</span> - l) / <span class="number">10</span> ** <span class="number">6</span> / <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    tbar = trange(loops)</span><br><span class="line">    tbar.set_description(<span class="string">"compute corr matrix"</span>)</span><br><span class="line">    pool = Pool(<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> loop <span class="keyword">in</span> tbar:</span><br><span class="line">        temp_lists = [[i, j, l1[i], l1[j]] <span class="keyword">for</span> i, j <span class="keyword">in</span> pairs[(<span class="number">10</span> ** <span class="number">6</span> * loop): (<span class="number">10</span> ** <span class="number">6</span> * (loop + <span class="number">1</span>))]]</span><br><span class="line">        temp_results = pool.map(cal, temp_lists)</span><br><span class="line">        <span class="keyword">for</span> i, j, k <span class="keyword">in</span> temp_results:</span><br><span class="line">            arr2[i, j] = k</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br><span class="line">    arr1 = l2 + l2.reshape((l, <span class="number">1</span>))</span><br><span class="line">    arr2 = arr2 + arr2.T  <span class="comment"># 变对称阵</span></span><br><span class="line">    arr3 = arr2 / (arr1 - arr2) + np.eye(l)</span><br><span class="line">    <span class="keyword">del</span> arr1</span><br><span class="line">    <span class="keyword">del</span> arr2</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line">    corr_matrix_df = pd.DataFrame(columns=sku_series, index=sku_series, data=arr3)</span><br><span class="line">    <span class="keyword">return</span> corr_matrix_df</span><br></pre></td></tr></table></figure><p>计算耗时：1563s<br><img src="/2019/09/25/numpy-vectorize/5.png" alt="5"></p><h1 id="4-numpy-vectorize计算相似度矩阵"><a href="#4-numpy-vectorize计算相似度矩阵" class="headerlink" title="4.numpy.vectorize计算相似度矩阵"></a>4.numpy.vectorize计算相似度矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_corr_matrix_vectorize</span><span class="params">(order_df)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    numpy.vectorice计算相似度矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    df = order_df.groupby([<span class="string">'sku'</span>]).agg(&#123;<span class="string">'orderno'</span>: <span class="keyword">lambda</span> x: set(x)&#125;).reset_index()</span><br><span class="line">    l = len(df)</span><br><span class="line">    sku_series = df.sku.astype(str)</span><br><span class="line">    arr = df.orderno.values</span><br><span class="line">    corr_matrix_arr = np.zeros((l, l))</span><br><span class="line">    f_vec = np.vectorize(len)</span><br><span class="line">    arr1 = f_vec(arr)</span><br><span class="line"></span><br><span class="line">    tbar = trange(l - <span class="number">1</span>)</span><br><span class="line">    tbar.set_description(<span class="string">"compute corr matrix"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tbar(l - <span class="number">1</span>):</span><br><span class="line">        corr_matrix_arr[i, (i + <span class="number">1</span>): l] = f_vec(arr[(i + <span class="number">1</span>): l] &amp; arr[i])</span><br><span class="line">    corr_matrix_arr1 = np.add.outer(arr1, arr1)</span><br><span class="line">    temp = corr_matrix_arr / (corr_matrix_arr1 - corr_matrix_arr)</span><br><span class="line">    temp = temp + temp.T + np.eye(l)</span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(columns=sku_series, index=sku_series, data=temp)</span><br></pre></td></tr></table></figure><p>计算耗时：72s<br><img src="/2019/09/25/numpy-vectorize/6.png" alt="6"></p><p>可以看到，使用numpy.vectorize提升了20倍左右！</p><p><strong>思考：</strong><br>结合到实际业务中，其实有很多可以改进的地方：1. 并不需要计算所有SKU之间的相似度（提速）; 2. 可以只保存上三角阵或保存有效的相似SKU数据(降低内存)。这块儿就不展开赘述了。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc/article/details/88748607&quot; title=&quot;https://blog.csdn.net/buracag_mc/article/details/88748607&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/2019/03/18/increase-calculation-speed-with-numpy-vectorize/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在实际项目中，对超大矩阵进行计算或者对超大的DataFrame进行计算是一个经常会出现的场景。这里先不考虑开发机本身内存等客观硬件因素，仅从设计上讨论一下不同实现方式带来的性能差异，抛砖引玉。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="Python" scheme="https://buracagyang.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer-数据结构与算法练习题</title>
    <link href="https://buracagyang.github.io/2019/08/26/sword-refers-to-offer/"/>
    <id>https://buracagyang.github.io/2019/08/26/sword-refers-to-offer/</id>
    <published>2019-08-26T08:08:00.000Z</published>
    <updated>2019-08-27T02:30:09.214Z</updated>
    
    <content type="html"><![CDATA[<p>《剑指Offer》中的一些常见练习题，包含二叉树、链表以及其他的一些常见算法练习题；最近又系统性地做了下，大致整理了一下解题思路，均用Python实现，持续更新中…</p><a id="more"></a><h1 id="1-二叉树"><a href="#1-二叉树" class="headerlink" title="1. 二叉树"></a>1. 二叉树</h1><p>首先需要定义好二叉树的结构，后续所有关于二叉树的算法默认其已经定义好对应的树结构，所以在节点处有<code>val</code>、<code>left</code>、<code>right</code>属性。</p><h2 id="1-1-定义树节点"><a href="#1-1-定义树节点" class="headerlink" title="1.1 定义树节点"></a>1.1 定义树节点</h2><p>定义树节点一般如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(x)</span>:</span></span><br><span class="line">self.val = x</span><br><span class="line">        self.left = <span class="literal">None</span></span><br><span class="line">        self.right = <span class="literal">None</span></span><br></pre></td></tr></table></figure><h2 id="1-2-根据序列生成一颗树"><a href="#1-2-根据序列生成一颗树" class="headerlink" title="1.2 根据序列生成一颗树"></a>1.2 根据序列生成一颗树</h2><p>生成树的方法有很多种，通常用到的一般是根据<strong>前序遍历的结果生成树</strong>和<strong>广度优先遍历结果的结果生成树</strong>。</p><ul><li>根据前序遍历的结果生成树：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree_by_list_1</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(arr) &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    val = arr.pop(<span class="number">0</span>)</span><br><span class="line">    root = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> val != <span class="string">"#"</span>:</span><br><span class="line">        <span class="comment"># 先左后右</span></span><br><span class="line">        root = TreeNode(int(val))</span><br><span class="line">        root.left = create_tree_by_list_1(arr)  <span class="comment"># 一直创建左子树，直到遇到"#"</span></span><br><span class="line">        root.right = create_tree_by_list_1(arr)</span><br><span class="line">    <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><ul><li>根据广度优先遍历结果生成树</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree_by_list_2</span><span class="params">(root, arr, i)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> i &lt; len(arr):</span><br><span class="line">        <span class="keyword">if</span> arr[i] == <span class="string">"#"</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            root = TreeNode(arr[i])</span><br><span class="line">            <span class="comment"># 向左递归，创建左子树</span></span><br><span class="line">            root.left = create_tree_by_list_2(root, arr, <span class="number">2</span> * i + <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 向右递归，创建右子树</span></span><br><span class="line">            root.right = create_tree_by_list_2(root, arr, <span class="number">2</span> * i + <span class="number">2</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="1-2-1-二叉树序列化和反序列化"><a href="#1-2-1-二叉树序列化和反序列化" class="headerlink" title="1.2.1 二叉树序列化和反序列化"></a>1.2.1 二叉树序列化和反序列化</h3><p>序列化：将二叉树序列化为一组元素；反序列化：根据一组元素生成一颗二叉树。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serialize</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    按照前序遍历顺序，将二叉树序列化为一组元素</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"#"</span></span><br><span class="line">    <span class="keyword">return</span> str(root.val) + <span class="string">","</span> + serialize(root.left) + <span class="string">","</span> + serialize(root.right)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deserialize</span><span class="params">(s)</span>:</span></span><br><span class="line">    serialized_list = s.split(<span class="string">","</span>)</span><br><span class="line">    <span class="comment"># 根据前序遍历的结果生成树</span></span><br><span class="line">    create_tree_by_list_1(serialized_list)</span><br></pre></td></tr></table></figure><h2 id="1-3-前中后序遍历"><a href="#1-3-前中后序遍历" class="headerlink" title="1.3 前中后序遍历"></a>1.3 前中后序遍历</h2><p>均分为递归实现和非递归实现。</p><h3 id="1-3-1-前序遍历"><a href="#1-3-1-前序遍历" class="headerlink" title="1.3.1 前序遍历"></a>1.3.1 前序遍历</h3><p>前序遍历顺序： root –&gt; left –&gt; right。</p><ul><li>递归实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_order_traversal_1</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    递归实现二叉树前序遍历</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 中左右</span></span><br><span class="line">    result.append(root.val)  <span class="comment"># 需提前定义好全局变量result</span></span><br><span class="line">    pre_order_traversal_1(root.left)</span><br><span class="line">    pre_order_traversal_1(root.right)</span><br></pre></td></tr></table></figure><ul><li>非递归实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_order_traversal_2</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    根据节点入栈出栈进行二叉树前序遍历</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    queue = [root]</span><br><span class="line">    order = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        tmp = queue.pop()</span><br><span class="line">        order.append(tmp.val)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 先进后出，故先将右节点push进行，再push左节点</span></span><br><span class="line">        <span class="keyword">if</span> tmp.right:</span><br><span class="line">            queue.append(tmp.right)</span><br><span class="line">        <span class="keyword">if</span> tmp.left:</span><br><span class="line">            queue.append(tmp.left)</span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h3 id="1-3-2-中序遍历"><a href="#1-3-2-中序遍历" class="headerlink" title="1.3.2 中序遍历"></a>1.3.2 中序遍历</h3><p>中序遍历顺序：left  –&gt; root –&gt;  right。</p><ul><li>递归实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">in_order_traversal_1</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    递归实现二叉树中序遍历</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 左中右</span></span><br><span class="line">    in_order_traversal_1(root.left)</span><br><span class="line">    result.append(root.val)  <span class="comment"># 同样，需要提前定义好全局变量result</span></span><br><span class="line">    in_order_traversal_1(root.right)</span><br></pre></td></tr></table></figure><ul><li>非递归实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">in_order_traversal_2</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    非递归实现二叉树中序遍历</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    order = []</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> order</span><br><span class="line">    queue = []</span><br><span class="line">    cur = root</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> cur <span class="keyword">or</span> len(queue):</span><br><span class="line">        <span class="comment"># 为了获取到最左节点</span></span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            queue.append(cur)</span><br><span class="line">            cur = cur.left</span><br><span class="line">    node = queue.pop()</span><br><span class="line">        order.append(node.val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 一直往上回溯到有右子树的节点，再push进栈中</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> node.right <span class="keyword">and</span> len(queue):</span><br><span class="line">            node = queue.pop()</span><br><span class="line">            order.append(node.val)</span><br><span class="line">        cur = node.right  <span class="comment"># 获取到右节点，对右子树同样进while循环</span></span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h3 id="1-3-3-后序遍历"><a href="#1-3-3-后序遍历" class="headerlink" title="1.3.3 后序遍历"></a>1.3.3 后序遍历</h3><p>后序遍历顺序： left –&gt; right –&gt; root。</p><ul><li>递归实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_order_traversal_1</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    递归实现二叉树后序遍历</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 左右中</span></span><br><span class="line">    post_order_traversal_1(root.left)</span><br><span class="line">    post_order_traversal_1(root.right)</span><br><span class="line">    result.append(root.val)  <span class="comment"># 同样，需要提前定义好全局变量result</span></span><br></pre></td></tr></table></figure><ul><li>非递归实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_order_traversal_2</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    非递归实现二叉树后徐遍历：</span></span><br><span class="line"><span class="string">    将前前序遍历顺序由root--&gt;left--&gt;right更改为root--&gt;right--&gt;left，再将结果转置一下，即得到left--&gt;right--&gt;root</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    queue = [root]</span><br><span class="line">    order = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        tmp = queue.pop()</span><br><span class="line">        order.append(tmp.val)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 先进后出,先左进后右进</span></span><br><span class="line">        <span class="keyword">if</span> tmp.left:</span><br><span class="line">            queue.append(tmp.left)</span><br><span class="line">        <span class="keyword">if</span> tmp.right:</span><br><span class="line">            queue.append(tmp.right)</span><br><span class="line">    order.reverse()</span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h2 id="1-4-BFS-和-DFS"><a href="#1-4-BFS-和-DFS" class="headerlink" title="1.4 BFS 和 DFS"></a>1.4 BFS 和 DFS</h2><h3 id="1-4-1-BFS"><a href="#1-4-1-BFS" class="headerlink" title="1.4.1 BFS"></a>1.4.1 BFS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    queue = [root]  <span class="comment"># 入栈顺序</span></span><br><span class="line">    order = []  <span class="comment"># 遍历顺序</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        tmp = queue.pop(<span class="number">0</span>)</span><br><span class="line">        order.append(tmp.val)</span><br><span class="line">        <span class="comment"># 如果该节点存在对应的左右节点</span></span><br><span class="line">        <span class="keyword">if</span> tmp.left:</span><br><span class="line">            queue(tmp.left)</span><br><span class="line">        <span class="keyword">if</span> tmp.right:</span><br><span class="line">            queue(tmp.right)</span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h3 id="1-4-2-DFS"><a href="#1-4-2-DFS" class="headerlink" title="1.4.2 DFS"></a>1.4.2 DFS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    queue = [root]</span><br><span class="line">    order = []</span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        tmp = queue.pop()</span><br><span class="line">        order.append(tmp.val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 后进先出，所以先pop出来的一直都是最左子树的节点</span></span><br><span class="line">        <span class="keyword">if</span> tmp.right:</span><br><span class="line">            queue.append(tmp.right)</span><br><span class="line">        <span class="keyword">if</span> tmp.left:</span><br><span class="line">            queue.append(tmp.left)</span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h3 id="1-4-3-将二叉树打印成多行"><a href="#1-4-3-将二叉树打印成多行" class="headerlink" title="1.4.3 将二叉树打印成多行"></a>1.4.3 将二叉树打印成多行</h3><p>将二叉树打印成多行，其实就是一个BFS:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_tree</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    queue = [root]</span><br><span class="line">    order = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        <span class="comment"># 获取到当前层的节点数，每个循环只对队列中size个数的节点获取其下属左右节点的操作</span></span><br><span class="line">        size = len(queue)  </span><br><span class="line">        tmp = []</span><br><span class="line">        <span class="comment"># 获取当前栈中的节点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> queue:</span><br><span class="line">            tmp.append(i.val)</span><br><span class="line">        order.append(tmp)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(size):</span><br><span class="line">            node_now = queue.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> node_now.left:</span><br><span class="line">                queue.append(node_now.left)</span><br><span class="line">            <span class="keyword">if</span> node_now.right:</span><br><span class="line">                queue.append(node_now.right)</span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h3 id="1-4-4-将二叉树按”之”字形打印"><a href="#1-4-4-将二叉树按”之”字形打印" class="headerlink" title="1.4.4 将二叉树按”之”字形打印"></a>1.4.4 将二叉树按”之”字形打印</h3><p>按照”之”字形打印二叉树，奇数行从左往右打印，偶数行从右往左打印；方法与1.4.3一样，加一步判断层数的奇偶性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_tree</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    queue = [root]</span><br><span class="line">    order = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        <span class="comment"># 获取到当前层的节点数，每个循环只对队列中size个数的节点获取其下属左右节点的操作</span></span><br><span class="line">        size = len(queue)  </span><br><span class="line">        tmp = []</span><br><span class="line">        <span class="comment"># 获取当前栈中的节点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> queue:</span><br><span class="line">            tmp.append(i.val)</span><br><span class="line">        order.append(tmp)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(size):</span><br><span class="line">            node_now = queue.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> node_now.left:</span><br><span class="line">                queue.append(node_now.left)</span><br><span class="line">            <span class="keyword">if</span> node_now.right:</span><br><span class="line">                queue.append(node_now.right)</span><br><span class="line">    <span class="comment"># 对于树的层数作一下判断</span></span><br><span class="line">    order = [t <span class="keyword">if</span> idx % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> t[::<span class="number">-1</span>] <span class="keyword">for</span> idx, t <span class="keyword">in</span> enumerate(order)]</span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><h2 id="1-5-中序遍历下的下一个节点"><a href="#1-5-中序遍历下的下一个节点" class="headerlink" title="1.5 中序遍历下的下一个节点"></a>1.5 中序遍历下的下一个节点</h2><p>给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。</p><p>考虑如下：</p><ol><li>有右子树的：下一个节点就是其右子树的最左边节点；</li><li>没有右子树的：<br>a. 是父节点的左子节点，那么父节点就是其下一个节点<br>b. 是父节点的右子节点，找他的父节点的父节点的父节点…，<strong>直到当前节点是父节点的左节点，则返回当前节点的父节点</strong>(如果没有,则为尾节点)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_next_node</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. 如果有右子树</span></span><br><span class="line">    <span class="keyword">if</span> root.right:</span><br><span class="line">        node = root.right</span><br><span class="line">        <span class="keyword">while</span> node.left:</span><br><span class="line">            node = node.left</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 如果没有右子树</span></span><br><span class="line">    <span class="keyword">while</span> root.father:</span><br><span class="line">        tmp = root.father</span><br><span class="line">        <span class="keyword">if</span> tmf.left = root:  <span class="comment"># 直到当前节点是父节点的左子节点</span></span><br><span class="line">            <span class="keyword">return</span> tmp</span><br><span class="line">        root = tmp</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h2 id="1-6-二叉树的深-高-度"><a href="#1-6-二叉树的深-高-度" class="headerlink" title="1.6 二叉树的深(高)度"></a>1.6 二叉树的深(高)度</h2><p>输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_depth</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = tree_depth(root.left)</span><br><span class="line">    right = tree_depth(root.right)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> max(left, right) + <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="1-6-1-二叉树最小路径"><a href="#1-6-1-二叉树最小路径" class="headerlink" title="1.6.1 二叉树最小路径"></a>1.6.1 二叉树最小路径</h3><p>与求深度不一样的是，求树是根节点到叶子节点的最小路径长度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tree_min_depth</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = tree_depth(root.left)</span><br><span class="line">    right = tree_depth(root.right)</span><br><span class="line">    <span class="keyword">if</span> left == <span class="number">0</span> <span class="keyword">or</span> right == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> left + right + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> min(left, right) + <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="1-6-2-判断是否是平衡二叉树"><a href="#1-6-2-判断是否是平衡二叉树" class="headerlink" title="1.6.2 判断是否是平衡二叉树"></a>1.6.2 判断是否是平衡二叉树</h3><p>输入一棵二叉树，判断该二叉树是否是平衡二叉树。</p><p>如果左子树和右子树深度相等则是平衡二叉树：<br>a. 遍历每一个节点，根据获取深度的递归函数，根据该节点的左右子树高度差判断是否平衡，然后递归地对左右子树进行判断<br>b. 上述做法有个缺点是，在判断上层节点时，会重复遍历下层节点；如果改为从下往上遍历，如果子树是平衡数，则返回其高度；否则直接停止迭代。</p><ul><li>方法一，从上往下迭代：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_balanced_tree</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> abs(tree_depth(root.left) - tree_depth(root.right) &gt; <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> is_balanced_tree(root.left) <span class="keyword">and</span> is_balanced_tree(root.right)</span><br></pre></td></tr></table></figure><ul><li>方法二，从下往上判断</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_balanced_tree_2</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    从下往上判断，如果子树是平衡数，则返回其高度；否则直接迭代返回False</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> get_depth_of_tree(root) != <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_depth_of_tree</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回-1，代表不是平衡树</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = get_depth_of_tree(root.left)</span><br><span class="line">    <span class="keyword">if</span> left == <span class="number">-1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    right = get_depth_of_tree(root.right)</span><br><span class="line">    <span class="keyword">if</span> right == <span class="number">-1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果子树高度不相等则返回-1，否则返回其树的高度</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span> <span class="keyword">if</span> abs(left - right) &gt; <span class="number">1</span> <span class="keyword">else</span> max(left, right) + <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="1-7-获取二叉树的镜像"><a href="#1-7-获取二叉树的镜像" class="headerlink" title="1.7 获取二叉树的镜像"></a>1.7 获取二叉树的镜像</h2><p>获取二叉树的镜像。根据迭代，不断交换其左右子树即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mirror_of_tree</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 交换其对应的左右节点</span></span><br><span class="line">        root.left, root.right = root.right, root.left</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 递归即可</span></span><br><span class="line">        get_mirror_of_tree(root.left)</span><br><span class="line">        get_mirror_of_tree(root.right)</span><br><span class="line">    <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><h3 id="1-7-1-对称二叉树"><a href="#1-7-1-对称二叉树" class="headerlink" title="1.7.1 对称二叉树"></a>1.7.1 对称二叉树</h3><p>请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> judge_same_tree(root, root)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">judge_same_tree</span><span class="params">(tree1, tree2)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> tree1 <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> tree2 <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> tree1 <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> tree2 <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> tree1.val != tree2.val:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    judge_same_tree(tree1.left, tree2.right) <span class="keyword">and</span> judge_same_tree(tree1.right, tree2.left)</span><br></pre></td></tr></table></figure><h2 id="1-8-根据前序和中序遍历结果重建二叉树"><a href="#1-8-根据前序和中序遍历结果重建二叉树" class="headerlink" title="1.8 根据前序和中序遍历结果重建二叉树"></a>1.8 根据前序和中序遍历结果重建二叉树</h2><p>输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reconstruct_tree</span><span class="params">(pre, tin)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    pre: 前序遍历结果</span></span><br><span class="line"><span class="string">    tin: 中序遍历结果</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    首先根据前序遍历序列中的第一个节点获取到当前树的root节点</span></span><br><span class="line"><span class="string">    再从中序遍历序列中找到root节点对应的idx,该idx以前的便是左子树的节点，以后的便是右子树的节点</span></span><br><span class="line"><span class="string">    递归即可</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pre <span class="keyword">or</span> <span class="keyword">not</span> tin:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    root = TreeNode(pre.pop(<span class="number">0</span>))</span><br><span class="line">    idx = tin.index(root.val)  <span class="comment"># 找到中序遍历结果中对应的idx</span></span><br><span class="line">    root.left = reconstruct_tree(pre, tin[:idx])</span><br><span class="line">    root.right = reconstruct_tree(pre, tin[idx+<span class="number">1</span>:])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><h2 id="1-9-判断子树"><a href="#1-9-判断子树" class="headerlink" title="1.9 判断子树"></a>1.9 判断子树</h2><p>输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(root1, root2)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root1 <span class="keyword">or</span> <span class="keyword">not</span> root2:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 递归考虑root2是否是root1的子树</span></span><br><span class="line">    <span class="keyword">return</span> judge(root1, root2) <span class="keyword">or</span> judge(root1.left, root2) <span class="keyword">or</span> judge(root1.right, root2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">judge</span><span class="params">(main_tree, sub_tree)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> sub_tree:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> main_tree <span class="keyword">or</span> main_tree.val != sub_tree.val:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 同时判断左树和右树是否相同</span></span><br><span class="line">    <span class="keyword">return</span> judge(main_tree.left, sub_tree.left) <span class="keyword">and</span> judge(main_tree.right, sub_tree.right)</span><br></pre></td></tr></table></figure><h2 id="1-10-二叉树判断路径和"><a href="#1-10-二叉树判断路径和" class="headerlink" title="1.10 二叉树判断路径和"></a>1.10 二叉树判断路径和</h2><p>在二叉树中判断路径和是否定于一个数；路径和定义为从root到leaf节点的和；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">has_path_sum</span><span class="params">(root, path_sum)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> root.left <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> root.right <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> root.val == path_sum:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> has_path_sum(root.left, path_sum - root.val) <span class="keyword">or</span> has_path_sum(root.right, path_sum - root.val)</span><br></pre></td></tr></table></figure><h3 id="1-10-1-不一定以root和leaf开头结尾"><a href="#1-10-1-不一定以root和leaf开头结尾" class="headerlink" title="1.10.1 不一定以root和leaf开头结尾"></a>1.10.1 不一定以root和leaf开头结尾</h3><p>统计路径和等于一个数的路径数量；路径不一定以root开头，也不一定以leaf结尾。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">has_path_sum2</span><span class="params">(root, path_sum)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    res = path_sum_start(root, path_sum) + path_sum_start(root.left, path_sum) + path_sum_start(root.right, path_sum)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">path_sum_start</span><span class="params">(root, s)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> root.val == s:</span><br><span class="line">        res += <span class="number">1</span></span><br><span class="line">    res += path_sum_start(root.left, s-root.val) + path_sum_start(root.right, s-root.val)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h1 id="2-二叉搜索树-BST"><a href="#2-二叉搜索树-BST" class="headerlink" title="2. 二叉搜索树(BST)"></a>2. 二叉搜索树(BST)</h1><p>二叉搜索树（BST）：根节点大于等于左子树所有节点，小于等于右子树所有节点。二叉查找树中序遍历有序。</p><h2 id="2-1-二叉树中第k小的节点"><a href="#2-1-二叉树中第k小的节点" class="headerlink" title="2.1 二叉树中第k小的节点"></a>2.1 二叉树中第k小的节点</h2><p>给定一棵二叉搜索树，请找出其中的第k小的结点。例如,(5, 3, 7, 2, 4, 6, 8)中，按结点数值大小顺序第三小结点的值为4。</p><p>对于二叉搜索树，中序遍历顺序就是从小到大排序的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_kth_node</span><span class="params">(root, k)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> result</span><br><span class="line">    result = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获得中序遍历结果</span></span><br><span class="line">    in_order_traversal(root)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> k &gt; len(result) <span class="keyword">or</span> k &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> result[k<span class="number">-1</span>]</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">in_order_traversal</span><span class="params">(root)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 左中右</span></span><br><span class="line">    in_order_traversal(root.left)</span><br><span class="line">    result.append(root.val)</span><br><span class="line">    in_order_traversal(root.right)</span><br></pre></td></tr></table></figure><h1 id="3-其他常见"><a href="#3-其他常见" class="headerlink" title="3. 其他常见"></a>3. 其他常见</h1><h2 id="3-1-双指针-和为S的两个数字"><a href="#3-1-双指针-和为S的两个数字" class="headerlink" title="3.1 [双指针]和为S的两个数字"></a>3.1 [双指针]和为S的两个数字</h2><p>输入一个递增排序的数组和一个数字S，在数组中查找两个数，使得他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。</p><p>左右夹逼，如果和比S小则左边往右挪，如果和比S大则右边往左挪。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sulution</span><span class="params">(array, tsum)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(array) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    end = len(array) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> start &lt; end:</span><br><span class="line">        <span class="keyword">if</span> array[start] + array[end] == tsum:</span><br><span class="line">            <span class="keyword">return</span> [array[start], array[end]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> array[start] + array[end] &lt; tsum:</span><br><span class="line">            start += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> array[start] + array[end] &gt; tsum:</span><br><span class="line">            end -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> []</span><br></pre></td></tr></table></figure><h2 id="3-2-和为S的连续正数序列"><a href="#3-2-和为S的连续正数序列" class="headerlink" title="3.2 和为S的连续正数序列"></a>3.2 和为S的连续正数序列</h2><p>输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序；<br>e.g. 9~16、 18,19,20,21,22的和均为100</p><p>1)由于我们要找的是和为S的连续正数序列，因此这个序列是个公差为1的等差数列，而这个序列的中间值代表了平均值的大小。假设序列长度为n，<br>  那么这个序列的中间值可以通过（S / n）得到，知道序列的中间值和长度，也就不难求出这段序列了。</p><p>2)满足条件的n分两种情况：<br>    n为奇数时，序列中间的数正好是序列的平均值，所以条件为：(n &amp; 1) == 1 &amp;&amp; sum % n == 0；<br>    n为偶数时，序列中间两个数的平均值是序列的平均值，而这个平均值的小数部分为0.5，所以条件为：(sum % n) * 2 == n.</p><p>3)由题可知n &gt;= 2，那么n的最大值是多少呢？我们完全可以将n从2到S全部遍历一次，但是大部分遍历是不必要的。为了让n尽可能大，<br>  我们让序列从1开始，根据等差数列的求和公式：S = (1 + n) * n / 2，得到.</p><p>最后举一个例子，假设输入sum = 100，我们只需遍历n = 13~2的情况（按题意应从大到小遍历），n = 8时，得到序列<br>[9, 10, 11, 12, 13, 14, 15, 16]；n  = 5时，得到序列[18, 19, 20, 21, 22]。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_continuous_sequence</span><span class="params">(tsum)</span>:</span></span><br><span class="line">    ans = []</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(int(math.sqrt(<span class="number">2</span> * tsum)), <span class="number">1</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="comment"># 判定规则</span></span><br><span class="line">        <span class="keyword">if</span> (n % <span class="number">2</span> == <span class="number">1</span> <span class="keyword">and</span> tsum % n == <span class="number">0</span>) <span class="keyword">or</span> ((tsum % n) * <span class="number">2</span> == n):</span><br><span class="line">            result = []</span><br><span class="line">            res_min = int((tsum * <span class="number">1.0</span> / n) - (n - <span class="number">1</span>) * <span class="number">1.0</span> / <span class="number">2</span>)</span><br><span class="line">            res_max = int((tsum * <span class="number">1.0</span> / n) + (n - <span class="number">1</span>) * <span class="number">1.0</span> / <span class="number">2</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(res_min, res_max + <span class="number">1</span>):</span><br><span class="line">                result.append(j)</span><br><span class="line">            ans.append(result)</span><br><span class="line">    <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure><h2 id="3-3-连续子数组的最大和"><a href="#3-3-连续子数组的最大和" class="headerlink" title="3.3 连续子数组的最大和"></a>3.3 连续子数组的最大和</h2><p>计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_greatest_sum_of_sub_array</span><span class="params">(arr)</span>:</span></span><br><span class="line">    max_sum, cur_sum = <span class="number">-1000000</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果当前的和已经小于0，直接将当前元素值赋给cur_sum</span></span><br><span class="line">        <span class="keyword">if</span> cur_sum &lt;= <span class="number">0</span>:</span><br><span class="line">            cur_sum = i</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cur_sum += i</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cur_sum &gt; max_sum:</span><br><span class="line">            max_sum = cur_sum</span><br><span class="line">    <span class="keyword">return</span> max_sum</span><br></pre></td></tr></table></figure><h2 id="3-4-最小的K个数"><a href="#3-4-最小的K个数" class="headerlink" title="3.4 最小的K个数"></a>3.4 最小的K个数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_least_numbers</span><span class="params">(array, k)</span>:</span></span><br><span class="line">    <span class="comment"># 用前k个初始化</span></span><br><span class="line">    least_numbers_list = array[:k]</span><br><span class="line">    <span class="comment"># 标记一个最大值</span></span><br><span class="line">    max_n = max(least_numbers_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> array[k:]:</span><br><span class="line">        <span class="comment"># 只要找个一个比最大值小的，就替换掉</span></span><br><span class="line">        <span class="keyword">if</span> n &lt; max_n:</span><br><span class="line">            least_numbers_list.remove(max_n)  </span><br><span class="line">            least_numbers_list.append(n)</span><br><span class="line">            max_n = max(least_numbers_list)</span><br><span class="line"></span><br><span class="line">    least_numbers_list.sort()</span><br><span class="line">    <span class="keyword">return</span> least_numbers_list</span><br></pre></td></tr></table></figure><h2 id="3-5-二进制中1的个数"><a href="#3-5-二进制中1的个数" class="headerlink" title="3.5 二进制中1的个数"></a>3.5 二进制中1的个数</h2><p>输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">number_of1</span><span class="params">(n)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 如果为负数</span></span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">0</span>:</span><br><span class="line">        n = n &amp; <span class="number">0xffffffff</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> n != <span class="number">0</span>:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        n = n &amp; (n<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> count</span><br></pre></td></tr></table></figure><h2 id="3-6-调整数组顺序使奇数位于偶数前面"><a href="#3-6-调整数组顺序使奇数位于偶数前面" class="headerlink" title="3.6 调整数组顺序使奇数位于偶数前面"></a>3.6 调整数组顺序使奇数位于偶数前面</h2><p><strong>题目描述</strong></p><p>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，<br>所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。</p><p><strong>思路</strong></p><p>要保证奇数和奇数、偶数和偶数之间的相对位置不变。故只能对调或者顺次移动</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(array)</span>:</span></span><br><span class="line">    <span class="comment"># 相对位置不能变，故只能对调或者顺次移动</span></span><br><span class="line">    array_len = len(array)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(array_len):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(array_len<span class="number">-1</span>, i, <span class="number">-1</span>):</span><br><span class="line">            <span class="comment"># 如果前偶数后奇数就对调其位置</span></span><br><span class="line">            <span class="keyword">if</span> array[j] % <span class="number">2</span> == <span class="number">1</span> <span class="keyword">and</span> array[j<span class="number">-1</span>] % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                temp = array[j<span class="number">-1</span>]</span><br><span class="line">                array[j<span class="number">-1</span>] = array[j]</span><br><span class="line">                array[j] = temp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> array</span><br></pre></td></tr></table></figure><h2 id="3-7-孩子们的游戏-圆圈中最后剩下的人"><a href="#3-7-孩子们的游戏-圆圈中最后剩下的人" class="headerlink" title="3.7 孩子们的游戏(圆圈中最后剩下的人)"></a>3.7 孩子们的游戏(圆圈中最后剩下的人)</h2><p>每年六一儿童节,牛客都会准备一些小礼物去看望孤儿院的小朋友,今年亦是如此。HF作为牛客的资深元老,自然也准备了一些小游戏。<br>其中,有个游戏是这样的:首先,让小朋友们围成一个大圈。然后,他随机指定一个数m,让编号为0的小朋友开始报数。每次喊到m-1的那个小朋友<br>要出列唱首歌,然后可以在礼品箱中任意的挑选礼物,并且不再回到圈中,从他的下一个小朋友开始,继续0…m-1报数….这样下去….直到<br>剩下最后一个小朋友,可以不用表演,并且拿到牛客名贵的“名侦探柯南”典藏版(名额有限哦!!^_^)。请你试着想下,哪个小朋友会得到这份礼<br>品呢？(注：小朋友的编号是从0到n-1)</p><p>2.3 数学推理：<br>假设在N0=N的时候，第一次出列的孩子在队列中序号为K，那么这个孩子出列后，剩余N-1个孩子的序号是<br>0,1,2….K-1, K+1,K+2,….N-1，这个序列要调整成N-K-1,N-K,N-K+1,…N-2, 0, 1, …,N-K-2，主要变化在：<br>原来的K+1到N-1的每个序号减去（K+1），因为原来K+1的序号变成了0，原来的N-1就就变成了（N-1）-(K+1)=N-K-2,<br>那么原来的0的序号变成了（N-K-1），那么原来的0到K-1的每个序号加上（N-K-1），因此原来的0变成了（N-K-1）。</p><p>数学规律总结：设置变化前有N个元素，出列小孩序号为K，那么K=（M-1）%N，设置剩余小孩调整前原始序号为X，<br>那么重新调整后，新序号为f（X）=（X-K-1）% N,将K值带入：f(X)=X0=(X-(M-1)%N-1)%N=(X-M)%N,<br>那么已知X0新序号推原序号就是X=（X0+M）% N</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(n, m)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> (solution(n<span class="number">-1</span>, m) + m) % n</span><br></pre></td></tr></table></figure><h2 id="3-8-二维数组中的查找"><a href="#3-8-二维数组中的查找" class="headerlink" title="3.8 二维数组中的查找"></a>3.8 二维数组中的查找</h2><p>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p><p>可以从右上角开始查找，如果：</p><ul><li>如果数组中的值大于target,则列数减1</li><li>如果数组中的值小于target,则行数加1</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(target, array)</span>:</span></span><br><span class="line">    row = len(array) - <span class="number">1</span></span><br><span class="line">    col = len(array[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    r = <span class="number">0</span></span><br><span class="line">    c = col</span><br><span class="line">    <span class="keyword">while</span> r &lt;= row <span class="keyword">and</span> c &gt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> array[r][c] &lt;= target:</span><br><span class="line">            r += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> array[r][c] &gt;= target:</span><br><span class="line">            c -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="3-9-旋转数组的最小数字"><a href="#3-9-旋转数组的最小数字" class="headerlink" title="3.9 旋转数组的最小数字"></a>3.9 旋转数组的最小数字</h2><p><strong>题目描述</strong></p><p>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。</p><p><strong>思路</strong></p><p>因为是一个非递减排序数组的一个旋转，所以从头到尾开始遍历，遇到第一个不满足递增规则的，如5–&gt;1，则返回1即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(rotate_array)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(rotate_array) &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    res = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> rotate_array:</span><br><span class="line">        <span class="keyword">if</span> num &lt; res:</span><br><span class="line">            <span class="keyword">return</span> num</span><br><span class="line">        res = num</span><br></pre></td></tr></table></figure><h2 id="3-10-顺时针打印矩阵"><a href="#3-10-顺时针打印矩阵" class="headerlink" title="3.10 顺时针打印矩阵"></a>3.10 顺时针打印矩阵</h2><p><strong>题目描述</strong></p><p>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵：<br>$$<br>\begin {pmatrix}<br>1, 2, 3, 4 \\<br>5, 6, 7, 8 \\<br>9, 10, 11, 12 \\<br>13, 14, 15, 16<br>\end {pmatrix}<br>$$<br>则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.</p><p><strong>思路</strong></p><p>依次打印出：</p><p>1: 1, 2, 3, 4</p><p>2: 8, 12, 16</p><p>3: 13, 14, 15</p><p>4: 9, 5</p><p>5: 6, 7</p><p>6: 11</p><p>7: 10</p><p>每次只打印矩阵的第0行，再打印矩阵的第0行后将矩阵按照逆时针旋转90度，然后再打印矩阵的第0行。重复进行下去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(matrix)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先将矩阵的第0行打印出来</span></span><br><span class="line">    <span class="keyword">while</span> matrix:</span><br><span class="line">        result.append(matrix[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> matrix:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 将矩阵按照逆时针旋转90度</span></span><br><span class="line">        matrix = translate_matrix(matrix)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate_matrix</span><span class="params">(m)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将矩阵按照逆时针旋转90度</span></span><br><span class="line"><span class="string">    :param m: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    row = len(m)</span><br><span class="line">    col = len(m[<span class="number">0</span>])</span><br><span class="line">    translated_m = []</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(col):</span><br><span class="line">        tmp = []</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> range(row):</span><br><span class="line">            tmp.append(m[r][c])</span><br><span class="line">        translated_m.append(tmp)</span><br><span class="line">    translated_m.reverse()</span><br><span class="line">    <span class="keyword">return</span> translated_m</span><br></pre></td></tr></table></figure><h2 id="3-11-数组中出现次数超过一半的数字"><a href="#3-11-数组中出现次数超过一半的数字" class="headerlink" title="3.11 数组中出现次数超过一半的数字"></a>3.11 数组中出现次数超过一半的数字</h2><p><strong>题目描述</strong></p><p>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。<br>由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。</p><p><strong>思路</strong></p><ol><li>‘分治法’，先将第一个数字设置为1，下一个数字如果相同，则加1；否则减1，如果次数为0；则将下一个数字次数置换成1</li><li>先找出出现次数最多的数字</li><li>再判定其出现次数是否大于数组长度的一半</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    <span class="comment"># ‘分治法’，先将第一个数字设置为1，下一个数字如果相同，则加1；否则减1，如果次数为0；则将下一个数字次数置换成1</span></span><br><span class="line">    result = numbers[<span class="number">0</span>]</span><br><span class="line">    t = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先找出出现次数最多的数字</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(numbers)):</span><br><span class="line">        <span class="keyword">if</span> t == <span class="number">0</span>:</span><br><span class="line">            result = numbers[i]</span><br><span class="line">            t = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> numbers[i] == result:</span><br><span class="line">            t += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            t -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 再判定其出现次数是否大于数组长度的一半</span></span><br><span class="line">    t = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(numbers)):</span><br><span class="line">        <span class="keyword">if</span> numbers[i] == result:</span><br><span class="line">            t += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> t &gt; len(numbers) / <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">else</span>:</span><br></pre></td></tr></table></figure><h2 id="3-12-将数组排成最小的数"><a href="#3-12-将数组排成最小的数" class="headerlink" title="3.12 将数组排成最小的数"></a>3.12 将数组排成最小的数</h2><p><strong>题目描述</strong></p><p>输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。<br>例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。</p><p><strong>思路</strong><br>对list内的数据进行排序，按照 将a和b转为string后<br>若 int(str(a) + str(b) &lt; str(b) + str(a)) ， 则a在前,<br>如 [‘2’, ‘21’]因为212 &lt; 221 所以排序后为[‘21’, ‘2’]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在python3中,需要用functools中的cmp_to_key方法进行转换</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> cmp_to_key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution_on_py3</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> numbers:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">    lmb = <span class="keyword">lambda</span> n1, n2: int(str(n1) + str(n2)) - int(str(n2) + str(n1))</span><br><span class="line">    numbers.sort(key=cmp_to_key(lmb))</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join([str(i) <span class="keyword">for</span> i <span class="keyword">in</span> numbers])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># python2中sorted方法可以有cmp参数，但是在python3中不行</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution_on_py2</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> numbers:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">    lmb = <span class="keyword">lambda</span> n1, n2: int(str(n1) + str(n2)) - int(str(n2) + str(n1))</span><br><span class="line">    array = sorted(numbers, cmp=lmb)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join([str(i) <span class="keyword">for</span> i <span class="keyword">in</span> array])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    input_l = [<span class="string">'3'</span>, <span class="string">'32'</span>, <span class="string">'321'</span>]</span><br><span class="line">    print(solution_on_py3(input_l))</span><br></pre></td></tr></table></figure><h2 id="3-13-丑数"><a href="#3-13-丑数" class="headerlink" title="3.13 丑数"></a>3.13 丑数</h2><p><strong>题目描述</strong></p><p>把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。</p><p><strong>思路</strong></p><p>穷举法：对于因子2,3,5都维护一个index值；每次append丑数列表中的丑数由如下规则确定：</p><ol><li>初始化2,3,5对应的index_list均为[0],[0],[0]</li><li>在丑数列表中找到2,3,5对应index对应的元素值 * 2/3/5</li><li>分别判定除以2， 3， 5对应的余数是否为0，如果为0，则对应2,3,5的indxe值加1，例如对于6这个丑数，2和3对应的index值均加上了1</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(index)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> index &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 丑数列表中第一个为0；后续的丑数递增地添加进list中</span></span><br><span class="line">    ugly_list = [<span class="number">1</span>]</span><br><span class="line">    index_two = <span class="number">0</span></span><br><span class="line">    index_three = <span class="number">0</span></span><br><span class="line">    index_five = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(index - <span class="number">1</span>):</span><br><span class="line">        new_ugly = min(ugly_list[index_two] * <span class="number">2</span>, ugly_list[index_three] * <span class="number">3</span>, ugly_list[index_five] * <span class="number">5</span>)</span><br><span class="line">        ugly_list.append(new_ugly)</span><br><span class="line">        <span class="comment"># 判断添加的丑数是2,3,5中哪个因子的倍数，同时对应的index加上1</span></span><br><span class="line">        <span class="keyword">if</span> new_ugly % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            index_two += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> new_ugly % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">            index_three += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> new_ugly % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            index_five += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> ugly_list[<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><h2 id="3-14-数组中只出现一次的数字"><a href="#3-14-数组中只出现一次的数字" class="headerlink" title="3.14 数组中只出现一次的数字"></a>3.14 数组中只出现一次的数字</h2><p><strong>题目描述</strong></p><p>一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。</p><p><strong>思路</strong></p><p>如果问题简化为1个数出现在两个集合A,B中，则其并集 - 交集所得结果便是只出现在集合A或只出现在集合B中的元素。</p><p>所以不断二分递归下去，直到集合中只有一个元素，然后再对两个集合做这个操作，最终会将出现两次的数据消除掉，只剩下出现一次的数字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(array)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> list(dc(array, <span class="number">0</span>, len(array)<span class="number">-1</span>))</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dc</span><span class="params">(arr, start, end)</span>:</span></span><br><span class="line">    res = set()</span><br><span class="line">    <span class="keyword">if</span> start &gt; end:</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">if</span> start == end:</span><br><span class="line">        <span class="keyword">return</span> set(arr[start:end+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    mid = (start + end) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 不断二分递归</span></span><br><span class="line">    s1 = dc(arr, start, mid)</span><br><span class="line">    s2 = dc(arr, mid+<span class="number">1</span>, end)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 并集 - 交集</span></span><br><span class="line">    <span class="keyword">return</span> s1.union(s2).difference(s1.intersection(s2))</span><br></pre></td></tr></table></figure><h2 id="3-15-数组中的重复数字"><a href="#3-15-数组中的重复数字" class="headerlink" title="3.15 数组中的重复数字"></a>3.15 数组中的重复数字</h2><p><strong>题目描述</strong></p><p>在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。</p><p><strong>思路</strong><br>如果数组元素与将该元素作为idx, 在位于该idx的元素是否相等，如果不相等则做一下交换；<br>如果相等，则返回这个元素，说明这是一个重复数字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">duplicate</span><span class="params">(numbers, duplication)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(numbers)):</span><br><span class="line">        <span class="keyword">if</span> numbers[i] != i:  <span class="comment"># 如果元素值不等于其idx</span></span><br><span class="line">            temp = numbers[numbers[i]]  <span class="comment"># 取得numbers[numbers[i] 的元素</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果numbers[i]与 numbers[numbers[i]]相等，说明已经重复，则直接返回这个数字</span></span><br><span class="line">            <span class="keyword">if</span> temp == numbers[i]:</span><br><span class="line">                duplication[<span class="number">0</span>] = numbers[i]</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果不相等则交换</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                numbers[numbers[i]] = numbers[i]</span><br><span class="line">                numbers[i] = temp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="3-16-构建乘积数组"><a href="#3-16-构建乘积数组" class="headerlink" title="3.16 构建乘积数组"></a>3.16 构建乘积数组</h2><p><strong>题目描述</strong></p><p>给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0]<em>A[1]</em>…<em>A[i-1]</em>A[i+1]<em>…</em>A[n-1]。不能使用除法。</p><p><strong>思路</strong></p><p>下三角用连乘可以很容求得，上三角，从下向上也是连乘。</p><p>因此我们的思路就很清晰了，先算下三角中的连乘，即我们先算出B[i]中的一部分，然后倒过来按上三角中的分布规律，把另一部分也乘进去。<br>$$<br>\begin{bmatrix}<br>1, A_1, A_2, …, A_{n-2}, A_{n-1} \\<br>A_0, 1, A_2, …, A_{n-2}, A_{n-1} \\<br>A_0, A_2, 1, …, A_{n-2}, A_{n-1} \\<br>… \\<br>A_0, A_1, A_2, …, 1, A_{n-1} \\<br>A_0, A_1, A_2, …, A_{n-2}, 1 \\<br>\end{bmatrix}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(A)</span>:</span></span><br><span class="line">    leng = len(A)</span><br><span class="line">    <span class="keyword">if</span> leng &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    B = [<span class="number">1</span>] * leng</span><br><span class="line">    B[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算下三角</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, leng):</span><br><span class="line">        B[i] = B[i<span class="number">-1</span>] * A[i<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算上三角</span></span><br><span class="line">    temp = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(leng<span class="number">-2</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        temp *= A[j+<span class="number">1</span>]</span><br><span class="line">        B[j] *= temp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> B</span><br></pre></td></tr></table></figure><h2 id="3-17-字符流中第一个不重复的字符"><a href="#3-17-字符流中第一个不重复的字符" class="headerlink" title="3.17 字符流中第一个不重复的字符"></a>3.17 字符流中第一个不重复的字符</h2><p><strong>题目描述</strong></p><p>请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符”go”时，第一个只出现一次的字符是”g”。当从该字符流中读出前六个符“google”时，第一个只出现一次的字符是”l”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.s = <span class="string">""</span></span><br><span class="line">        self.dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 得到第一个只出现一次的字符</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_first_appear_str</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> self.s:</span><br><span class="line">            <span class="keyword">if</span> self.dict[s] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> s</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"#"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, char)</span>:</span></span><br><span class="line">        self.s += char</span><br><span class="line">        <span class="keyword">if</span> char <span class="keyword">in</span> self.dict:</span><br><span class="line">            self.dict[char] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.dict[char] = <span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="4-链表"><a href="#4-链表" class="headerlink" title="4. 链表"></a>4. 链表</h1><h2 id="4-1-双指针-链表中倒数第k个节点"><a href="#4-1-双指针-链表中倒数第k个节点" class="headerlink" title="4.1 [双指针]链表中倒数第k个节点"></a>4.1 [双指针]链表中倒数第k个节点</h2><p>输入一个链表，输出该链表中倒数第k个结点。</p><p>可以用两个指针：p1 和 p2<br>    先让p1跑k-1个节点，然后让p2开始跑；当p1跑到最后一个节点时，p2对应的节点就是倒数第k个节点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(head, k)</span>:</span></span><br><span class="line">    p1 = head</span><br><span class="line">    p2 = head</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    node_count = <span class="number">0</span>  <span class="comment"># 记录一下节点数，如果节点数小于k值，则返回空值</span></span><br><span class="line">    <span class="keyword">while</span> p1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p1 = p1.next</span><br><span class="line">        node_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i &gt;= k:</span><br><span class="line">            p2 = p2.next</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> node_count &lt; k:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> p2</span><br></pre></td></tr></table></figure><h2 id="4-2-反转链表"><a href="#4-2-反转链表" class="headerlink" title="4.2 反转链表"></a>4.2 反转链表</h2><p>输入一个链表，反转链表后，输出新链表的表头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(pHead)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pHead <span class="keyword">or</span> pHead.next <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> pHead</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先定义last节点是None</span></span><br><span class="line">    last = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">while</span> pHead:</span><br><span class="line">        temp = pHead.next  <span class="comment"># 首先获取到当前节点的下一个节点，存储下来</span></span><br><span class="line">        pHead.next = last  <span class="comment"># 对于当前的头节点，反转过后其next节点就是None</span></span><br><span class="line">        last = pHead  <span class="comment"># 将当前节点赋值给last</span></span><br><span class="line">        pHead = temp  <span class="comment"># 将下一个节点赋给pHead</span></span><br><span class="line">    <span class="keyword">return</span> last</span><br></pre></td></tr></table></figure><h2 id="4-3-两个链表的第一个公共节点"><a href="#4-3-两个链表的第一个公共节点" class="headerlink" title="4.3 两个链表的第一个公共节点"></a>4.3 两个链表的第一个公共节点</h2><p>输入两个链表，找出它们的第一个公共结点。</p><p>当访问 A 链表的指针访问到链表尾部时，令它从链表 B 的头部开始访问链表 B；(a+b)<br>同样地，当访问 B 链表的指针访问到链表尾部时，令它从链表 A 的头部开始访问链表 A。(b+a)<br>这样就能控制访问 A 和 B 两个链表的指针能同时访问到交点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(pHead1, pHead2)</span>:</span></span><br><span class="line">    l1 = pHead1</span><br><span class="line">    l2 = pHead2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> l1 != l2:</span><br><span class="line">        l1 = pHead2 <span class="keyword">if</span> l1.next <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> l1.next</span><br><span class="line">        l2 = pHead1 <span class="keyword">if</span> l2.next <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> l2.next</span><br><span class="line">    <span class="keyword">return</span> l1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution2</span><span class="params">(pHead1, pHead2)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    先保存链表1的节点，再遍历链表2，如果在链表1中出现，则返回跳出循环。否则返回None</span></span><br><span class="line"><span class="string">    :param pHead1:</span></span><br><span class="line"><span class="string">    :param pHead2:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    l = []</span><br><span class="line">    <span class="keyword">while</span> pHead1:</span><br><span class="line">        l.append(pHead1)</span><br><span class="line">        pHead1 = pHead1.next</span><br><span class="line">    <span class="keyword">while</span> pHead2:</span><br><span class="line">        <span class="keyword">if</span> pHead2 <span class="keyword">in</span> l:</span><br><span class="line">            <span class="keyword">return</span> pHead2</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        pHead2 = pHead2.next</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h2 id="4-4-合并两个排序的链表"><a href="#4-4-合并两个排序的链表" class="headerlink" title="4.4 合并两个排序的链表"></a>4.4 合并两个排序的链表</h2><p>输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(pHead1, pHead2)</span>:</span></span><br><span class="line">    <span class="comment"># 可以挨个合并，递归可以解决这个问题</span></span><br><span class="line">    <span class="keyword">if</span> pHead1 <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> pHead2</span><br><span class="line">    <span class="keyword">if</span> pHead2 <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> pHead1</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pHead1.val &lt;= pHead2.val:</span><br><span class="line">        pHead1.next = solution(pHead1.next, pHead2)</span><br><span class="line">        <span class="keyword">return</span> pHead1</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pHead2.next = solution(pHead1, pHead2.next)</span><br><span class="line">        <span class="keyword">return</span> pHead2</span><br></pre></td></tr></table></figure><h2 id="4-5-复杂链表的复制"><a href="#4-5-复杂链表的复制" class="headerlink" title="4.5 复杂链表的复制"></a>4.5 复杂链表的复制</h2><p><strong>题目描述</strong></p><p>输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.label = x</span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line">        self.random = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iter_node</span><span class="params">(node)</span>:</span></span><br><span class="line">    <span class="comment"># 迭代返回node的下一个节点</span></span><br><span class="line">    <span class="keyword">while</span> node:</span><br><span class="line">        <span class="keyword">yield</span> node</span><br><span class="line">        node = node.next</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clone_list</span><span class="params">(p_head)</span>:</span></span><br><span class="line">    mem = dict()</span><br><span class="line">    <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(iter_node(p_head)):</span><br><span class="line">        mem[id(n)] = i</span><br><span class="line">    lst = [RandomListNode(n.label) <span class="keyword">for</span> n <span class="keyword">in</span> iter_node(p_head)]  <span class="comment"># copy a new list</span></span><br><span class="line">    <span class="keyword">for</span> t, f <span class="keyword">in</span> zip(iter_node(p_head), lst):</span><br><span class="line">        <span class="comment"># 如果该节点有next节点，则获取到next节点的id，再从mem中根据id找到对应的节点</span></span><br><span class="line">        <span class="keyword">if</span> t.next:  </span><br><span class="line">            f.next = lst[mem[id(t.next)]]</span><br><span class="line">        <span class="comment"># 如果该节点有random节点，则获取到random节点的id，再从mem中根据id找到对应的节点</span></span><br><span class="line">        <span class="keyword">if</span> t.random:</span><br><span class="line">            f.random = lst[mem[id(t.random)]]</span><br><span class="line">    <span class="keyword">return</span> lst[<span class="number">0</span>] <span class="keyword">if</span> lst <span class="keyword">else</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h2 id="4-6-二叉搜索树与双向链表"><a href="#4-6-二叉搜索树与双向链表" class="headerlink" title="4.6 二叉搜索树与双向链表"></a>4.6 二叉搜索树与双向链表</h2><p><strong>题目描述</strong></p><p>输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">node_list</span><span class="params">(root_of_tree)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    得到其中序遍历结果</span></span><br><span class="line"><span class="string">    :param root_of_tree:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root_of_tree:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    <span class="keyword">return</span> node_list(root_of_tree.left) + [root_of_tree] + node_list(root_of_tree)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span><span class="params">(root_of_tree)</span>:</span></span><br><span class="line">    res = node_list(root_of_tree)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(res) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(res) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> root_of_tree</span><br><span class="line">    res[<span class="number">0</span>].left = <span class="literal">None</span></span><br><span class="line">    res[<span class="number">0</span>].right = res[<span class="number">1</span>]</span><br><span class="line">    res[<span class="number">-1</span>].left = res[<span class="number">-2</span>]</span><br><span class="line">    res[<span class="number">-1</span>].right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(res)<span class="number">-1</span>):</span><br><span class="line">        res[i].left = res[i<span class="number">-1</span>]</span><br><span class="line">        res[i].right = res[i+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> res[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h2 id="4-7-链表中环的入口节点"><a href="#4-7-链表中环的入口节点" class="headerlink" title="4.7 链表中环的入口节点"></a>4.7 链表中环的入口节点</h2><p><strong>题目描述</strong></p><p>给一个链表，若其中包含环，请找出该链表的环的入口结点，否则，输出null。</p><p><strong>思路</strong></p><p>有两个：</p><ol><li><p>遍历整个链表，将节点缓存起来，第一个重复的节点就是环的入口(时间、空间复杂度都是O(n));</p></li><li><p>第二个方法相对比较复杂：</p><p>a. 如果将环抽象为如下形式，从链表起点A开始，经过环的入口B，假设从A–&gt;B的距离为x;</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A -----&gt; B ------&gt; C</span><br><span class="line">         ^         |</span><br><span class="line">         |         |</span><br><span class="line">         |         |</span><br><span class="line">         &lt;----------</span><br></pre></td></tr></table></figure><p>b. 假设快指针fast一次移动2步，慢指针一次移动1步，当快慢指针在环中的C点相遇时，假设整个环B–&gt;C–&gt;B的距离为c；从环的入口B到环中相遇节点C的距离为a.</p><p>c. 可以得到如下信息，</p><p>slow = x + n*c + a（n代表慢指针走过了n次环）</p><p>fast = x + m*c + a（m代表快指针走过了m次环）</p><p>有：</p><p>2 * slow = fast ==&gt; x = (m-2n)c - a ==&gt; x = (m-2n-1)c + c - a</p><p>什么意思呢，即A–&gt;B的距离 = 数个环的长度(可能为0) + c - a(即相遇点C继续走到B的距离) </p><p>d. 所以，可以再让一个指针从起点A开始走，让一个指针从相遇点C开始继续往后走，2个指针速度一样，那么两个指针的相遇点一定到达环的入口点。时间复杂度为O(n)， 空间复杂度为O(1)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution1</span><span class="params">(p_head)</span>:</span></span><br><span class="line">    temp_list = []</span><br><span class="line">    p = p_head</span><br><span class="line">    <span class="keyword">while</span> p:</span><br><span class="line">        <span class="keyword">if</span> p <span class="keyword">in</span> temp_list:</span><br><span class="line">            <span class="keyword">return</span> p</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            temp_list.append(p)</span><br><span class="line">        p = p.next</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution2</span><span class="params">(p_head)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> p_head <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> p_head.next <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> p_head.next.next <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    fast = p_head.next.next  <span class="comment"># 2 steps</span></span><br><span class="line">    slow = p_head.next  <span class="comment"># 1 step</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先判断是否存在环</span></span><br><span class="line">    <span class="keyword">while</span> fast != slow:</span><br><span class="line">        <span class="keyword">if</span> fast.next <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> fast.next.next <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            fast = fast.next.next</span><br><span class="line">            slow = slow.next</span><br><span class="line">        <span class="comment"># 如果没有环则返回None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果存在环</span></span><br><span class="line">    fast = p_head  <span class="comment"># 一个指针从起点开始，另一个指针还是从相遇点开始</span></span><br><span class="line">    <span class="keyword">while</span> fast != slow:</span><br><span class="line">        fast = fast.next</span><br><span class="line">        slow = slow.next</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> slow</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;《剑指Offer》中的一些常见练习题，包含二叉树、链表以及其他的一些常见算法练习题；最近又系统性地做了下，大致整理了一下解题思路，均用Python实现，持续更新中…&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】模型选择和调优</title>
    <link href="https://buracagyang.github.io/2019/08/09/spark-ml-tuning/"/>
    <id>https://buracagyang.github.io/2019/08/09/spark-ml-tuning/</id>
    <published>2019-08-09T03:22:42.000Z</published>
    <updated>2019-08-12T08:01:24.107Z</updated>
    
    <content type="html"><![CDATA[<p>翻译自：<a href="http://spark.apache.org/docs/2.3.2/ml-tuning.html" target="_blank" rel="noopener">http://spark.apache.org/docs/2.3.2/ml-tuning.html</a></p><p>介绍如何使用MLlib的工具来调整ML算法和Pipelines。 内置的交叉验证和其他工具允许用户优化算法和pipelines中的超参数。</p><a id="more"></a><h1 id="1-模型选择-亦称-超参数调优"><a href="#1-模型选择-亦称-超参数调优" class="headerlink" title="1. 模型选择(亦称 超参数调优)"></a>1. 模型选择(亦称 超参数调优)</h1><p>ML中的一项重要任务是模型选择，或使用数据来查找给定任务的最佳模型或参数。这也称为调整。可以针对单个estimator（例如LogisticRegression）或针对包括多个算法，特征化和其他步骤的整个pipeline进行调整。用户可以一次调整整个pipeline，而不是分别调整管道中的每个元素。</p><p>MLlib支持使用CrossValidator和TrainValidationSplit等工具进行模型选择。这些工具需要以下项目：</p><ul><li>Estimator：算法或pipeline调整</li><li>一组ParamMaps：可供选择的参数，有时也称为“参数网格”(“parameter grid”)来搜索</li><li>评估器：衡量拟合模型对保持测试数据的效果的度量标准</li></ul><p>从较高的层面来看，这些模型选择工具的工作原理如下：</p><ul><li>他们将输入数据分成单独的训练和测试数据集。</li><li>对于每个（训练，测试）对，他们遍历ParamMaps集合：<ul><li>对于每个ParamMap，它们使用这些参数拟合Estimator，获得拟合的模型，并使用Evaluator评估模型的性能。</li></ul></li><li>他们选择由性能最佳的参数组生成的模型。</li></ul><p>Evaluator可以是回归问题的RegressionEvaluator，二进制数据的BinaryClassificationEvaluator，或多类问题的MulticlassClassificationEvaluator。 用于选择最佳ParamMap的默认度量标准可以由每个评估程序中的setMetricName方法覆盖。</p><p>为了帮助构造参数网格，用户可以使用ParamGridBuilder。 默认情况下，参数网格中的参数集将按顺序进行评估。 在使用CrossValidator或TrainValidationSplit运行模型选择之前，可以通过设置值为2或更大的并行度（值为1是船型的）来并行完成参数评估。 应谨慎选择并行度的值，以在不超出群集资源的情况下最大化并行性，并且较大的值可能并不总是导致性能提高。 一般来说，对于大多数集群而言，高达10的值应该足够了。</p><h1 id="2-交叉验证"><a href="#2-交叉验证" class="headerlink" title="2. 交叉验证"></a>2. 交叉验证</h1><p>CrossValidator首先将数据集拆分为一组folds，这些folds用作单独的训练和测试数据集。例如，当k = 3倍时，CrossValidator将生成3个（训练，测试）数据集对，每个数据集对使用2/3的数据进行训练，1/3进行测试。为了评估特定的ParamMap，CrossValidator通过在3个不同（训练，测试）数据集对上拟合Estimator来计算3个模型的平均评估度量。</p><p>在确定最佳ParamMap之后，CrossValidator最终使用最佳ParamMap和整个数据集重新拟合Estimator。</p><p><strong>示例</strong>：通过交叉验证选择模型</p><p>以下示例演示如何使用CrossValidator从参数网格中进行选择。</p><p>请注意，通过参数网格进行交叉验证非常昂贵。例如，在下面的示例中，参数网格具有3个hashingTF.numFeatures值和2个lr.regParam值，CrossValidator使用2个折叠。这乘以（3×2）×2 = 12个正在训练的不同模型。在实际设置中，通常可以尝试更多参数并使用更多折叠（k = 3和k = 10是常见的）。换句话说，使用CrossValidator可能非常昂贵。然而，它也是一种成熟的方法，用于选择比启发式手动调整更具统计学意义的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/9 11:50</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : cross_validator.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> BinaryClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.tuning <span class="keyword">import</span> CrossValidator, ParamGridBuilder</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"CrossValidatorExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    training = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="string">"a b c d e spark"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">"b d"</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">"spark f g h"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">3</span>, <span class="string">"hadoop mapreduce"</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="string">"b spark who"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">5</span>, <span class="string">"g d a y"</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">6</span>, <span class="string">"spark fly"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">7</span>, <span class="string">"was mapreduce"</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">8</span>, <span class="string">"e spark program"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">9</span>, <span class="string">"a e c l"</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">10</span>, <span class="string">"spark compile"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">11</span>, <span class="string">"hadoop software"</span>, <span class="number">0.0</span>)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"label"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 配置一个ML pipeline</span></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">"features"</span>)</span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>)</span><br><span class="line">    pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    CrossValidator需要Estimator，ParamMaps和一个Evaluator。</span></span><br><span class="line"><span class="string">    Estimator: 将Pipeline视为Estimator，将其包装在CrossValidator实例中。允许我们选择所有Pipeline阶段的参数。</span></span><br><span class="line"><span class="string">    ParamMaps: 使用ParamGridBuilder构建一个要搜索的参数网格。hasingTF.numFeatures有3个值，lr.regParam有2个值，总计6个参数。</span></span><br><span class="line"><span class="string">    Evaluator: BinaryClassificationEvaluator</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    paramGrid = ParamGridBuilder().\</span><br><span class="line">        addGrid(hashingTF.numFeatures, [<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]).\</span><br><span class="line">        addGrid(lr.regParam, [<span class="number">0.1</span>, <span class="number">0.01</span>]).\</span><br><span class="line">        build()</span><br><span class="line"></span><br><span class="line">    crossval = CrossValidator(estimator=pipeline,</span><br><span class="line">                              estimatorParamMaps=paramGrid,</span><br><span class="line">                              evaluator=BinaryClassificationEvaluator(),</span><br><span class="line">                              numFolds=<span class="number">2</span>)  <span class="comment"># 通常都使用3+折交叉验证</span></span><br><span class="line"></span><br><span class="line">    cvModel = crossval.fit(training)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备一个test set</span></span><br><span class="line">    test = spark.createDataFrame([</span><br><span class="line">        (<span class="number">4</span>, <span class="string">"spark i j k"</span>),</span><br><span class="line">        (<span class="number">5</span>, <span class="string">"l m n"</span>),</span><br><span class="line">        (<span class="number">6</span>, <span class="string">"mapreduce spark"</span>),</span><br><span class="line">        (<span class="number">7</span>, <span class="string">"test hadoop"</span>)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"text"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用cvModel 寻找到的最优模型</span></span><br><span class="line">    prediction = cvModel.transform(test)</span><br><span class="line">    selected = prediction.select(<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"probability"</span>, <span class="string">"prediction"</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> selected.collect():</span><br><span class="line">        print(row)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Row(id=4, text=u<span class="string">'spark i j k'</span>, probability=DenseVector([0.1702, 0.8298]), prediction=1.0)</span><br><span class="line">Row(id=5, text=u<span class="string">'l m n'</span>, probability=DenseVector([0.6476, 0.3524]), prediction=0.0)</span><br><span class="line">Row(id=6, text=u<span class="string">'mapreduce spark'</span>, probability=DenseVector([0.425, 0.575]), prediction=1.0)</span><br><span class="line">Row(id=7, text=u<span class="string">'test hadoop'</span>, probability=DenseVector([0.6753, 0.3247]), prediction=0.0)</span><br></pre></td></tr></table></figure><h1 id="3-训练集-验证集划分"><a href="#3-训练集-验证集划分" class="headerlink" title="3. 训练集-验证集划分"></a>3. 训练集-验证集划分</h1><p>除了CrossValidator之外，Spark还提供TrainValidationSplit用于超参数调整。</p><p>与CrossValidator一样，TrainValidationSplit最终使用最佳ParamMap和整个数据集来拟合Estimator。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/9 12:56</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : train_validation_split.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.tuning <span class="keyword">import</span> ParamGridBuilder, TrainValidationSplit</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"TrainValidationSplit"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    train, test = data.randomSplit([<span class="number">0.9</span>, <span class="number">0.1</span>], seed=<span class="number">2019</span>)</span><br><span class="line"></span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 同样构建参数网络</span></span><br><span class="line">    paramGrid = ParamGridBuilder()\</span><br><span class="line">        .addGrid(lr.regParam, [<span class="number">0.1</span>, <span class="number">0.01</span>]) \</span><br><span class="line">        .addGrid(lr.fitIntercept, [<span class="literal">False</span>, <span class="literal">True</span>])\</span><br><span class="line">        .addGrid(lr.elasticNetParam, [<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">1.0</span>])\</span><br><span class="line">        .build()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 80%的数据运来进行训练， 20%的数据用于验证</span></span><br><span class="line">    tvs = TrainValidationSplit(estimator=lr,</span><br><span class="line">                               estimatorParamMaps=paramGrid,</span><br><span class="line">                               evaluator=RegressionEvaluator(),</span><br><span class="line">                               trainRatio=<span class="number">0.8</span>)</span><br><span class="line">    model = tvs.fit(train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对测试数据进行测试</span></span><br><span class="line">    model.transform(test).select(<span class="string">"features"</span>, <span class="string">"label"</span>, <span class="string">"prediction"</span>).show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+----------+</span><br><span class="line">|            features|label|prediction|</span><br><span class="line">+--------------------+-----+----------+</span><br><span class="line">|(692,[121,122,123...|  0.0|       0.0|</span><br><span class="line">|(692,[124,125,126...|  0.0|       0.0|</span><br><span class="line">|(692,[124,125,126...|  0.0|       0.0|</span><br><span class="line">|(692,[124,125,126...|  0.0|       0.0|</span><br><span class="line">|(692,[150,151,152...|  0.0|       0.0|</span><br><span class="line">|(692,[153,154,155...|  0.0|       0.0|</span><br><span class="line">|(692,[154,155,156...|  0.0|       0.0|</span><br><span class="line">|(692,[154,155,156...|  0.0|       0.0|</span><br><span class="line">|(692,[123,124,125...|  1.0|       1.0|</span><br><span class="line">|(692,[124,125,126...|  1.0|       1.0|</span><br><span class="line">+--------------------+-----+----------+</span><br><span class="line">only showing top 10 rows</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;翻译自：&lt;a href=&quot;http://spark.apache.org/docs/2.3.2/ml-tuning.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://spark.apache.org/docs/2.3.2/ml-tuning.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;介绍如何使用MLlib的工具来调整ML算法和Pipelines。 内置的交叉验证和其他工具允许用户优化算法和pipelines中的超参数。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】频繁项集挖掘</title>
    <link href="https://buracagyang.github.io/2019/08/09/spark-frequent-pattern-mining/"/>
    <id>https://buracagyang.github.io/2019/08/09/spark-frequent-pattern-mining/</id>
    <published>2019-08-09T02:32:02.000Z</published>
    <updated>2019-08-09T02:45:07.859Z</updated>
    
    <content type="html"><![CDATA[<p>挖掘频繁项目，项目集，子序列或其他子结构通常是分析大规模数据集的第一步，这是数据挖掘多年来一直活跃的研究课题。 可以参考一下维基百科中关于<a href="http://en.wikipedia.org/wiki/Association_rule_learning" target="_blank" rel="noopener">关联规则学习</a>的基础知识。</p><a id="more"></a><h1 id="1-FP-Growth"><a href="#1-FP-Growth" class="headerlink" title="1. FP-Growth"></a>1. FP-Growth</h1><p>FP-growth算法在<a href="https://dl.acm.org/citation.cfm?doid=335191.335372" target="_blank" rel="noopener">Han等人的文章</a>中描述，挖掘频繁模式而没有候选生成，其中“FP”代表频繁模式。 给定数据集，FP-growth的第一步是计算项目频率并识别频繁项目。 与为同一目的而设计的类似Apriori的算法不同，FP-growth的第二步使用后缀树（FP-tree）结构来编码事务而不显式生成候选集，这通常很难生成。 在第二步之后，可以从FP-tree中提取频繁项集。 在spark.mllib中，我们实现了称为PFP的FP-growth的分布式版本，如Li等人，在<a href="https://dl.acm.org/citation.cfm?doid=1454008.1454027" target="_blank" rel="noopener">PFP：Parallel FP-growth for query recommendation</a>中所述。 PFP基于事务的后缀分配增长FP-tree的工作，因此比单机实现更具可扩展性。</p><p>spark.ml的FP-growth实现采用以下（超）参数：</p><ul><li>minSupport：对项目集进行频繁识别的最低支持。例如，如果一个项目出现在5个交易中的3个中，则它具有3/5 = 0.6的支持。</li><li>minConfidence：生成关联规则的最小置信度。置信度表明关联规则经常被发现的频率。例如，如果在交易项目集X中出现4次，X和Y仅出现2次，则规则X =&gt; Y的置信度则为2/4 = 0.5。该参数不会影响频繁项集的挖掘，但会指定从频繁项集生成关联规则的最小置信度。</li><li>numPartitions：用于并行工作的分区数。默认情况下，不设置参数，并使用输入数据集的分区数。</li></ul><p>FPGrowthModel提供：</p><ul><li>freqItemsets：DataFrame格式的频繁项集（“items”[Array]，“freq”[Long]）</li><li>associationRules：以高于minConfidence的置信度生成的关联规则，格式为DataFrame（“antecedent”[Array]，“consequent”[Array]，“confidence”[Double]）。</li><li>transform：对于itemsCol中的每个事务，transform方法将其项目与每个关联规则的前提进行比较。如果记录包含特定关联规则的所有前提，则该规则将被视为适用，并且其结果将被添加到预测结果中。变换方法将所有适用规则的结果总结为预测。预测列与itemsCol具有相同的数据类型，并且不包含itemsCol中的现有项。</li></ul><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/9 10:40</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : fpgrowth_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.fpm <span class="keyword">import</span> FPGrowth</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"FPGrowthExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>]),</span><br><span class="line">        (<span class="number">1</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>]),</span><br><span class="line">        (<span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"items"</span>])</span><br><span class="line"></span><br><span class="line">    fpGrowth = FPGrowth(itemsCol=<span class="string">"items"</span>, minSupport=<span class="number">0.5</span>, minConfidence=<span class="number">0.6</span>)</span><br><span class="line">    model = fpGrowth.fit(df)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 频繁项集</span></span><br><span class="line">    model.freqItemsets.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成的关联规则</span></span><br><span class="line">    model.associationRules.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># transform根据所有关联规则检查输入项，并将结果作为预测</span></span><br><span class="line">    model.transform(df).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">+---------+----+</span><br><span class="line">|    items|freq|</span><br><span class="line">+---------+----+</span><br><span class="line">|      [1]|   3|</span><br><span class="line">|      [2]|   3|</span><br><span class="line">|   [2, 1]|   3|</span><br><span class="line">|      [5]|   2|</span><br><span class="line">|   [5, 2]|   2|</span><br><span class="line">|[5, 2, 1]|   2|</span><br><span class="line">|   [5, 1]|   2|</span><br><span class="line">+---------+----+</span><br><span class="line"></span><br><span class="line">+----------+----------+------------------+</span><br><span class="line">|antecedent|consequent|        confidence|</span><br><span class="line">+----------+----------+------------------+</span><br><span class="line">|    [5, 2]|       [1]|               1.0|</span><br><span class="line">|    [2, 1]|       [5]|0.6666666666666666|</span><br><span class="line">|    [5, 1]|       [2]|               1.0|</span><br><span class="line">|       [5]|       [2]|               1.0|</span><br><span class="line">|       [5]|       [1]|               1.0|</span><br><span class="line">|       [1]|       [2]|               1.0|</span><br><span class="line">|       [1]|       [5]|0.6666666666666666|</span><br><span class="line">|       [2]|       [1]|               1.0|</span><br><span class="line">|       [2]|       [5]|0.6666666666666666|</span><br><span class="line">+----------+----------+------------------+</span><br><span class="line"></span><br><span class="line">+---+------------+----------+</span><br><span class="line">| id|       items|prediction|</span><br><span class="line">+---+------------+----------+</span><br><span class="line">|  0|   [1, 2, 5]|        []|</span><br><span class="line">|  1|[1, 2, 3, 5]|        []|</span><br><span class="line">|  2|      [1, 2]|       [5]|</span><br><span class="line">+---+------------+----------+</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;挖掘频繁项目，项目集，子序列或其他子结构通常是分析大规模数据集的第一步，这是数据挖掘多年来一直活跃的研究课题。 可以参考一下维基百科中关于&lt;a href=&quot;http://en.wikipedia.org/wiki/Association_rule_learning&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;关联规则学习&lt;/a&gt;的基础知识。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】协同过滤</title>
    <link href="https://buracagyang.github.io/2019/08/08/spark-collaborative-filtering/"/>
    <id>https://buracagyang.github.io/2019/08/08/spark-collaborative-filtering/</id>
    <published>2019-08-08T10:09:07.000Z</published>
    <updated>2019-08-08T11:51:25.633Z</updated>
    
    <content type="html"><![CDATA[<p>协同过滤通常用于推荐系统。这些技术旨在根据user-item关联矩阵的缺失条目。 spark.ml目前支持基于模型的协同过滤，其中users和items由一小组可用于预测缺失条目的潜在因子（latent factors）描述。 spark.ml使用交替最小二乘（ALS）算法来学习这些潜在因素。 spark.ml中的实现具有以下参数：</p><ul><li>numBlocks，是users和items将被分区为多个块的数量，以便并行化计算（默认为10）。</li><li>rank，是模型中潜在因子（latent factors）的数量（默认为10）。</li><li>maxIter，是要运行的最大迭代次数（默认为10）。</li><li>regParam，指定ALS中的正则化参数（默认为1.0）。</li><li>implicitPrefs，指定是使用显式反馈ALS变体还是使用适用于隐式反馈数据的（默认为false，这意味着使用显式反馈）。</li><li>alpha，是适用于ALS的隐式反馈变量的参数，其控制偏好观察中的基线置信度（默认为1.0）。</li><li>nonnegative，指定是否对最小二乘使用非负约束（默认为false）。</li></ul><a id="more"></a><p><strong>注意：</strong>基于DataFrame的ALS API目前仅支持整数类型的user和item ID。 </p><h1 id="1-显式和隐式反馈"><a href="#1-显式和隐式反馈" class="headerlink" title="1. 显式和隐式反馈"></a>1. 显式和隐式反馈</h1><p>基于矩阵分解的协同过滤的标准方法将user-item矩阵中的数据视为user对item给出的显式偏好，例如，给予电影评级的用户。</p><p>在许多现实世界的用例中，通常只能访问隐式反馈（例如，观看，点击，购买，喜欢，分享等）。 spark.ml中用于处理此类数据的方法取自<a href="https://ieeexplore.ieee.org/document/4781121/" target="_blank" rel="noopener">Collaborative Filtering for Implicit Feedback Datasets</a>。 本质上，这种方法不是试图直接对评级矩阵进行建模，而是将数据视为表示用户操作观察强度的数字（例如点击次数或某人花在观看电影上的累积持续时间）。 然后，这些数字与观察到的用户偏好的置信水平相关，而不是与item的明确评级相关。 然后，该模型试图找到可用于预测user对item的预期偏好的潜在因素。</p><h1 id="2-正则化参数的缩放"><a href="#2-正则化参数的缩放" class="headerlink" title="2. 正则化参数的缩放"></a>2. 正则化参数的缩放</h1><p>我们通过用户在更新用户因素（user factors）时产生的评级数或在更新产品因素（product factors）时收到的产品评级数来缩小正则化参数regParam以解决每个最小二乘问题。 这种方法被命名为“ALS-WR”，并在“<a href="http://dx.doi.org/10.1007/978-3-540-68880-8_32" target="_blank" rel="noopener">Large-Scale Parallel Collaborative Filtering for the Netflix Prize</a>”一文中进行了讨论。 它使regParam较少依赖于数据集的规模，因此我们可以将从采样子集中学习的最佳参数应用于完整数据集，并期望获得类似的性能。</p><h1 id="3-冷启动的策略"><a href="#3-冷启动的策略" class="headerlink" title="3. 冷启动的策略"></a>3. 冷启动的策略</h1><p>在使用ALSModel进行预测时，通常会遇到测试数据集中的user或者item在训练模型期间不存在。这通常发生在两种情况中：</p><ol><li>在生产中，对于没有评级历史且未对模型进行过训练的新user或item（这是“冷启动问题”）。</li><li>在交叉验证期间，数据在训练和评估集之间分配。当使用Spark的CrossValidator或TrainValidationSplit中的简单随机拆分时，实际上很常见的是在评估集中遇到不在训练集中的user 或 item。</li></ol><p>默认情况下，当模型中不存在user or item factors时，Spark会在ALSModel.transform期间分配NaN预测。这在生产系统中很有用，因为它表示新用户或项目，因此系统可以决定使用某些后备作为预测。</p><p>但是，这在交叉验证期间是不合需要的，因为任何NaN预测值都将导致评估指标的NaN结果（例如，使用RegressionEvaluator时）。这使得模型选择不可能。</p><p>Spark允许用户将coldStartStrategy参数设置为“drop”，以便删除包含NaN值的预测的DataFrame中的任何行。然后将根据非NaN数据计算评估度量并且该评估度量将是有效的。以下示例说明了此参数的用法。</p><p><strong>注意：</strong>目前支持的冷启动策略是“nan”（上面提到的默认行为）和“drop”。将来可能会支持更多的策略。</p><p>在以下示例中，我们从MovieLens数据集加载评级数据，每行包含用户，电影，评级和时间戳。 然后我们训练一个ALS模型，默认情况下假设评级是显式的（implicitPrefs是False）。 我们通过测量评级预测的均方根误差来评估推荐模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/8 19:40</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : als_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"ALSExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    lines = spark.read.text(<span class="string">"../data/mllib/als/sample_movielens_ratings.txt"</span>).rdd</span><br><span class="line">    parts = lines.map(<span class="keyword">lambda</span> row: row.value.split(<span class="string">"::"</span>))</span><br><span class="line">    ratingsRDD = parts.map(<span class="keyword">lambda</span> p: Row(userId=int(p[<span class="number">0</span>]), movieId=int(p[<span class="number">1</span>]), rating=float(p[<span class="number">2</span>]), timestamp=long(p[<span class="number">3</span>])))</span><br><span class="line">    ratings = spark.createDataFrame(ratingsRDD)</span><br><span class="line">    (training, test) = ratings.randomSplit([<span class="number">0.8</span>, <span class="number">0.2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 冷启动策略使用"drop"，不对NaN进行评估</span></span><br><span class="line">    als = ALS(maxIter=<span class="number">5</span>, regParam=<span class="number">0.01</span>, userCol=<span class="string">"userId"</span>, itemCol=<span class="string">"movieId"</span>, ratingCol=<span class="string">"rating"</span>,</span><br><span class="line">              coldStartStrategy=<span class="string">"drop"</span>)</span><br><span class="line">    model = als.fit(training)</span><br><span class="line"></span><br><span class="line">    predictions = model.transform(test)</span><br><span class="line">    evaluator = RegressionEvaluator(metricName=<span class="string">"rmse"</span>, labelCol=<span class="string">"rating"</span>, predictionCol=<span class="string">"prediction"</span>)</span><br><span class="line">    rmse = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Root-mean-square error = "</span> + str(rmse))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对每个用户推荐top 10的movie</span></span><br><span class="line">    userRecs = model.recommendForAllUsers(<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 对每部电影推荐top 10的user</span></span><br><span class="line">    movieRecs = model.recommendForAllItems(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为指定的用户组推荐top 10的电影</span></span><br><span class="line">    users = ratings.select(als.getUserCol()).distinct().limit(<span class="number">3</span>)</span><br><span class="line">    userSubsetRecs = model.recommendForUserSubset(users, <span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 为指定的电影组推荐top 10的用户</span></span><br><span class="line">    movies = ratings.select(als.getItemCol()).distinct().limit(<span class="number">3</span>)</span><br><span class="line">    movieSubSetRecs = model.recommendForItemSubset(movies, <span class="number">10</span>)</span><br><span class="line">    userRecs.show(<span class="number">10</span>)</span><br><span class="line">    movieRecs.show(<span class="number">10</span>)</span><br><span class="line">    userSubsetRecs.show()</span><br><span class="line">    movieSubSetRecs.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">Root-mean-square error = 1.65962683297</span><br><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|    28|[[92, 4.7627287],...|</span><br><span class="line">|    26|[[22, 5.353035], ...|</span><br><span class="line">|    27|[[75, 4.7605653],...|</span><br><span class="line">|    12|[[12, 5.364489], ...|</span><br><span class="line">|    22|[[51, 5.1232195],...|</span><br><span class="line">|     1|[[34, 6.5673475],...|</span><br><span class="line">|    13|[[93, 3.92995], [...|</span><br><span class="line">|     6|[[25, 5.123874], ...|</span><br><span class="line">|    16|[[85, 5.03955], [...|</span><br><span class="line">|     3|[[51, 4.974762], ...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">+-------+--------------------+</span><br><span class="line">|movieId|     recommendations|</span><br><span class="line">+-------+--------------------+</span><br><span class="line">|     31|[[28, 3.4169104],...|</span><br><span class="line">|     85|[[16, 5.03955], [...|</span><br><span class="line">|     65|[[23, 4.9267926],...|</span><br><span class="line">|     53|[[23, 6.9966245],...|</span><br><span class="line">|     78|[[24, 1.1653752],...|</span><br><span class="line">|     34|[[1, 6.5673475], ...|</span><br><span class="line">|     81|[[11, 4.0272694],...|</span><br><span class="line">|     28|[[18, 4.8363395],...|</span><br><span class="line">|     76|[[14, 4.6251163],...|</span><br><span class="line">|     26|[[12, 4.3116484],...|</span><br><span class="line">+-------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|    26|[[22, 5.353035], ...|</span><br><span class="line">|    19|[[98, 3.8704958],...|</span><br><span class="line">|    29|[[30, 4.1840963],...|</span><br><span class="line">+------+--------------------+</span><br><span class="line"></span><br><span class="line">+-------+--------------------+</span><br><span class="line">|movieId|     recommendations|</span><br><span class="line">+-------+--------------------+</span><br><span class="line">|     65|[[23, 4.9267926],...|</span><br><span class="line">|     26|[[12, 4.3116484],...|</span><br><span class="line">|     29|[[8, 4.954544], [...|</span><br><span class="line">+-------+--------------------+</span><br></pre></td></tr></table></figure><p>如果评级矩阵是从另一个信息源派生的（即从其他信号推断出来），您可以将implicitPrefs设置为True以获得更好的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">als = ALS(maxIter=<span class="number">5</span>, regParam=<span class="number">0.01</span>, implicitPrefs=<span class="literal">True</span>, userCol=<span class="string">"userId"</span>, itemCol=<span class="string">"movieId"</span>, ratingCol=<span class="string">"rating"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;协同过滤通常用于推荐系统。这些技术旨在根据user-item关联矩阵的缺失条目。 spark.ml目前支持基于模型的协同过滤，其中users和items由一小组可用于预测缺失条目的潜在因子（latent factors）描述。 spark.ml使用交替最小二乘（ALS）算法来学习这些潜在因素。 spark.ml中的实现具有以下参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;numBlocks，是users和items将被分区为多个块的数量，以便并行化计算（默认为10）。&lt;/li&gt;
&lt;li&gt;rank，是模型中潜在因子（latent factors）的数量（默认为10）。&lt;/li&gt;
&lt;li&gt;maxIter，是要运行的最大迭代次数（默认为10）。&lt;/li&gt;
&lt;li&gt;regParam，指定ALS中的正则化参数（默认为1.0）。&lt;/li&gt;
&lt;li&gt;implicitPrefs，指定是使用显式反馈ALS变体还是使用适用于隐式反馈数据的（默认为false，这意味着使用显式反馈）。&lt;/li&gt;
&lt;li&gt;alpha，是适用于ALS的隐式反馈变量的参数，其控制偏好观察中的基线置信度（默认为1.0）。&lt;/li&gt;
&lt;li&gt;nonnegative，指定是否对最小二乘使用非负约束（默认为false）。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】聚类分析</title>
    <link href="https://buracagyang.github.io/2019/08/08/spark-clustering/"/>
    <id>https://buracagyang.github.io/2019/08/08/spark-clustering/</id>
    <published>2019-08-08T07:36:07.000Z</published>
    <updated>2019-08-08T10:08:35.578Z</updated>
    
    <content type="html"><![CDATA[<p>本节主要讲Spark ML中关于聚类算法的实现。示例的算法Demo包含：K-means、LDA、高斯混合模型(GMM)等。</p><a id="more"></a><h1 id="1-K-means"><a href="#1-K-means" class="headerlink" title="1. K-means"></a>1. K-means</h1><p>KMeans作为Estimator实现，并生成KMeansModel作为基本模型。</p><h2 id="1-1-输入"><a href="#1-1-输入" class="headerlink" title="1.1 输入"></a>1.1 输入</h2><table><thead><tr><th style="text-align:center">Param name</th><th style="text-align:center">Type(s)</th><th style="text-align:center">Default</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center">featuresCol</td><td style="text-align:center">Vector</td><td style="text-align:center">“features”</td><td style="text-align:center">Feature vector</td></tr></tbody></table><h2 id="1-2-输出"><a href="#1-2-输出" class="headerlink" title="1.2 输出"></a>1.2 输出</h2><table><thead><tr><th style="text-align:center">Param name</th><th style="text-align:center">Type(s)</th><th style="text-align:center">Default</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center">predictionCol</td><td style="text-align:center">Int</td><td style="text-align:center">“prediction”</td><td style="text-align:center">Predicted cluster center</td></tr></tbody></table><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/8 15:52</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : kmeans_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> ClusteringEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"KMeansExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_kmeans_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    kmeans = KMeans().setK(<span class="number">2</span>).setSeed(<span class="number">1</span>)</span><br><span class="line">    model = kmeans.fit(dataset)</span><br><span class="line"></span><br><span class="line">    predictions = model.transform(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过计算Silhouette得分来评估聚类</span></span><br><span class="line">    evaluator = ClusteringEvaluator()</span><br><span class="line">    silhouette = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Silhouette with squared euclidean distance = "</span> + str(silhouette))</span><br><span class="line"></span><br><span class="line">    centers = model.clusterCenters()</span><br><span class="line">    print(<span class="string">"Cluster Centers: "</span>)</span><br><span class="line">    <span class="keyword">for</span> center <span class="keyword">in</span> centers:</span><br><span class="line">        print(center)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Silhouette with squared euclidean distance = 0.999753030538</span><br><span class="line">Cluster Centers: </span><br><span class="line">[0.1 0.1 0.1]</span><br><span class="line">[9.1 9.1 9.1]</span><br></pre></td></tr></table></figure><h1 id="2-隐狄利克雷分布-Latent-Dirichlet-Allocation-LDA"><a href="#2-隐狄利克雷分布-Latent-Dirichlet-Allocation-LDA" class="headerlink" title="2. 隐狄利克雷分布(Latent Dirichlet Allocation, LDA)"></a>2. 隐狄利克雷分布(Latent Dirichlet Allocation, LDA)</h1><p>LDA实现支持EMLDAOptimizer和OnlineLDAOptimizer的Estimator，并生成LDAModel作为基本模型。 如果需要，用户可以将EMLDAOptimizer生成的LDAModel转换为DistributedLDAModel。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/8 15:57</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : lda_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> LDA</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"LDAExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_lda_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    lda = LDA(k=<span class="number">10</span>, maxIter=<span class="number">10</span>)</span><br><span class="line">    model = lda.fit(dataset)</span><br><span class="line"></span><br><span class="line">    ll = model.logLikelihood(dataset)</span><br><span class="line">    lp = model.logPerplexity(dataset)</span><br><span class="line">    print(<span class="string">"The lower bound on the log likelihood of the entire corpus: "</span> + str(ll))</span><br><span class="line">    print(<span class="string">"The upper bound on perplexity: "</span> + str(lp))</span><br><span class="line"></span><br><span class="line">    topics = model.describeTopics(<span class="number">3</span>)</span><br><span class="line">    print(<span class="string">"The topics described by their top-weighted terms:"</span>)</span><br><span class="line">    topics.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    transformed = model.transform(dataset)</span><br><span class="line">    transformed.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">The lower bound on the <span class="built_in">log</span> likelihood of the entire corpus: -819.009950373</span><br><span class="line">The upper bound on perplexity: 3.15003826823</span><br><span class="line">The topics described by their top-weighted terms:</span><br><span class="line">+-----+-----------+---------------------------------------------------------------+</span><br><span class="line">|topic|termIndices|termWeights                                                    |</span><br><span class="line">+-----+-----------+---------------------------------------------------------------+</span><br><span class="line">|0    |[5, 0, 4]  |[0.15844458913187548, 0.14007374754187465, 0.13600455491609725]|</span><br><span class="line">|1    |[4, 10, 1] |[0.10928579282605518, 0.10301239992895456, 0.10233720065679922]|</span><br><span class="line">|2    |[7, 2, 8]  |[0.09993621815412573, 0.0995604576055824, 0.09839140083978774] |</span><br><span class="line">|3    |[10, 6, 9] |[0.22028286673724704, 0.14180332771724063, 0.10480970083316132]|</span><br><span class="line">|4    |[3, 1, 7]  |[0.1069290730844232, 0.09913915882531774, 0.09829708091766262] |</span><br><span class="line">|5    |[8, 4, 3]  |[0.10062018802985315, 0.10039557022704547, 0.09964881942009583]|</span><br><span class="line">|6    |[7, 6, 8]  |[0.10241014766676104, 0.10114682616315203, 0.09877798196420218]|</span><br><span class="line">|7    |[3, 10, 4] |[0.23627099191080478, 0.11550793060134483, 0.09113132802908004]|</span><br><span class="line">|8    |[2, 4, 10] |[0.11417002337049241, 0.09981723889288864, 0.09638496973844993]|</span><br><span class="line">|9    |[1, 5, 3]  |[0.11538963974318006, 0.10464760125021952, 0.09761099598591011]|</span><br><span class="line">+-----+-----------+---------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h1 id="3-二分K-means-Bisecting-K-means"><a href="#3-二分K-means-Bisecting-K-means" class="headerlink" title="3. 二分K-means(Bisecting K-means)"></a>3. 二分K-means(Bisecting K-means)</h1><p>二分k-means是一种使用分裂（或“自上而下”）方法的层次聚类：首先将所有点作为一个簇， 然后将该簇一分为二，递归地执行拆分。二分K-means通常比常规K-means快得多，但它通常会产生不同的聚类。</p><p>BisectingKMeans作为Estimator实现，并生成BisectingKMeansModel作为基本模型。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/8 16:12</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : bisecting_k_means_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> BisectingKMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"BisectingKMeansExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_kmeans_data.txt"</span>)</span><br><span class="line">    bkm = BisectingKMeans().setK(<span class="number">2</span>).setSeed(<span class="number">1</span>)</span><br><span class="line">    model = bkm.fit(dataset)</span><br><span class="line"></span><br><span class="line">    cost = model.computeCost(dataset)</span><br><span class="line">    print(<span class="string">"Within Set Sum of Squared Errors = "</span> + str(cost))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Cluster Centers: "</span>)</span><br><span class="line">    centers = model.clusterCenters()</span><br><span class="line">    <span class="keyword">for</span> center <span class="keyword">in</span> centers:</span><br><span class="line">        print(center)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Within Set Sum of Squared Errors = 0.12</span><br><span class="line">Cluster Centers: </span><br><span class="line">[0.1 0.1 0.1]</span><br><span class="line">[9.1 9.1 9.1]</span><br></pre></td></tr></table></figure><h1 id="4-混合高斯模型-Gaussian-Mixture-Model-GMM"><a href="#4-混合高斯模型-Gaussian-Mixture-Model-GMM" class="headerlink" title="4. 混合高斯模型(Gaussian Mixture Model, GMM)"></a>4. 混合高斯模型(Gaussian Mixture Model, GMM)</h1><p>高斯混合模型表示复合分布，其中从k个高斯子分布中的一个绘制点，每个子分布具有其自己的概率。 spark.ml实现使用期望最大化算法求解最大似然模型。</p><h2 id="4-1-输入"><a href="#4-1-输入" class="headerlink" title="4.1 输入"></a>4.1 输入</h2><table><thead><tr><th style="text-align:center">Param name</th><th style="text-align:center">Type(s)</th><th style="text-align:center">Default</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center">featuresCol</td><td style="text-align:center">Vector</td><td style="text-align:center">“features”</td><td style="text-align:center">Feature vector</td></tr></tbody></table><h2 id="4-2-输出"><a href="#4-2-输出" class="headerlink" title="4.2 输出"></a>4.2 输出</h2><table><thead><tr><th style="text-align:center">Param name</th><th style="text-align:center">Type(s)</th><th style="text-align:center">Default</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center">predictionCol</td><td style="text-align:center">Int</td><td style="text-align:center">“prediction”</td><td style="text-align:center">Predicted cluster center</td></tr><tr><td style="text-align:center">probabilityCol</td><td style="text-align:center">Vector</td><td style="text-align:center">“probability”</td><td style="text-align:center">Probability of each cluster</td></tr></tbody></table><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/8 16:21</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : gaussian_mixture_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"GaussianMixtureExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_kmeans_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    gmm = GaussianMixture().setK(<span class="number">2</span>).setSeed(<span class="number">1</span>)</span><br><span class="line">    model = gmm.fit(dataset)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Gaussians shown as a DataFrame: "</span>)</span><br><span class="line">    model.gaussiansDF.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Gaussians shown as a DataFrame: </span><br><span class="line">+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|mean                                                         |cov                                                                                                                                                                                                     |</span><br><span class="line">+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|[0.10000000000001552,0.10000000000001552,0.10000000000001552]|0.006666666666806454  0.006666666666806454  0.006666666666806454  </span><br><span class="line">0.006666666666806454  0.006666666666806454  0.006666666666806454  </span><br><span class="line">0.006666666666806454  0.006666666666806454  0.006666666666806454  |</span><br><span class="line">|[9.099999999999984,9.099999999999984,9.099999999999984]      |0.006666666666812185  0.006666666666812185  0.006666666666812185  </span><br><span class="line">0.006666666666812185  0.006666666666812185  0.006666666666812185  </span><br><span class="line">0.006666666666812185  0.006666666666812185  0.006666666666812185  |</span><br><span class="line">+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本节主要讲Spark ML中关于聚类算法的实现。示例的算法Demo包含：K-means、LDA、高斯混合模型(GMM)等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】分类和回归算法-回归</title>
    <link href="https://buracagyang.github.io/2019/08/07/spark-classification-and-regression-2/"/>
    <id>https://buracagyang.github.io/2019/08/07/spark-classification-and-regression-2/</id>
    <published>2019-08-07T02:01:34.000Z</published>
    <updated>2019-08-07T07:03:42.640Z</updated>
    
    <content type="html"><![CDATA[<p>本节主要讲Spark ML中关于回归算法的实现。示例的算法Demo包含：线性回归、广义线性回归、决策树回归、随机森林回归、梯度提升树回归等。</p><a id="more"></a><h1 id="1-线性回归-Linear-regression"><a href="#1-线性回归-Linear-regression" class="headerlink" title="1. 线性回归(Linear regression)"></a>1. 线性回归(Linear regression)</h1><p>与logistic regression类似的，直接附上示例代码吧：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 10:11</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : linear_regression_with_elastic_net.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"LinearRegressionWithElasticNet"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_linear_regression_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    lr = LinearRegression(maxIter=<span class="number">20</span>, regParam=<span class="number">0.01</span>, elasticNetParam=<span class="number">0.6</span>)</span><br><span class="line">    lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 参数和截距项</span></span><br><span class="line">    <span class="comment"># print("Coefficients: %s" % str(lrModel.coefficients))</span></span><br><span class="line">    <span class="comment"># print("Intercept: %s" % str(lrModel.intercept))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型评估指标</span></span><br><span class="line">    trainingSummary = lrModel.summary</span><br><span class="line">    print(<span class="string">"numIterations: %d"</span> % trainingSummary.totalIterations)</span><br><span class="line">    print(<span class="string">"objectiveHistory: %s"</span> % str(trainingSummary.objectiveHistory))</span><br><span class="line">    trainingSummary.residuals.show()</span><br><span class="line">    print(<span class="string">"RMSE: %f"</span> % trainingSummary.rootMeanSquaredError)</span><br><span class="line">    print(<span class="string">"r2: %f"</span> % trainingSummary.r2)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下($r^2$如此低。。。。)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">numIterations: 8</span><br><span class="line">objectiveHistory: [0.49999999999999994, 0.4931849471651455, 0.4863393782275527, 0.48633557300904495, 0.48633543657045664, 0.4863354337756586, 0.4863354337094886, 0.4863354337092549]</span><br><span class="line">+-------------------+</span><br><span class="line">|          residuals|</span><br><span class="line">+-------------------+</span><br><span class="line">|  -10.9791066152217|</span><br><span class="line">| 0.9208605107751258|</span><br><span class="line">| -4.608888656779226|</span><br><span class="line">|-20.424003572582702|</span><br><span class="line">|-10.316545030639608|</span><br><span class="line">+-------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">RMSE: 10.163110</span><br><span class="line">r2: 0.027836</span><br></pre></td></tr></table></figure><h1 id="2-广义线性回归-Generalized-linear-regression"><a href="#2-广义线性回归-Generalized-linear-regression" class="headerlink" title="2. 广义线性回归(Generalized linear regression)"></a>2. 广义线性回归(Generalized linear regression)</h1><p>与假设输出遵循高斯分布的线性回归相反，广义线性模型（GLMs）是线性模型的规范，其中响应变量$Y_i$遵循指数分布族的一些分布。 Spark的GeneralizedLinearRegression接口允许灵活地指定GLMs，可用于各种类型的预测问题，包括线性回归，泊松回归，逻辑回归等。目前在spark.ml中，仅支持指数族分布的子集，在下面列出。</p><table><thead><tr><th>分布族</th><th>响应变量类型</th><th>Supported Links</th></tr></thead><tbody><tr><td>高斯分布</td><td>Continuous</td><td>Identity*,Log,Inverse</td></tr><tr><td>Binomial</td><td>二元变量</td><td>Logit*, Probit, CLogLog</td></tr><tr><td>泊松分布</td><td>数值</td><td>Log*, Identity, Sqrt</td></tr><tr><td>Gamma分布</td><td>连续变量</td><td>Inverse*, Identity, Log</td></tr><tr><td>Tweedie分布</td><td>zero-inflated continuous</td><td>Power link function</td></tr></tbody></table><p>*标准Link</p><p><strong>注意</strong>：Spark目前通过其GeneralizedLinearRegression接口仅支持4096个特征，如果超出此约束，则会抛出异常。尽管如此，对于线性回归和逻辑回归，可以使用LinearRegression和LogisticRegression估计来训练具有更多特征的模型(对于高纬特征集没啥用。。。)。</p><p>GLMs需要指数族分布，这些分布可以用“标准(canonical)”或“自然(natural)”形式写成，也就是自然指数族分布。自然指数分布族(natural exponential family distribution)的形式如下：<br>$$<br>f_Y(y|\theta, \tau) = h(y, \tau)exp(\frac{\theta.y - A(\theta)}{d(\tau)}) \tag{1}<br>$$<br>其中$\theta$是parameter of interest，$\tau$是dispersion parameter。 在GLMs中，假设响应变量$Y_i$是从自然指数分布族中提取的：<br>$$<br>Y_i \sim f(\cdot|\theta_i, \tau) \tag{2}<br>$$<br>其中，parameter of interest $\theta_i$与响应变量的期望值$\mu_i$相关:<br>$$<br>\mu_i = A’(\theta_i) \tag{3}<br>$$<br>这里，$A’(\theta_i)$根据选择的分布形式定义，GLMs还支持指定的链接函数(link function)，该函数定义响应变量的期望值$\mu_i$与线性预测值$\eta_i$之间的关系：<br>$$<br>g(\mu_i) = \eta_i = \vec{x_i}^T \cdot \vec{\beta} \tag{4}<br>$$<br>通常，选择链接函数(link function)使得$A’ =  g^{-1}$，其产生的parameter of interest $θ$与线性预测值$\eta$之间的简化关系。 在这种情况下，链接函数$g(μ)$被称为“标准”(“canonical”)链接函数。<br>$$<br>\theta_i = A’^{-1}(\mu_i) = g(g^{-1}(\eta_i)) = \eta_i \tag{5}<br>$$<br>一个GLM根据最大化似然概率函数值寻找回归系数$\vec{\beta}$:<br>$$<br>\max_{\vec{\beta}} \mathcal{L}(\vec{\theta}|\vec{y},X) =<br>\prod_{i=1}^{N} h(y_i, \tau) \exp{\left(\frac{y_i\theta_i - A(\theta_i)}{d(\tau)}\right)} \tag{6}<br>$$<br>其中the parameter of interest $\theta_i$与回归系数$\vec{\beta}$的关系为：<br>$$<br>\theta_i = A’^{-1}(g^{-1}(\vec{x_i} \cdot \vec{\beta})) \tag{7}<br>$$</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 13:12</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : generalized_linear_regression_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GeneralizedLinearRegression</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"GeneralizedLinearRegressionExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_linear_regression_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    glr = GeneralizedLinearRegression(family=<span class="string">"gaussian"</span>, link=<span class="string">"identity"</span>, maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>)</span><br><span class="line">    model = glr.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 参数和截距项</span></span><br><span class="line">    print(<span class="string">"Coefficients: "</span> + str(model.coefficients))</span><br><span class="line">    print(<span class="string">"Intercept: "</span> + str(model.intercept))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 通不过模型检验啊...</span></span><br><span class="line">    summary = model.summary</span><br><span class="line">    print(<span class="string">"Coefficient Standard Errors: "</span> + str(summary.coefficientStandardErrors))</span><br><span class="line">    print(<span class="string">"T Values: "</span> + str(summary.tValues))</span><br><span class="line">    print(<span class="string">"P Values: "</span> + str(summary.pValues))</span><br><span class="line">    print(<span class="string">"Dispersion: "</span> + str(summary.dispersion))</span><br><span class="line">    print(<span class="string">"Null Deviance: "</span> + str(summary.nullDeviance))</span><br><span class="line">    print(<span class="string">"Residual Degree Of Freedom Null: "</span> + str(summary.residualDegreeOfFreedomNull))</span><br><span class="line">    print(<span class="string">"Deviance: "</span> + str(summary.deviance))</span><br><span class="line">    print(<span class="string">"Residual Degree Of Freedom: "</span> + str(summary.residualDegreeOfFreedom))</span><br><span class="line">    print(<span class="string">"AIC: "</span> + str(summary.aic))</span><br><span class="line">    print(<span class="string">"Deviance Residuals: "</span>)</span><br><span class="line">    summary.residuals().show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><h1 id="3-决策树回归-Decision-tree-regression"><a href="#3-决策树回归-Decision-tree-regression" class="headerlink" title="3. 决策树回归(Decision tree regression)"></a>3. 决策树回归(Decision tree regression)</h1><p>与决策树分类类似，直接附上示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 13:57</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : decision_tree_regression_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"DecisionTreeRegressionExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别分类特性，并对它们进行索引。指定maxCategories，这样存在 &gt; 4个不同值的特征将被视为连续的。</span></span><br><span class="line">    featureIndexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>], seed=<span class="number">2019</span>)</span><br><span class="line">    dt = DecisionTreeRegressor(featuresCol=<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过Pipeline进行训练</span></span><br><span class="line">    pipeline = Pipeline(stages=[featureIndexer, dt])</span><br><span class="line"></span><br><span class="line">    model = pipeline.fit(trainingData)</span><br><span class="line">    predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    evaluator = RegressionEvaluator(labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"rmse"</span>)</span><br><span class="line">    rmse = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Root Mean Squared Error (RMSE) on test data = %g"</span> % rmse)</span><br><span class="line"></span><br><span class="line">    treeModel = model.stages[<span class="number">1</span>]</span><br><span class="line">    print(treeModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       0.0|  0.0|(692,[100,101,102...|</span><br><span class="line">|       0.0|  0.0|(692,[121,122,123...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Root Mean Squared Error (RMSE) on <span class="built_in">test</span> data = 0.297044</span><br><span class="line">DecisionTreeRegressionModel (uid=DecisionTreeRegressor_4089a3fc367ac7a943d9) of depth 2 with 5 nodes</span><br></pre></td></tr></table></figure><h1 id="4-随机森林回归-Random-forest-regression"><a href="#4-随机森林回归-Random-forest-regression" class="headerlink" title="4. 随机森林回归(Random forest regression)"></a>4. 随机森林回归(Random forest regression)</h1><p>与决策树回归类似，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 14:05</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : random_forest_regressor_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"RandomForestRegressorExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别分类特性，并对它们进行索引。指定maxCategories，这样存在 &gt; 4个不同值的特征将被视为连续的。</span></span><br><span class="line">    featureIndexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>], seed=<span class="number">2019</span>)</span><br><span class="line">    rf = RandomForestRegressor(featuresCol=<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过Pipeline进行训练</span></span><br><span class="line">    pipeline = Pipeline(stages=[featureIndexer, rf])</span><br><span class="line">    model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    evaluator = RegressionEvaluator(labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"rmse"</span>)</span><br><span class="line">    rmse = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Root Mean Squared Error (RMSE) on test data = %g"</span> % rmse)</span><br><span class="line"></span><br><span class="line">    rfModel = model.stages[<span class="number">1</span>]</span><br><span class="line">    print(rfModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       0.4|  0.0|(692,[100,101,102...|</span><br><span class="line">|       0.0|  0.0|(692,[121,122,123...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.1|  0.0|(692,[124,125,126...|</span><br><span class="line">|      0.15|  0.0|(692,[124,125,126...|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Root Mean Squared Error (RMSE) on <span class="built_in">test</span> data = 0.141421</span><br><span class="line">RandomForestRegressionModel (uid=RandomForestRegressor_4dc1b1ad32480cc89ddc) with 20 trees</span><br></pre></td></tr></table></figure><h1 id="5-梯度提升树回归-Gradient-boosted-tree-regression"><a href="#5-梯度提升树回归-Gradient-boosted-tree-regression" class="headerlink" title="5. 梯度提升树回归(Gradient-boosted tree regression)"></a>5. 梯度提升树回归(Gradient-boosted tree regression)</h1><p>示例代码如下(需要注意的是，对于这个示例样本集，GBTRegressor只需要一次迭代，但是在通常情况下是不止一次的~)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 14:11</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : gradient_boosted_tree_regressor_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GBTRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"GradientBoostedTreeRegressorExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    featureIndexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>], seed=<span class="number">2019</span>)</span><br><span class="line">    gbt = GBTRegressor(featuresCol=<span class="string">"indexedFeatures"</span>, maxIter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过Pipeline进行训练</span></span><br><span class="line">    pipeline = Pipeline(stages=[featureIndexer, gbt])</span><br><span class="line">    model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    evaluator = RegressionEvaluator(labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"rmse"</span>)</span><br><span class="line">    rmse = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Root Mean Squared Error (RMSE) on test data = %g"</span> % rmse)</span><br><span class="line"></span><br><span class="line">    gbtModel = model.stages[<span class="number">1</span>]</span><br><span class="line">    print(gbtModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       0.0|  0.0|(692,[100,101,102...|</span><br><span class="line">|       0.0|  0.0|(692,[121,122,123...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Root Mean Squared Error (RMSE) on <span class="built_in">test</span> data = 0.297044</span><br><span class="line">GBTRegressionModel (uid=GBTRegressor_46239bc64cc2f59b1fb5) with 10 trees</span><br></pre></td></tr></table></figure><h1 id="6-生存回归-Survival-regression"><a href="#6-生存回归-Survival-regression" class="headerlink" title="6. 生存回归(Survival regression)"></a>6. 生存回归(Survival regression)</h1><p>在spark.ml中，实现了加速失败时间（Accelerated failure time, AFT）模型，它是一个用于删失数据的参数生存回归模型（survival regression model）。 它描述了生存时间对数的模型，因此它通常被称为生存分析的对数线性模型。 与为相同目的设计的比例风险模型不同，AFT模型更易于并行化，因为每个实例都独立地为目标函数做出贡献。</p><p>给定协变量$x’$的值，对于受试者$i = 1，…，n$的随机寿命$t_i$(random lifetime)，可能进行右截尾(right-censoring)，AFT模型下的似然函数如下：<br>$$<br>L(\beta,\sigma)=\prod_{i=1}^n[\frac{1}{\sigma}f_{0}(\frac{\log{t_{i}}-x^{‘}\beta}{\sigma})]^{\delta_{i}}S_{0}(\frac{\log{t_{i}}-x^{‘}\beta}{\sigma})^{1-\delta_{i}} \tag{8}<br>$$<br>其中$\delta_i$是事件发生的指标，即是否经过截尾的。 使用$\epsilon_{i}=\frac{\log{t_{i}}-x^{‘}\beta}{\sigma}$，对数似然函数采用以下形式：<br>$$<br>\iota(\beta,\sigma)=\sum_{i=1}^{n}[-\delta_{i}\log\sigma+\delta_{i}\log{f_{0}}(\epsilon_{i})+(1-\delta_{i})\log{S_{0}(\epsilon_{i})}] \tag{9}<br>$$<br>其中$S_{0}(\epsilon_{i})$是幸存函数基线，$f_{0}(\epsilon_{i})$是相应的密度函数。</p><p>最常用的AFT模型基于Weibull分布的生存时间。 生命周期的Weibull分布对应于生命日志的极值分布(the extreme value distribution for the log of the lifetime)，$S_{0}(\epsilon)$函数是：<br>$$<br>S_{0}(\epsilon_{i})=\exp(-e^{\epsilon_{i}}) \tag{10}<br>$$<br>其中$f_{0}(\epsilon_{i})$函数形式为：<br>$$<br>f_{0}(\epsilon_{i})=e^{\epsilon_{i}}\exp(-e^{\epsilon_{i}}) \tag{11}<br>$$<br>带有Weibull生命分布的AFT模型的对数似然函数是：<br>$$<br>\iota(\beta,\sigma)= -\sum_{i=1}^n[\delta_{i}\log\sigma-\delta_{i}\epsilon_{i}+e^{\epsilon_{i}}] \tag{12}<br>$$<br>由于最小化负对数似然函数等效于最大化后验概率的，我们用于优化的损失函数是$-\iota(\beta,\sigma)$。 $\beta$和$\log\sigma$的梯度函数分别为：<br>$$<br>\begin{eqnarray}<br>\frac{\partial (-\iota)}{\partial \beta} &amp;=&amp; \sum_{1=1}^{n}[\delta_{i}-e^{\epsilon_{i}}]\frac{x_{i}}{\sigma} \\<br>\frac{\partial (-\iota)}{\partial (\log\sigma)} &amp;=&amp; \sum_{i=1}^{n}[\delta_{i}+(\delta_{i}-e^{\epsilon_{i}})\epsilon_{i}]<br>\end{eqnarray} \tag{13}<br>$$</p><p>AFT模型可以被转换为凸优化问题，即，找到取决于系数向量$\beta$和尺度参数的对数$\log\sigma$的凸函数的最小化的任务$-\iota(\beta,\sigma)$。 实现的优化算法是L-BFGS。 实现匹配R的生存函数的<a href="https://stat.ethz.ch/R-manual/R-devel/library/survival/html/survreg.html" target="_blank" rel="noopener">幸存结果</a>。</p><blockquote><p>当拟合AFTSurvivalRegressionModel而不截断具有常量非零列的数据集时，Spark MLlib为常量非零列输出零系数。 此与R survival :: survreg不同</p></blockquote><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 14:38</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : aft_survival_regression.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> AFTSurvivalRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"AFTSurvivalRegressionExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    training = spark.createDataFrame([</span><br><span class="line">        (<span class="number">1.218</span>, <span class="number">1.0</span>, Vectors.dense(<span class="number">1.560</span>, <span class="number">-0.605</span>)),</span><br><span class="line">        (<span class="number">2.949</span>, <span class="number">0.0</span>, Vectors.dense(<span class="number">0.346</span>, <span class="number">2.158</span>)),</span><br><span class="line">        (<span class="number">3.627</span>, <span class="number">0.0</span>, Vectors.dense(<span class="number">1.380</span>, <span class="number">0.231</span>)),</span><br><span class="line">        (<span class="number">0.273</span>, <span class="number">1.0</span>, Vectors.dense(<span class="number">0.520</span>, <span class="number">1.151</span>)),</span><br><span class="line">        (<span class="number">4.199</span>, <span class="number">0.0</span>, Vectors.dense(<span class="number">0.795</span>, <span class="number">-0.226</span>))], [<span class="string">"label"</span>, <span class="string">"censor"</span>, <span class="string">"features"</span>])</span><br><span class="line">    quantileProbabilities = [<span class="number">0.3</span>, <span class="number">0.6</span>]</span><br><span class="line">    aft = AFTSurvivalRegression(quantileProbabilities=quantileProbabilities, quantilesCol=<span class="string">"quantiles"</span>)</span><br><span class="line"></span><br><span class="line">    model = aft.fit(training)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Coefficients: "</span> + str(model.coefficients))</span><br><span class="line">    print(<span class="string">"Intercept: "</span> + str(model.intercept))</span><br><span class="line">    print(<span class="string">"Scale: "</span> + str(model.scale))</span><br><span class="line">    model.transform(training).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: [-0.49631114666506776,0.1984443769993409]</span><br><span class="line">Intercept: 2.6380946151</span><br><span class="line">Scale: 1.54723455744</span><br><span class="line">+-----+------+--------------+-----------------+---------------------------------------+</span><br><span class="line">|label|censor|features      |prediction       |quantiles                              |</span><br><span class="line">+-----+------+--------------+-----------------+---------------------------------------+</span><br><span class="line">|1.218|1.0   |[1.56,-0.605] |5.718979487634966|[1.1603238947151588,4.995456010274735] |</span><br><span class="line">|2.949|0.0   |[0.346,2.158] |18.07652118149563|[3.667545845471802,15.789611866277884] |</span><br><span class="line">|3.627|0.0   |[1.38,0.231]  |7.381861804239103|[1.4977061305190853,6.447962612338967] |</span><br><span class="line">|0.273|1.0   |[0.52,1.151]  |13.57761250142538|[2.7547621481507067,11.859872224069784]|</span><br><span class="line">|4.199|0.0   |[0.795,-0.226]|9.013097744073846|[1.8286676321297735,7.872826505878384] |</span><br><span class="line">+-----+------+--------------+-----------------+---------------------------------------+</span><br></pre></td></tr></table></figure><h1 id="7-Isotonic-regression"><a href="#7-Isotonic-regression" class="headerlink" title="7. Isotonic regression"></a>7. Isotonic regression</h1><p><a href="https://en.wikipedia.org/wiki/Isotonic_regression" target="_blank" rel="noopener">Isotonic regression</a>属于回归算法族。 对 isotonic regression定义如下，给定一组有限的实数$Y = {y_1, y_2, …, y_n}$表示观察到的响应，$X = {x_1, x_2, …, x_n}$表示未知的响应值，拟合一个函数以最小化：<br>$$<br>f(x) = \sum_{i=1}^n w_i (y_i - x_i)^2 \tag{14}<br>$$<br>以$x_1\le x_2\le …\le x_n$为完整的顺序，其中$w_i$是正权重。 由此产生的函数称为isotonic regression，它是独一无二的。 它可以被视为有顺序限制下的最小二乘问题。 基本上isotonic regression是最适合原始数据点的单调函数。</p><p>Spark实现了一个相邻违规算法的池，该算法使用一种并行化isotonic regression的方法。 训练输入是一个DataFrame，它包含三列标签，label, features 和 weight。 此外，IsotonicRegression算法有一个<code>isotonis</code>(默认为true)的可选参数。 表示isotonic regression是isotonic的（单调递增的）还是antitonic的（单调递减的）。</p><p>训练返回IsotonicRegressionModel，可用于预测已知和未知特征的标签。isotonic regression的结果被视为分段线性函数。因此预测规则是：</p><ul><li>如果预测输入与训练特征完全匹配，则返回相关联的预测。如果有多个具有相同特征的预测，则返回其中一个。哪一个是未定义的（与java.util.Arrays.binarySearch相同）。</li><li>如果预测输入低于或高于所有训练特征，则分别返回具有最低或最高特征的预测。如果存在具有相同特征的多个预测，则分别返回最低或最高。</li><li>如果预测输入落在两个训练特征之间，则将预测视为分段线性函数，并且根据两个最接近特征的预测来计算内插值。如果存在具有相同特征的多个值，则使用与先前点相同的规则。</li></ul><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/7 14:56</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : isotonic_regression_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> IsotonicRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"IsotonicRegressionExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_isotonic_regression_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    model = IsotonicRegression().fit(dataset)</span><br><span class="line">    print(<span class="string">"Boundaries in increasing order: %s\n"</span> % str(model.boundaries))</span><br><span class="line">    print(<span class="string">"Predictions associated with the boundaries: %s\n"</span> % str(model.predictions))</span><br><span class="line"></span><br><span class="line">    model.transform(dataset).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Boundaries <span class="keyword">in</span> increasing order: [0.01,0.17,0.18,0.27,0.28,0.29,0.3,0.31,0.34,0.35,0.36,0.41,0.42,0.71,0.72,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,0.86,0.87,0.88,0.89,1.0]</span><br><span class="line"></span><br><span class="line">Predictions associated with the boundaries: [0.15715271294117644,0.15715271294117644,0.189138196,0.189138196,0.20040796,0.29576747,0.43396226,0.5081591025000001,0.5081591025000001,0.54156043,0.5504844466666667,0.5504844466666667,0.563929967,0.563929967,0.5660377366666667,0.5660377366666667,0.56603774,0.57929628,0.64762876,0.66241713,0.67210607,0.67210607,0.674655785,0.674655785,0.73890872,0.73992861,0.84242733,0.89673636,0.89673636,0.90719021,0.9272055075,0.9272055075]</span><br><span class="line"></span><br><span class="line">+----------+--------------+-------------------+</span><br><span class="line">|     label|      features|         prediction|</span><br><span class="line">+----------+--------------+-------------------+</span><br><span class="line">|0.24579296|(1,[0],[0.01])|0.15715271294117644|</span><br><span class="line">|0.28505864|(1,[0],[0.02])|0.15715271294117644|</span><br><span class="line">|0.31208567|(1,[0],[0.03])|0.15715271294117644|</span><br><span class="line">|0.35900051|(1,[0],[0.04])|0.15715271294117644|</span><br><span class="line">|0.35747068|(1,[0],[0.05])|0.15715271294117644|</span><br><span class="line">+----------+--------------+-------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本节主要讲Spark ML中关于回归算法的实现。示例的算法Demo包含：线性回归、广义线性回归、决策树回归、随机森林回归、梯度提升树回归等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】分类和回归算法-分类</title>
    <link href="https://buracagyang.github.io/2019/08/02/spark-classification-and-regression-1/"/>
    <id>https://buracagyang.github.io/2019/08/02/spark-classification-and-regression-1/</id>
    <published>2019-08-02T09:25:40.000Z</published>
    <updated>2019-08-08T07:41:54.011Z</updated>
    
    <content type="html"><![CDATA[<p>本节主要讲Spark ML中关于分类算法的实现。示例的算法Demo包含：LR、DT、RF、GBTs、多层感知器、线性支持向量机、One-vs-Rest分类器以及NB等。</p><a id="more"></a><h1 id="1-Logistic-regression"><a href="#1-Logistic-regression" class="headerlink" title="1. Logistic regression"></a>1. Logistic regression</h1><p>在spark.ml中，逻辑回归可以用于通过二项逻辑回归来预测二元结果，或者它可以用于通过使用多项逻辑回归来预测多类结果。 使用family参数在这两个算法之间进行选择，或者保持不设置，Spark将推断出正确的变量。</p><blockquote><p> 通过将’family’参数设置为“multinomial”，可以将多项逻辑回归用于二元分类。 它将产生两组系数和两个截距。</p></blockquote><h2 id="1-1-二分类LR"><a href="#1-1-二分类LR" class="headerlink" title="1.1 二分类LR"></a>1.1 二分类LR</h2><p>直接给出示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/2 17:42</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : logistic_regression_with_elastic_net.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"LogisticRegressionWithElasticNet"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line">    lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Coefficients: "</span> + str(lrModel.coefficients))</span><br><span class="line">    print(<span class="string">"Intercept: "</span> + str(lrModel.intercept))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对于二分类也可以参数设置为，family="multinomial"</span></span><br><span class="line">    mlr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>, family=<span class="string">"multinomial"</span>)</span><br><span class="line">    mlrModel = mlr.fit(training)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Multinomial coefficients: "</span> + str(mlrModel.coefficientMatrix))</span><br><span class="line">    print(<span class="string">"Multinomial intercepts: "</span> + str(mlrModel.interceptVector))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: (692,[...])</span><br><span class="line">Intercept: 0.224563159613</span><br><span class="line">Multinomial coefficients: 2 X 692 CSRMatrix</span><br><span class="line">(0,244) 0.0</span><br><span class="line">(0,263) 0.0001</span><br><span class="line">..</span><br><span class="line">..</span><br><span class="line">Multinomial intercepts: [-0.12065879445860686,0.12065879445860686]</span><br></pre></td></tr></table></figure><p>LogisticRegressionTrainingSummary提供LogisticRegressionModel的一些训练指标摘要。 在二进制分类的情况下例如， ROC曲线。</p><p>继续前面的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/2 17:49</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : logistic_regression_summary_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession \</span><br><span class="line">        .builder \</span><br><span class="line">        .appName(<span class="string">"LogisticRegressionSummary"</span>) \</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line">    lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line">    trainingSummary = lrModel.summary</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得每次迭代的优化目标(损失 + 惩罚项)</span></span><br><span class="line">    objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line">    print(<span class="string">"objectiveHistory:"</span>)</span><br><span class="line">    <span class="keyword">for</span> objective <span class="keyword">in</span> objectiveHistory:</span><br><span class="line">        print(objective)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.</span></span><br><span class="line">    trainingSummary.roc.show()</span><br><span class="line">    print(<span class="string">"areaUnderROC: "</span> + str(trainingSummary.areaUnderROC))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置模型阈值，使得最大化F度量值</span></span><br><span class="line">    fMeasure = trainingSummary.fMeasureByThreshold</span><br><span class="line">    maxFMeasure = fMeasure.groupBy().max(<span class="string">'F-Measure'</span>).select(<span class="string">'max(F-Measure)'</span>).head()</span><br><span class="line">    bestThreshold = fMeasure.where(fMeasure[<span class="string">'F-Measure'</span>] == maxFMeasure[<span class="string">'max(F-Measure)'</span>]) \</span><br><span class="line">        .select(<span class="string">'threshold'</span>).head()[<span class="string">'threshold'</span>]</span><br><span class="line">    lr.setThreshold(bestThreshold)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>日志信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">objectiveHistory:</span><br><span class="line">0.683314913574</span><br><span class="line">...</span><br><span class="line">+---+--------------------+</span><br><span class="line">|FPR|                 TPR|</span><br><span class="line">+---+--------------------+</span><br><span class="line">|0.0|                 0.0|</span><br><span class="line">|0.0|0.017543859649122806|</span><br><span class="line">|0.0| 0.03508771929824561|</span><br><span class="line">|0.0| 0.05263157894736842|</span><br><span class="line">|0.0| 0.07017543859649122|</span><br><span class="line">|0.0| 0.08771929824561403|</span><br><span class="line">|0.0| 0.10526315789473684|</span><br><span class="line">|0.0| 0.12280701754385964|</span><br><span class="line">|0.0| 0.14035087719298245|</span><br><span class="line">|0.0| 0.15789473684210525|</span><br><span class="line">|0.0| 0.17543859649122806|</span><br><span class="line">|0.0| 0.19298245614035087|</span><br><span class="line">|0.0| 0.21052631578947367|</span><br><span class="line">|0.0| 0.22807017543859648|</span><br><span class="line">|0.0| 0.24561403508771928|</span><br><span class="line">|0.0|  0.2631578947368421|</span><br><span class="line">|0.0|  0.2807017543859649|</span><br><span class="line">|0.0|  0.2982456140350877|</span><br><span class="line">|0.0|  0.3157894736842105|</span><br><span class="line">|0.0|  0.3333333333333333|</span><br><span class="line">+---+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">areaUnderROC: 1.0</span><br></pre></td></tr></table></figure><h2 id="1-2-多分类LR"><a href="#1-2-多分类LR" class="headerlink" title="1.2 多分类LR"></a>1.2 多分类LR</h2><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 16:35</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : multiclass_logistic_regression_with_elastic_net.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession \</span><br><span class="line">        .builder \</span><br><span class="line">        .appName(<span class="string">"MulticlassLogisticRegressionWithElasticNet"</span>) \</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    training = spark \</span><br><span class="line">        .read \</span><br><span class="line">        .format(<span class="string">"libsvm"</span>) \</span><br><span class="line">        .load(<span class="string">"../data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line">    lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 系数和截距项</span></span><br><span class="line">    print(<span class="string">"Coefficients: \n"</span> + str(lrModel.coefficientMatrix))</span><br><span class="line">    print(<span class="string">"Intercept: "</span> + str(lrModel.interceptVector))</span><br><span class="line"></span><br><span class="line">    trainingSummary = lrModel.summary</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得每次迭代的优化目标(损失 + 惩罚项)</span></span><br><span class="line">    objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line">    print(<span class="string">"objectiveHistory:"</span>)</span><br><span class="line">    <span class="keyword">for</span> objective <span class="keyword">in</span> objectiveHistory:</span><br><span class="line">        print(objective)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可以查看每个类的FPR &amp; TPR</span></span><br><span class="line">    print(<span class="string">"False positive rate by label:"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, rate <span class="keyword">in</span> enumerate(trainingSummary.falsePositiveRateByLabel):</span><br><span class="line">        print(<span class="string">"label %d: %s"</span> % (i, rate))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"True positive rate by label:"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, rate <span class="keyword">in</span> enumerate(trainingSummary.truePositiveRateByLabel):</span><br><span class="line">        print(<span class="string">"label %d: %s"</span> % (i, rate))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Precision by label:"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, prec <span class="keyword">in</span> enumerate(trainingSummary.precisionByLabel):</span><br><span class="line">        print(<span class="string">"label %d: %s"</span> % (i, prec))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Recall by label:"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, rec <span class="keyword">in</span> enumerate(trainingSummary.recallByLabel):</span><br><span class="line">        print(<span class="string">"label %d: %s"</span> % (i, rec))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"F-measure by label:"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, f <span class="keyword">in</span> enumerate(trainingSummary.fMeasureByLabel()):</span><br><span class="line">        print(<span class="string">"label %d: %s"</span> % (i, f))</span><br><span class="line"></span><br><span class="line">    accuracy = trainingSummary.accuracy</span><br><span class="line">    falsePositiveRate = trainingSummary.weightedFalsePositiveRate</span><br><span class="line">    truePositiveRate = trainingSummary.weightedTruePositiveRate</span><br><span class="line">    fMeasure = trainingSummary.weightedFMeasure()</span><br><span class="line">    precision = trainingSummary.weightedPrecision</span><br><span class="line">    recall = trainingSummary.weightedRecall</span><br><span class="line">    print(<span class="string">"Accuracy: %s\nFPR: %s\nTPR: %s\nF-measure: %s\nPrecision: %s\nRecall: %s"</span></span><br><span class="line">          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: </span><br><span class="line">3 X 4 CSRMatrix</span><br><span class="line">(0,3) 0.3176</span><br><span class="line">(1,2) -0.7804</span><br><span class="line">(1,3) -0.377</span><br><span class="line">Intercept: [0.05165231659832854,-0.12391224990853622,0.07225993331020768]</span><br><span class="line">objectiveHistory:</span><br><span class="line">1.09861228867</span><br><span class="line">...</span><br><span class="line">False positive rate by label:</span><br><span class="line">label 0: 0.22</span><br><span class="line">label 1: 0.05</span><br><span class="line">label 2: 0.0</span><br><span class="line">True positive rate by label:</span><br><span class="line">label 0: 1.0</span><br><span class="line">label 1: 1.0</span><br><span class="line">label 2: 0.46</span><br><span class="line">Precision by label:</span><br><span class="line">label 0: 0.694444444444</span><br><span class="line">label 1: 0.909090909091</span><br><span class="line">label 2: 1.0</span><br><span class="line">Recall by label:</span><br><span class="line">label 0: 1.0</span><br><span class="line">label 1: 1.0</span><br><span class="line">label 2: 0.46</span><br><span class="line">F-measure by label:</span><br><span class="line">label 0: 0.819672131148</span><br><span class="line">label 1: 0.952380952381</span><br><span class="line">label 2: 0.630136986301</span><br><span class="line">Accuracy: 0.82</span><br><span class="line">FPR: 0.09</span><br><span class="line">TPR: 0.82</span><br><span class="line">F-measure: 0.800730023277</span><br><span class="line">Precision: 0.867845117845</span><br><span class="line">Recall: 0.82</span><br></pre></td></tr></table></figure><h1 id="2-决策树分类器"><a href="#2-决策树分类器" class="headerlink" title="2. 决策树分类器"></a>2. 决策树分类器</h1><p><strong>举例</strong></p><p>以LibSVM格式加载数据集，将其拆分为训练集和测试集，在第一个数据集上训练，然后在保留的测试集上进行评估。 我们使用两个特征变换器(transformers)来准备数据; 这些帮助标记和分类特征的索引类别，向决策树算法可识别的DataFrame添加元数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 16:41</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : decision_tree_classification_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer, VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"DecisionTreeClassificationExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对于整个数据集，将label转换为索引</span></span><br><span class="line">    labelIndexer = StringIndexer(inputCol=<span class="string">"label"</span>, outputCol=<span class="string">"indexedLabel"</span>).fit(data)</span><br><span class="line">    <span class="comment"># 自动识别数据集中的分类特征，并且进行矢量化处理;设定maxCategories，以便将具有&gt; 4个不同值的特性视为连续的。</span></span><br><span class="line">    featureIndexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 切分训练集和测试集</span></span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练一颗决策树</span></span><br><span class="line">    dt = DecisionTreeClassifier(labelCol=<span class="string">"indexedLabel"</span>, featuresCol=<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 连接indexers和决策树</span></span><br><span class="line">    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])</span><br><span class="line"></span><br><span class="line">    model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行预测</span></span><br><span class="line">    predictions = model.transform(testData)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"indexedLabel"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算测试误差</span></span><br><span class="line">    evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">        labelCol=<span class="string">"indexedLabel"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g "</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    treeModel = model.stages[<span class="number">2</span>]</span><br><span class="line">    print(treeModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+------------+--------------------+</span><br><span class="line">|prediction|indexedLabel|            features|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">|       1.0|         1.0|(692,[98,99,100,1...|</span><br><span class="line">|       1.0|         1.0|(692,[121,122,123...|</span><br><span class="line">|       1.0|         1.0|(692,[122,123,148...|</span><br><span class="line">|       1.0|         1.0|(692,[124,125,126...|</span><br><span class="line">|       1.0|         1.0|(692,[126,127,128...|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Test Error = 0.0357143 </span><br><span class="line">DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4f508c37c4be93461970) of depth 1 with 3 nodes</span><br></pre></td></tr></table></figure><h1 id="3-随机森林分类器"><a href="#3-随机森林分类器" class="headerlink" title="3. 随机森林分类器"></a>3. 随机森林分类器</h1><p>与DT类似的，只不过选择RF来进行训练，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 16:56</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : random_forest_classifier_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> IndexToString, StringIndexer, VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"RandomForestClassifierExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理方式如DT类似</span></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    labelIndexer = StringIndexer(inputCol=<span class="string">"label"</span>, outputCol=<span class="string">"indexedLabel"</span>).fit(data)</span><br><span class="line">    featureIndexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># TRAIN RF</span></span><br><span class="line">    rf = RandomForestClassifier(labelCol=<span class="string">"indexedLabel"</span>, featuresCol=<span class="string">"indexedFeatures"</span>, numTrees=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将标签的索引转换为原始标签</span></span><br><span class="line">    labelConverter = IndexToString(inputCol=<span class="string">"prediction"</span>, outputCol=<span class="string">"predictedLabel"</span>, labels=labelIndexer.labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在Pipeline中进行整个训练流程</span></span><br><span class="line">    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])</span><br><span class="line"></span><br><span class="line">    model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    predictions.select(<span class="string">"predictedLabel"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    evaluator = MulticlassClassificationEvaluator(labelCol=<span class="string">"indexedLabel"</span>, predictionCol=<span class="string">"prediction"</span>, </span><br><span class="line">                                                  metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    rfModel = model.stages[<span class="number">2</span>]</span><br><span class="line">    print(rfModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+--------------+-----+--------------------+</span><br><span class="line">|predictedLabel|label|            features|</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">|           0.0|  0.0|(692,[98,99,100,1...|</span><br><span class="line">|           0.0|  0.0|(692,[122,123,148...|</span><br><span class="line">|           0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|           0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|           0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Test Error = 0.0294118</span><br><span class="line">RandomForestClassificationModel (uid=RandomForestClassifier_421b9fdfb8d0ee9acde3) with 10 trees</span><br></pre></td></tr></table></figure><h1 id="4-梯度提升树分类器"><a href="#4-梯度提升树分类器" class="headerlink" title="4. 梯度提升树分类器"></a>4. 梯度提升树分类器</h1><p>如前文类似，选用梯度提升树（Gradient-boosted trees, GBTs）来进行训练，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 17:09</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : gradient_boosted_tree_classifier_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> GBTClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer, VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"GradientBoostedTreeClassifierExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    labelIndex = StringIndexer(inputCol=<span class="string">"label"</span>, outputCol=<span class="string">"indexedLabel"</span>).fit(data)</span><br><span class="line">    featureIndexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    gbt = GBTClassifier(labelCol=<span class="string">"indexedLabel"</span>, featuresCol=<span class="string">"indexedFeatures"</span>, maxDepth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在管道中进行整个训练流程</span></span><br><span class="line">    pipeline = Pipeline(stages=[labelIndex, featureIndexer, gbt])</span><br><span class="line">    model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    predictions = model.transform(testData)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"indexedLabel"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算测试误差</span></span><br><span class="line">    evaluator = MulticlassClassificationEvaluator(labelCol=<span class="string">"indexedLabel"</span>, predictionCol=<span class="string">"prediction"</span>,</span><br><span class="line">                                                  metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    gbtModel = model.stages[<span class="number">2</span>]</span><br><span class="line">    print(gbtModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+------------+--------------------+</span><br><span class="line">|prediction|indexedLabel|            features|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">|       1.0|         1.0|(692,[95,96,97,12...|</span><br><span class="line">|       1.0|         1.0|(692,[100,101,102...|</span><br><span class="line">|       1.0|         1.0|(692,[122,123,148...|</span><br><span class="line">|       1.0|         1.0|(692,[123,124,125...|</span><br><span class="line">|       1.0|         1.0|(692,[124,125,126...|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Test Error = 0</span><br><span class="line">GBTClassificationModel (uid=GBTClassifier_4a1fa549ada75fa70795) with 20 trees</span><br></pre></td></tr></table></figure><h1 id="5-多层感知器分类器"><a href="#5-多层感知器分类器" class="headerlink" title="5. 多层感知器分类器"></a>5. 多层感知器分类器</h1><p>多层感知器分类器（Multilayer perceptron classifier, MLPC）是基于前馈人工神经网络的分类器。 MLPC由多层节点组成。 每层完全连接到网络中的下一层。 输入层中的节点表示输入数据。 所有其他节点通过输入与节点权重$w$和偏差$b$的线性组合将输入映射到输出，并应用激活函数。 这可以用矩阵形式写入MLPC，$K + 1$层如下：<br>$$<br>y(x)= f_K（… f_2（w^T_2f_1（w^T_1x+ b_1）+ b_2）… +b_K） \tag{1}<br>$$<br>中间层中的节点使用sigmoid函数：<br>$$<br>f（z_i）= \frac{1}{1+e^{-z_i}} \tag{2}<br>$$<br>输出层中的节点使用softmax函数：<br>$$<br>f（z_i）= \frac{e^{z_i}}{\sum_{k=1}^Ke^{z_K}} \tag{3}<br>$$</p><p>输出层中的节点数$N$对应于类的数量。</p><p>MLPC采用反向传播来学习模型。 我们使用逻辑损失函数进行优化，使用L-BFGS作为优化过程。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 17:30</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : multilayer_perceptron_classification.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> MultilayerPerceptronClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"multilayer_perceptron_classification_example"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line">    (train_data, test_data) = data.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], seed=<span class="number">2019</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输入层为features的大小(4)，输出层为labels的大小(3)</span></span><br><span class="line">    layers = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    trainer = MultilayerPerceptronClassifier(maxIter=<span class="number">100</span>, layers=layers, blockSize=<span class="number">128</span>, seed=<span class="number">2019</span>)</span><br><span class="line">    model = trainer.fit(train_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算在测试集上的准确率</span></span><br><span class="line">    predictions = model.transform(test_data)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line">    evaluator = MulticlassClassificationEvaluator(labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>,</span><br><span class="line">                                                  metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line">    print(model)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       0.0|  0.0|(4,[0,1,2,3],[-0....|</span><br><span class="line">|       0.0|  0.0|(4,[0,1,2,3],[-0....|</span><br><span class="line">|       0.0|  0.0|(4,[0,1,2,3],[0.0...|</span><br><span class="line">|       0.0|  0.0|(4,[0,1,2,3],[0.0...|</span><br><span class="line">|       0.0|  0.0|(4,[0,1,2,3],[0.1...|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Test Error = 0.0172414</span><br><span class="line">MultilayerPerceptronClassifier_4f01847fd0f3f4531e41</span><br></pre></td></tr></table></figure><h1 id="6-线性支持向量机"><a href="#6-线性支持向量机" class="headerlink" title="6. 线性支持向量机"></a>6. 线性支持向量机</h1><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 17:48</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : linearsvc.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> BinaryClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"linearSVC Example"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    (trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>], seed=<span class="number">2019</span>)</span><br><span class="line">    lsvc = LinearSVC(maxIter=<span class="number">10</span>, regParam=<span class="number">0.1</span>)</span><br><span class="line">    lsvcModel = lsvc.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print("Coefficients: " + str(lsvcModel.coefficients))</span></span><br><span class="line">    <span class="comment"># print("Intercept: " + str(lsvcModel.intercept))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算在测试集上的准确率</span></span><br><span class="line">    predictions = lsvcModel.transform(testData)</span><br><span class="line">    predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line">    evaluator = BinaryClassificationEvaluator(labelCol=<span class="string">"label"</span>, rawPredictionCol=<span class="string">"prediction"</span>, </span><br><span class="line">                                              metricName=<span class="string">"areaUnderROC"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line">    print(lsvcModel)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       0.0|  0.0|(692,[100,101,102...|</span><br><span class="line">|       0.0|  0.0|(692,[121,122,123...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">|       0.0|  0.0|(692,[124,125,126...|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Test Error = 0</span><br><span class="line">LinearSVC_409bb95a7222b3ec2faa</span><br></pre></td></tr></table></figure><h1 id="7-One-vs-Rest分类器"><a href="#7-One-vs-Rest分类器" class="headerlink" title="7. One-vs-Rest分类器"></a>7. One-vs-Rest分类器</h1><p>OneVsRest作为Estimator实现。 对于基类分类器，它接受分类器的实例，并为每个k类创建二进制分类问题。 训练i类的分类器来预测标签是否为i，将类i与所有其他类区分开来。通过评估每个二元分类器来完成预测，并且将自信(most confident)的分类器的索引输出为标签。</p><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 18:05</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : one_vs_rest_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression, OneVsRest</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"OneVsRestExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    inputData = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    (train, test) = inputData.randomSplit([<span class="number">0.8</span>, <span class="number">0.2</span>], seed=<span class="number">2019</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个分类器</span></span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, tol=<span class="number">1E-6</span>, fitIntercept=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 实例化One Vs Rest分类器</span></span><br><span class="line">    ovr = OneVsRest(classifier=lr)</span><br><span class="line">    ovrModel = ovr.fit(train)</span><br><span class="line"></span><br><span class="line">    predictions = ovrModel.transform(test)</span><br><span class="line">    evaluator = MulticlassClassificationEvaluator(metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test Error = 0.030303</span><br></pre></td></tr></table></figure><h1 id="8-朴素贝叶斯"><a href="#8-朴素贝叶斯" class="headerlink" title="8. 朴素贝叶斯"></a>8. 朴素贝叶斯</h1><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/5 20:08</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : naive_bayes_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> NaiveBayes</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">"NaiveBayesExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    splits = data.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], seed=<span class="number">2019</span>)</span><br><span class="line">    train = splits[<span class="number">0</span>]</span><br><span class="line">    test = splits[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    nb = NaiveBayes(smoothing=<span class="number">1.0</span>, modelType=<span class="string">"multinomial"</span>)</span><br><span class="line">    model = nb.fit(train)</span><br><span class="line"></span><br><span class="line">    predictions = model.transform(test)</span><br><span class="line">    predictions.show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    evaluator = MulticlassClassificationEvaluator(labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">    accuracy = evaluator.evaluate(predictions)</span><br><span class="line">    print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------------------+--------------------+-----------+----------+</span><br><span class="line">|label|            features|       rawPrediction|probability|prediction|</span><br><span class="line">+-----+--------------------+--------------------+-----------+----------+</span><br><span class="line">|  0.0|(692,[100,101,102...|[-98334.092010814...|  [1.0,0.0]|       0.0|</span><br><span class="line">|  0.0|(692,[121,122,123...|[-220853.86656723...|  [1.0,0.0]|       0.0|</span><br><span class="line">|  0.0|(692,[124,125,126...|[-244907.22501172...|  [1.0,0.0]|       0.0|</span><br><span class="line">|  0.0|(692,[124,125,126...|[-149338.93024598...|  [1.0,0.0]|       0.0|</span><br><span class="line">|  0.0|(692,[124,125,126...|[-216105.12197743...|  [1.0,0.0]|       0.0|</span><br><span class="line">+-----+--------------------+--------------------+-----------+----------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">Test Error = 0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本节主要讲Spark ML中关于分类算法的实现。示例的算法Demo包含：LR、DT、RF、GBTs、多层感知器、线性支持向量机、One-vs-Rest分类器以及NB等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】特征工程2-Transformers</title>
    <link href="https://buracagyang.github.io/2019/07/31/spark-features-project-2/"/>
    <id>https://buracagyang.github.io/2019/07/31/spark-features-project-2/</id>
    <published>2019-07-31T06:37:16.000Z</published>
    <updated>2019-08-09T02:32:29.762Z</updated>
    
    <content type="html"><![CDATA[<p>Spark MLlib中关于特征处理的相关算法，大致分为以下几组：</p><ul><li>提取(Extraction)：从“原始”数据中提取特征</li><li>转换(Transformation)：缩放，转换或修改特征</li><li>选择(Selection)：从较大的一组特征中选择一个子集</li><li>局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。</li></ul><p>本文介绍第二组： 特征转换器(Transformers)</p><a id="more"></a><h1 id="1-特征转换器"><a href="#1-特征转换器" class="headerlink" title="1. 特征转换器"></a>1. 特征转换器</h1><h2 id="1-1-分词器-Tokenizer"><a href="#1-1-分词器-Tokenizer" class="headerlink" title="1.1 分词器(Tokenizer)"></a>1.1 分词器(Tokenizer)</h2><p>标记化(Tokenization)是将文本（例如句子）分解为单个术语（通常是单词）的过程。 一个简单的Tokenizer类提供此功能。 下面的示例显示了如何将句子拆分为单词序列。</p><p>RegexTokenizer允许基于正则表达式（正则表达式）匹配的更高级标记化。 默认情况下，参数“pattern”（正则表达式，默认值：“\\s +”）用作分隔输入文本的分隔符。 或者，用户可以将参数“gap”设置为false，指示正则表达式“pattern”表示“令牌”而不是分割间隙，并找到所有匹配的出现作为标记化结果。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:58</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : tokenizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Tokenizer, RegexTokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col, udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> IntegerType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"TokenizerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    sentenceDataFrame = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="string">"Hi I heard about Spark"</span>),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">"I wish Java could use case classes"</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">"Logistic,regression,models,are,neat"</span>)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"sentence"</span>])</span><br><span class="line"></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line"></span><br><span class="line">    regexTokenizer = RegexTokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>, pattern=<span class="string">"\\W"</span>)</span><br><span class="line">    <span class="comment"># 也可以选择， pattern="\\w+", gaps(False)</span></span><br><span class="line"></span><br><span class="line">    countTokens = udf(<span class="keyword">lambda</span> words: len(words), IntegerType())</span><br><span class="line"></span><br><span class="line">    tokenized = tokenizer.transform(sentenceDataFrame)</span><br><span class="line">    tokenized.select(<span class="string">"sentence"</span>, <span class="string">"words"</span>).withColumn(<span class="string">"tokens"</span>, countTokens(col(<span class="string">"words"</span>))).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    regexTokenized = regexTokenizer.transform(sentenceDataFrame)</span><br><span class="line">    regexTokenized.select(<span class="string">"sentence"</span>, <span class="string">"words"</span>).withColumn(<span class="string">"tokens"</span>, countTokens(col(<span class="string">"words"</span>))).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|sentence                           |words                                     |tokens|</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |</span><br><span class="line">|I wish Java could use <span class="keyword">case</span> classes |[i, wish, java, could, use, <span class="keyword">case</span>, classes]|7     |</span><br><span class="line">|Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|sentence                           |words                                     |tokens|</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |</span><br><span class="line">|I wish Java could use <span class="keyword">case</span> classes |[i, wish, java, could, use, <span class="keyword">case</span>, classes]|7     |</span><br><span class="line">|Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br></pre></td></tr></table></figure><h2 id="1-2-StopWordsRemover"><a href="#1-2-StopWordsRemover" class="headerlink" title="1.2 StopWordsRemover"></a>1.2 StopWordsRemover</h2><p>停用词是应该从输入中排除的词，通常是因为词经常出现而且没有那么多含义。</p><p>StopWordsRemover将字符串序列（例如，Tokenizer的输出）作为输入，并从输入序列中删除所有停用词。 停用词列表由stopWords参数指定。 通过调用StopWordsRemover.loadDefaultStopWords（语言）可以访问某些语言的默认停用词，其中可用选项为“danish”，“dutch”，“english”，“finnish”，“french”，“german”，“hungarian”，italian”, “norwegian”, “portuguese”, “russian”, “spanish”, “swedish” and “turkish”。 布尔参数caseSensitive指示匹配项是否区分大小写（默认为false）。</p><p><strong>举例</strong></p><p>假设我们有以下具有列id和raw的DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">id | raw</span><br><span class="line">----|----------</span><br><span class="line"> 0  | [I, saw, the, red, baloon]</span><br><span class="line"> 1  | [Mary, had, a, little, lamb]</span><br></pre></td></tr></table></figure><p>经过停用词处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 17:26</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : stopwords_remover_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StopWordsRemover</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"StopWordsRemoverExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    sentenceData = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, [<span class="string">"I"</span>, <span class="string">"saw"</span>, <span class="string">"the"</span>, <span class="string">"red"</span>, <span class="string">"balloon"</span>]),</span><br><span class="line">        (<span class="number">1</span>, [<span class="string">"Mary"</span>, <span class="string">"had"</span>, <span class="string">"a"</span>, <span class="string">"little"</span>, <span class="string">"lamb"</span>])</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"raw"</span>])</span><br><span class="line"></span><br><span class="line">    remover = StopWordsRemover(inputCol=<span class="string">"raw"</span>, outputCol=<span class="string">"filtered"</span>)</span><br><span class="line">    remover.transform(sentenceData).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+----------------------------+--------------------+</span><br><span class="line">|id |raw                         |filtered            |</span><br><span class="line">+---+----------------------------+--------------------+</span><br><span class="line">|0  |[I, saw, the, red, balloon] |[saw, red, balloon] |</span><br><span class="line">|1  |[Mary, had, a, little, lamb]|[Mary, little, lamb]|</span><br><span class="line">+---+----------------------------+--------------------+</span><br></pre></td></tr></table></figure><h2 id="1-3-n-gram"><a href="#1-3-n-gram" class="headerlink" title="1.3 n-gram"></a>1.3 n-gram</h2><p>对于某些整数n，n-gram是n个tokens（通常是单词）的序列。 NGram类可用于将输入要素转换为n-gram。</p><p>NGram将字符串序列（例如，Tokenizer的输出）作为输入。 参数n用于确定每个n-gram中的项数。 输出将由一系列n-gram组成，其中每个n-gram由n个连续单词的空格分隔的字符串表示。 如果输入序列包含少于n个字符串，则不会生成输出。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 17:32</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : n_gram_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> NGram</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"NGramExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    wordDataFrame = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, [<span class="string">"Hi"</span>, <span class="string">"I"</span>, <span class="string">"heard"</span>, <span class="string">"about"</span>, <span class="string">"Spark"</span>]),</span><br><span class="line">        (<span class="number">1</span>, [<span class="string">"I"</span>, <span class="string">"wish"</span>, <span class="string">"Java"</span>, <span class="string">"could"</span>, <span class="string">"use"</span>, <span class="string">"case"</span>, <span class="string">"classes"</span>]),</span><br><span class="line">        (<span class="number">2</span>, [<span class="string">"Logistic"</span>, <span class="string">"regression"</span>, <span class="string">"models"</span>, <span class="string">"are"</span>, <span class="string">"neat"</span>])</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"words"</span>])</span><br><span class="line"></span><br><span class="line">    ngram = NGram(n=<span class="number">2</span>, inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"ngrams"</span>)</span><br><span class="line"></span><br><span class="line">    ngramDataFrame = ngram.transform(wordDataFrame)</span><br><span class="line">    ngramDataFrame.select(<span class="string">"ngrams"</span>).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+------------------------------------------------------------------+</span><br><span class="line">|ngrams                                                            |</span><br><span class="line">+------------------------------------------------------------------+</span><br><span class="line">|[Hi I, I heard, heard about, about Spark]                         |</span><br><span class="line">|[I wish, wish Java, Java could, could use, use <span class="keyword">case</span>, <span class="keyword">case</span> classes]|</span><br><span class="line">|[Logistic regression, regression models, models are, are neat]    |</span><br><span class="line">+------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h2 id="1-4-二元化-Binarizer"><a href="#1-4-二元化-Binarizer" class="headerlink" title="1.4 二元化(Binarizer)"></a>1.4 二元化(Binarizer)</h2><p>二元化是将数值特征阈值化为二元（0/1）特征的过程。</p><p>Binarizer采用公共参数inputCol和outputCol，以及二元化的阈值。 大于阈值的特征值被二进制化为1.0; 小于等于阈值的值被二值化为0.0。 inputCol支持Vector和Double类型。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 17:36</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : binarizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Binarizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"BinarizerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    continuousDataFrame = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="number">0.1</span>),</span><br><span class="line">        (<span class="number">1</span>, <span class="number">0.8</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="number">0.2</span>)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"feature"</span>])</span><br><span class="line"></span><br><span class="line">    binarizer = Binarizer(threshold=<span class="number">0.5</span>, inputCol=<span class="string">"feature"</span>, outputCol=<span class="string">"binarized_feature"</span>)</span><br><span class="line">    binarizedDataFrame = binarizer.transform(continuousDataFrame)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Binarizer output with Threshold = %f"</span> % binarizer.getThreshold())</span><br><span class="line">    binarizedDataFrame.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Binarizer output with Threshold = 0.500000</span><br><span class="line">+---+-------+-----------------+</span><br><span class="line">| id|feature|binarized_feature|</span><br><span class="line">+---+-------+-----------------+</span><br><span class="line">|  0|    0.1|              0.0|</span><br><span class="line">|  1|    0.8|              1.0|</span><br><span class="line">|  2|    0.2|              0.0|</span><br><span class="line">+---+-------+-----------------+</span><br></pre></td></tr></table></figure><h2 id="1-5-主成分分析-PCA"><a href="#1-5-主成分分析-PCA" class="headerlink" title="1.5 主成分分析(PCA)"></a>1.5 主成分分析(PCA)</h2><p>PCA是一种统计过程，它使用正交变换将可能相关变量的一组观察值转换为称为主成分的线性不相关变量的一组值。 PCA类使用PCA训练模型以将向量映射到低维空间。 下面的示例显示了如何将5维特征向量映射到3维主成分中。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 17:39</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : pca_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"PCAExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = [(Vectors.sparse(<span class="number">5</span>, [(<span class="number">1</span>, <span class="number">1.0</span>), (<span class="number">3</span>, <span class="number">7.0</span>)]),),</span><br><span class="line">            (Vectors.dense([<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>]),),</span><br><span class="line">            (Vectors.dense([<span class="number">4.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>]),)]</span><br><span class="line">    df = spark.createDataFrame(data, [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    pca = PCA(k=<span class="number">3</span>, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"pcaFeatures"</span>)</span><br><span class="line">    model = pca.fit(df)</span><br><span class="line"></span><br><span class="line">    result = model.transform(df).select(<span class="string">"pcaFeatures"</span>)</span><br><span class="line">    result.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------------------------------------------+</span><br><span class="line">|pcaFeatures                                                |</span><br><span class="line">+-----------------------------------------------------------+</span><br><span class="line">|[1.6485728230883807,-4.013282700516296,-5.524543751369388] |</span><br><span class="line">|[-4.645104331781534,-1.1167972663619026,-5.524543751369387]|</span><br><span class="line">|[-6.428880535676489,-5.337951427775355,-5.524543751369389] |</span><br><span class="line">+-----------------------------------------------------------+</span><br></pre></td></tr></table></figure><h2 id="1-6-多项式扩展-PolynomialExpansion"><a href="#1-6-多项式扩展-PolynomialExpansion" class="headerlink" title="1.6 多项式扩展(PolynomialExpansion)"></a>1.6 多项式扩展(PolynomialExpansion)</h2><p>多项式展开是将要素扩展为多项式空间的过程，该多项式空间由原始维度的n度组合制定。 PolynomialExpansion类提供此功能。 以下示例显示如何将特征扩展为3度多项式空间。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 17:44</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : polynomial_expansion_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> PolynomialExpansion</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"PolynomialExpansionExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">        (Vectors.dense([<span class="number">0.0</span>, <span class="number">0.0</span>]),),</span><br><span class="line">        (Vectors.dense([<span class="number">3.0</span>, <span class="number">-1.0</span>]),)</span><br><span class="line">    ], [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    polyExpansion = PolynomialExpansion(degree=<span class="number">3</span>, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"polyFeatures"</span>)</span><br><span class="line">    polyDF = polyExpansion.transform(df)</span><br><span class="line"></span><br><span class="line">    polyDF.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------+------------------------------------------+</span><br><span class="line">|features  |polyFeatures                              |</span><br><span class="line">+----------+------------------------------------------+</span><br><span class="line">|[2.0,1.0] |[2.0,4.0,8.0,1.0,2.0,4.0,1.0,2.0,1.0]     |</span><br><span class="line">|[0.0,0.0] |[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]     |</span><br><span class="line">|[3.0,-1.0]|[3.0,9.0,27.0,-1.0,-3.0,-9.0,1.0,3.0,-1.0]|</span><br><span class="line">+----------+------------------------------------------+</span><br></pre></td></tr></table></figure><p>简单解释一下：</p><p>原始特征: $x_1$, $x_2$</p><p>二阶多项式的展开部分：$x_1^2$, $x_1x_2$, $x_2^2$</p><p>三阶多项式的展开部分：$x_1^2x_2$, $x_1x_2^2$, $x_1^3$, $x_2^3$</p><p>所以得到,</p><p>二阶多项式扩展为： 原始特征 + 二阶多项式的展开部分</p><p>三阶多项式扩展为： 原始特征 + 二阶多项式的展开部分 + 三阶多项式的展开部分</p><h2 id="1-7-离散余弦距离-Discrete-Cosine-Transform-DCT"><a href="#1-7-离散余弦距离-Discrete-Cosine-Transform-DCT" class="headerlink" title="1.7 离散余弦距离(Discrete Cosine Transform, DCT)"></a>1.7 离散余弦距离(Discrete Cosine Transform, DCT)</h2><p>离散余弦变换将时域中的长度N实值序列变换为频域中的另一长度N实值序列。 DCT类提供此功能，实现DCT-II并将结果缩放$\frac{1}{\sqrt{2}}$，使得变换的表示矩阵是单一的。应用于变换序列没有移位（例如，变换序列的第0个元素是第0个DCT系数而不是N / 2个）。</p><p> <strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 17:59</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : dct_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> DCT</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"DCTExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (Vectors.dense([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">-2.0</span>, <span class="number">3.0</span>]),),</span><br><span class="line">        (Vectors.dense([<span class="number">-1.0</span>, <span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">-7.0</span>]),),</span><br><span class="line">        (Vectors.dense([<span class="number">14.0</span>, <span class="number">-2.0</span>, <span class="number">-5.0</span>, <span class="number">1.0</span>]),)], [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    dct = DCT(inverse=<span class="literal">False</span>, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"featuresDCT"</span>)</span><br><span class="line">    dctDf = dct.transform(df)</span><br><span class="line"></span><br><span class="line">    dctDf.select(<span class="string">"featuresDCT"</span>).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------------------------------------------+</span><br><span class="line">|featuresDCT                                                     |</span><br><span class="line">+----------------------------------------------------------------+</span><br><span class="line">|[1.0,-1.1480502970952693,2.0000000000000004,-2.7716385975338604]|</span><br><span class="line">|[-1.0,3.378492794482933,-7.000000000000001,2.9301512653149677]  |</span><br><span class="line">|[4.0,9.304453421915744,11.000000000000002,1.5579302036357163]   |</span><br><span class="line">+----------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h2 id="1-8-字符串索引器-StringIndexer"><a href="#1-8-字符串索引器-StringIndexer" class="headerlink" title="1.8 字符串索引器(StringIndexer)"></a>1.8 字符串索引器(StringIndexer)</h2><p>StringIndexer将标签的字符串列编码为标签索引列。 索引在[0，numLabels)中，按标签频率排序，因此最常见的标签得到索引0。如果用户选择保留它们，则看不见的标签将被放在索引numLabels处。 如果输入列是数字，我们将其转换为字符串并索引字符串值。 当下游管道组件（如Estimator或Transformer）使用此字符串索引标签时，必须将组件的输入列设置为此字符串索引列名称。 在许多情况下，您可以使用setInputCol设置输入列。</p><p><strong>举例</strong></p><p>假设我们有以下DataFrame，列id和类别：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">id | category</span><br><span class="line">----|----------</span><br><span class="line"> 0  | a</span><br><span class="line"> 1  | b</span><br><span class="line"> 2  | c</span><br><span class="line"> 3  | a</span><br><span class="line"> 4  | a</span><br><span class="line"> 5  | c</span><br></pre></td></tr></table></figure><p>category是一个包含三个标签的字符串列：“a”，“b”和“c”。 使用StringIndexer作为输入列，categoryIndex作为输出列，我们应该得到以下结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> id | category | categoryIndex</span><br><span class="line">----|----------|---------------</span><br><span class="line"> 0  | a        | 0.0</span><br><span class="line"> 1  | b        | 2.0</span><br><span class="line"> 2  | c        | 1.0</span><br><span class="line"> 3  | a        | 0.0</span><br><span class="line"> 4  | a        | 0.0</span><br><span class="line"> 5  | c        | 1.0</span><br></pre></td></tr></table></figure><p>“a”得到索引0，因为它是最常见的，其次是索引1的“c”和索引2的“b”。</p><p>此外，当您在一个数据集上使用StringIndexer然后使用它来转换另一个数据集时，有三种策略可以解决StringIndexer如何处理看不见的标签：</p><ul><li>抛出异常（这是默认值）</li><li>完全跳过包含看不见的标签的行, “skip”</li><li>将看不见的标签放在索引numLabels的特殊附加存储桶中, “keep”</li></ul><p><strong>举例</strong></p><p>让我们回到之前的示例，但这次重用我们之前在以下数据集上定义的StringIndexer：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> id | category</span><br><span class="line">----|----------</span><br><span class="line"> 0  | a</span><br><span class="line"> 1  | b</span><br><span class="line"> 2  | c</span><br><span class="line"> 3  | d</span><br><span class="line"> 4  | e</span><br></pre></td></tr></table></figure><p>如果您没有设置StringIndexer如何处理看不见的标签或将其设置为“error”，则会抛出异常。 但是，如果您调用了setHandleInvalid<strong>（“skip”）</strong>，则将生成以下数据集：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> id | category | categoryIndex</span><br><span class="line">----|----------|---------------</span><br><span class="line"> 0  | a        | 0.0</span><br><span class="line"> 1  | b        | 2.0</span><br><span class="line"> 2  | c        | 1.0</span><br></pre></td></tr></table></figure><p>请注意，不显示包含“d”或“e”的行。如果调用setHandleInvalid<strong>（“keep”）</strong>，将生成以下数据集：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> id | category | categoryIndex</span><br><span class="line">----|----------|---------------</span><br><span class="line"> 0  | a        | 0.0</span><br><span class="line"> 1  | b        | 2.0</span><br><span class="line"> 2  | c        | 1.0</span><br><span class="line"> 3  | d        | 3.0</span><br><span class="line"> 4  | e        | 3.0</span><br></pre></td></tr></table></figure><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 18:11</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : string_indexer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"StringIndexerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame(</span><br><span class="line">        [(<span class="number">0</span>, <span class="string">"a"</span>), (<span class="number">1</span>, <span class="string">"b"</span>), (<span class="number">2</span>, <span class="string">"c"</span>), (<span class="number">3</span>, <span class="string">"a"</span>), (<span class="number">4</span>, <span class="string">"a"</span>), (<span class="number">5</span>, <span class="string">"c"</span>)],</span><br><span class="line">        [<span class="string">"id"</span>, <span class="string">"category"</span>])</span><br><span class="line"></span><br><span class="line">    indexer = StringIndexer(inputCol=<span class="string">"category"</span>, outputCol=<span class="string">"categoryIndex"</span>)</span><br><span class="line">    indexed = indexer.fit(df).transform(df)</span><br><span class="line">    indexed.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><h2 id="1-9-IndexToString"><a href="#1-9-IndexToString" class="headerlink" title="1.9 IndexToString"></a>1.9 IndexToString</h2><p>与StringIndexer相反，IndexToString将一列标签索引映射回包含原始标签作为字符串的列。 一个常见的用例是使用StringIndexer从标签生成索引，使用这些索引训练模型，并使用IndexToString从预测索引列中检索原始标签。 但是，您可以自由提供自己的标签。</p><p><strong>举例</strong></p><p>将categoryIndex作为输入列应用IndexToString，将originalCategory作为输出列，我们可以检索原始标签（它们将从列的元数据中推断出来）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 18:59</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : index_to_string_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> IndexToString, StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"IndexToStringExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame(</span><br><span class="line">        [(<span class="number">0</span>, <span class="string">"a"</span>), (<span class="number">1</span>, <span class="string">"b"</span>), (<span class="number">2</span>, <span class="string">"c"</span>), (<span class="number">3</span>, <span class="string">"a"</span>), (<span class="number">4</span>, <span class="string">"a"</span>), (<span class="number">5</span>, <span class="string">"c"</span>)],</span><br><span class="line">        [<span class="string">"id"</span>, <span class="string">"category"</span>])</span><br><span class="line"></span><br><span class="line">    indexer = StringIndexer(inputCol=<span class="string">"category"</span>, outputCol=<span class="string">"categoryIndex"</span>)</span><br><span class="line">    model = indexer.fit(df)</span><br><span class="line">    indexed = model.transform(df)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Transformed string column '%s' to indexed column '%s'"</span> % (indexer.getInputCol(), indexer.getOutputCol()))</span><br><span class="line">    indexed.show()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"StringIndexer will store labels in output column metadata\n"</span>)</span><br><span class="line"></span><br><span class="line">    converter = IndexToString(inputCol=<span class="string">"categoryIndex"</span>, outputCol=<span class="string">"originalCategory"</span>)</span><br><span class="line">    converted = converter.transform(indexed)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Transformed indexed column '%s' back to original string column '%s' using "</span></span><br><span class="line">          <span class="string">"labels in metadata"</span> % (converter.getInputCol(), converter.getOutputCol()))</span><br><span class="line">    converted.select(<span class="string">"id"</span>, <span class="string">"categoryIndex"</span>, <span class="string">"originalCategory"</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Transformed string column <span class="string">'category'</span> to indexed column <span class="string">'categoryIndex'</span></span><br><span class="line">+---+--------+-------------+</span><br><span class="line">| id|category|categoryIndex|</span><br><span class="line">+---+--------+-------------+</span><br><span class="line">|  0|       a|          0.0|</span><br><span class="line">|  1|       b|          2.0|</span><br><span class="line">|  2|       c|          1.0|</span><br><span class="line">|  3|       a|          0.0|</span><br><span class="line">|  4|       a|          0.0|</span><br><span class="line">|  5|       c|          1.0|</span><br><span class="line">+---+--------+-------------+</span><br><span class="line"></span><br><span class="line">StringIndexer will store labels <span class="keyword">in</span> output column metadata</span><br><span class="line"></span><br><span class="line">Transformed indexed column <span class="string">'categoryIndex'</span> back to original string column <span class="string">'originalCategory'</span> using labels <span class="keyword">in</span> metadata</span><br><span class="line">+---+-------------+----------------+</span><br><span class="line">| id|categoryIndex|originalCategory|</span><br><span class="line">+---+-------------+----------------+</span><br><span class="line">|  0|          0.0|               a|</span><br><span class="line">|  1|          2.0|               b|</span><br><span class="line">|  2|          1.0|               c|</span><br><span class="line">|  3|          0.0|               a|</span><br><span class="line">|  4|          0.0|               a|</span><br><span class="line">|  5|          1.0|               c|</span><br><span class="line">+---+-------------+----------------+</span><br></pre></td></tr></table></figure><h2 id="1-10-One-Hot-OneHotEncoderEstimator"><a href="#1-10-One-Hot-OneHotEncoderEstimator" class="headerlink" title="1.10 One-Hot(OneHotEncoderEstimator)"></a>1.10 One-Hot(OneHotEncoderEstimator)</h2><p>One-hot编码将表示为标签索引的分类特征映射到二进制向量，该二进制向量具有至多单个一个值，该值表示所有特征值集合中存在特定特征值。 此编码允许期望连续特征（例如Logistic回归）的算法使用分类特征。 对于字符串类型输入数据，通常首先使用StringIndexer对分类特征进行编码。</p><p>OneHotEncoderEstimator可以转换多个列，为每个输入列返回一个热编码的输出向量列。 通常使用VectorAssembler将这些向量合并为单个特征向量。</p><p>OneHotEncoderEstimator支持handleInvalid参数，以选择在转换数据期间如何处理无效输入。 可用选项包括’keep’（任何无效输入分配给额外的分类索引）和’error’（抛出错误）。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 19:05</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : onehot_encoder_estimator_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoderEstimator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"OneHotEncoderEstimatorExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分类特征通常先用StringIndexer先进行编码</span></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0.0</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">1.0</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">2.0</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">0.0</span>, <span class="number">2.0</span>),</span><br><span class="line">        (<span class="number">0.0</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">2.0</span>, <span class="number">0.0</span>)</span><br><span class="line">    ], [<span class="string">"categoryIndex1"</span>, <span class="string">"categoryIndex2"</span>])</span><br><span class="line"></span><br><span class="line">    encoder = OneHotEncoderEstimator(inputCols=[<span class="string">"categoryIndex1"</span>, <span class="string">"categoryIndex2"</span>],</span><br><span class="line">                                     outputCols=[<span class="string">"categoryVec1"</span>, <span class="string">"categoryVec2"</span>])</span><br><span class="line">    model = encoder.fit(df)</span><br><span class="line">    encoded = model.transform(df)</span><br><span class="line">    encoded.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------+--------------+-------------+-------------+</span><br><span class="line">|categoryIndex1|categoryIndex2| categoryVec1| categoryVec2|</span><br><span class="line">+--------------+--------------+-------------+-------------+</span><br><span class="line">|           0.0|           1.0|(2,[0],[1.0])|(2,[1],[1.0])|</span><br><span class="line">|           1.0|           0.0|(2,[1],[1.0])|(2,[0],[1.0])|</span><br><span class="line">|           2.0|           1.0|    (2,[],[])|(2,[1],[1.0])|</span><br><span class="line">|           0.0|           2.0|(2,[0],[1.0])|    (2,[],[])|</span><br><span class="line">|           0.0|           1.0|(2,[0],[1.0])|(2,[1],[1.0])|</span><br><span class="line">|           2.0|           0.0|    (2,[],[])|(2,[0],[1.0])|</span><br><span class="line">+--------------+--------------+-------------+-------------+</span><br></pre></td></tr></table></figure><h2 id="1-11-矢量索引器-VectorIndexer"><a href="#1-11-矢量索引器-VectorIndexer" class="headerlink" title="1.11 矢量索引器(VectorIndexer)"></a>1.11 矢量索引器(VectorIndexer)</h2><p>VectorIndexer帮助索引Vectors的数据集中的分类特征。它既可以自动决定哪些特征是分类的，也可以将原始值转换为类别索引。具体来说，它执行以下操作：</p><ol><li>获取Vector类型的输入列和参数maxCategories。</li><li>根据不同值的数量确定哪些要素应该是分类的，其中最多maxCategories的要素被声明为分类。为每个分类特征计算基于0的类别索引。</li><li>索引分类要素并将原始要素值转换为索引。</li><li>索引分类特征允许决策树和树集合等算法适当地处理分类特征，从而提高性能。</li></ol><p><strong>举例</strong></p><p>在下面的示例中，我们读入标记点的数据集，然后使用VectorIndexer确定哪些要素应被视为分类。我们将分类特征值转换为它们的索引。然后，可以将转换后的数据传递给处理分类特征的DecisionTreeRegressor等算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 19:11</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : vector_indexer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"VectorIndexerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    indexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexed"</span>, maxCategories=<span class="number">10</span>)</span><br><span class="line">    indexerModel = indexer.fit(data)</span><br><span class="line"></span><br><span class="line">    categoricalFeatures = indexerModel.categoryMaps</span><br><span class="line">    print(<span class="string">"Chose %d categorical features: %s"</span> %</span><br><span class="line">          (len(categoricalFeatures), <span class="string">", "</span>.join(str(k) <span class="keyword">for</span> k <span class="keyword">in</span> categoricalFeatures.keys())))</span><br><span class="line"></span><br><span class="line">    indexedData = indexerModel.transform(data)</span><br><span class="line">    indexedData.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">|label|            features|             indexed|</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">|  0.0|(692,[127,128,129...|(692,[127,128,129...|</span><br><span class="line">|  1.0|(692,[158,159,160...|(692,[158,159,160...|</span><br><span class="line">|  1.0|(692,[124,125,126...|(692,[124,125,126...|</span><br><span class="line">|  1.0|(692,[152,153,154...|(692,[152,153,154...|</span><br><span class="line">|  1.0|(692,[151,152,153...|(692,[151,152,153...|</span><br><span class="line">|  0.0|(692,[129,130,131...|(692,[129,130,131...|</span><br><span class="line">|  1.0|(692,[158,159,160...|(692,[158,159,160...|</span><br><span class="line">|  1.0|(692,[99,100,101,...|(692,[99,100,101,...|</span><br><span class="line">|  0.0|(692,[154,155,156...|(692,[154,155,156...|</span><br><span class="line">|  0.0|(692,[127,128,129...|(692,[127,128,129...|</span><br><span class="line">|  1.0|(692,[154,155,156...|(692,[154,155,156...|</span><br><span class="line">|  0.0|(692,[153,154,155...|(692,[153,154,155...|</span><br><span class="line">|  0.0|(692,[151,152,153...|(692,[151,152,153...|</span><br><span class="line">|  1.0|(692,[129,130,131...|(692,[129,130,131...|</span><br><span class="line">|  0.0|(692,[154,155,156...|(692,[154,155,156...|</span><br><span class="line">|  1.0|(692,[150,151,152...|(692,[150,151,152...|</span><br><span class="line">|  0.0|(692,[124,125,126...|(692,[124,125,126...|</span><br><span class="line">|  0.0|(692,[152,153,154...|(692,[152,153,154...|</span><br><span class="line">|  1.0|(692,[97,98,99,12...|(692,[97,98,99,12...|</span><br><span class="line">|  1.0|(692,[124,125,126...|(692,[124,125,126...|</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><h2 id="1-12-交互作用-Interaction"><a href="#1-12-交互作用-Interaction" class="headerlink" title="1.12 交互作用(Interaction)"></a>1.12 交互作用(Interaction)</h2><p>Interaction是一个Transformer，它接收向量或双值列，并生成一个向量列，其中包含每个输入列中一个值的所有组合的乘积。</p><p>例如，如果您有2个矢量类型列，每个列都有3个维度作为输入列，那么您将获得9维向量作为输出列。</p><p><strong>举例</strong></p><p>假设我们有以下DataFrame，其列为“id1”，“vec1”和“vec2”：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">id1|vec1          |vec2          </span><br><span class="line">---|--------------|--------------</span><br><span class="line">1  |[1.0,2.0,3.0] |[8.0,4.0,5.0] </span><br><span class="line">2  |[4.0,3.0,8.0] |[7.0,9.0,8.0] </span><br><span class="line">3  |[6.0,1.0,9.0] |[2.0,3.0,6.0] </span><br><span class="line">4  |[10.0,8.0,6.0]|[9.0,4.0,5.0] </span><br><span class="line">5  |[9.0,2.0,7.0] |[10.0,7.0,3.0]</span><br><span class="line">6  |[1.0,1.0,4.0] |[2.0,8.0,4.0]</span><br></pre></td></tr></table></figure><p>将交互应用于这些输入列，然后将interactedCol作为输出列包含:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">id1|vec1          |vec2          |interactedCol                                         </span><br><span class="line">---|--------------|--------------|------------------------------------------------------</span><br><span class="line"><span class="number">1</span>  |[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>] |[<span class="number">8.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>] |[<span class="number">8.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">16.0</span>,<span class="number">8.0</span>,<span class="number">10.0</span>,<span class="number">24.0</span>,<span class="number">12.0</span>,<span class="number">15.0</span>]            </span><br><span class="line"><span class="number">2</span>  |[<span class="number">4.0</span>,<span class="number">3.0</span>,<span class="number">8.0</span>] |[<span class="number">7.0</span>,<span class="number">9.0</span>,<span class="number">8.0</span>] |[<span class="number">56.0</span>,<span class="number">72.0</span>,<span class="number">64.0</span>,<span class="number">42.0</span>,<span class="number">54.0</span>,<span class="number">48.0</span>,<span class="number">112.0</span>,<span class="number">144.0</span>,<span class="number">128.0</span>]     </span><br><span class="line"><span class="number">3</span>  |[<span class="number">6.0</span>,<span class="number">1.0</span>,<span class="number">9.0</span>] |[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">6.0</span>] |[<span class="number">36.0</span>,<span class="number">54.0</span>,<span class="number">108.0</span>,<span class="number">6.0</span>,<span class="number">9.0</span>,<span class="number">18.0</span>,<span class="number">54.0</span>,<span class="number">81.0</span>,<span class="number">162.0</span>]        </span><br><span class="line"><span class="number">4</span>  |[<span class="number">10.0</span>,<span class="number">8.0</span>,<span class="number">6.0</span>]|[<span class="number">9.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>] |[<span class="number">360.0</span>,<span class="number">160.0</span>,<span class="number">200.0</span>,<span class="number">288.0</span>,<span class="number">128.0</span>,<span class="number">160.0</span>,<span class="number">216.0</span>,<span class="number">96.0</span>,<span class="number">120.0</span>]</span><br><span class="line"><span class="number">5</span>  |[<span class="number">9.0</span>,<span class="number">2.0</span>,<span class="number">7.0</span>] |[<span class="number">10.0</span>,<span class="number">7.0</span>,<span class="number">3.0</span>]|[<span class="number">450.0</span>,<span class="number">315.0</span>,<span class="number">135.0</span>,<span class="number">100.0</span>,<span class="number">70.0</span>,<span class="number">30.0</span>,<span class="number">350.0</span>,<span class="number">245.0</span>,<span class="number">105.0</span>] </span><br><span class="line"><span class="number">6</span>  |[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">4.0</span>] |[<span class="number">2.0</span>,<span class="number">8.0</span>,<span class="number">4.0</span>] |[<span class="number">12.0</span>,<span class="number">48.0</span>,<span class="number">24.0</span>,<span class="number">12.0</span>,<span class="number">48.0</span>,<span class="number">24.0</span>,<span class="number">48.0</span>,<span class="number">192.0</span>,<span class="number">96.0</span>]</span><br></pre></td></tr></table></figure><p>示例脚本(Java/Scala)请参照<a href="http://spark.apache.org/docs/2.3.2/ml-features.html#feature-transformers" target="_blank" rel="noopener">这里</a>。</p><h2 id="1-13-标准化-Normalizer"><a href="#1-13-标准化-Normalizer" class="headerlink" title="1.13 标准化(Normalizer)"></a>1.13 标准化(Normalizer)</h2><p>Normalizer是一个Transformer，它转换Vector行的数据集，将每个Vector规范化为具有单位范数。 它需要参数p，它指定用于归一化的p范数。（默认情况下p = 2）此标准化有助于标准化输入数据并改善学习算法的行为。</p><p><strong>举例</strong></p><p>以下示例演示如何以libsvm格式加载数据集，然后将每行标准化为具有单位$\ell^1$范数和单位$\ell^{\infty}$范数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 19:51</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : normalizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Normalizer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"NormalizerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataFrame = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.5</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">        (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">        (<span class="number">2</span>, Vectors.dense([<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">2.0</span>]),)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L1</span></span><br><span class="line">    normalizer = Normalizer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"normFeatures"</span>, p=<span class="number">1.0</span>)</span><br><span class="line">    l1NormData = normalizer.transform(dataFrame)</span><br><span class="line">    print(<span class="string">"Normalized using L^1 norm"</span>)</span><br><span class="line">    l1NormData.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L^&#123;\infty&#125;</span></span><br><span class="line">    lInfNormData = normalizer.transform(dataFrame, &#123;normalizer.p: float(<span class="string">"inf"</span>)&#125;)</span><br><span class="line">    print(<span class="string">"Normalized using L^inf norm"</span>)</span><br><span class="line">    lInfNormData.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Normalized using L^1 norm</span><br><span class="line">+---+--------------+------------------+</span><br><span class="line">| id|      features|      normFeatures|</span><br><span class="line">+---+--------------+------------------+</span><br><span class="line">|  0|[1.0,0.5,-1.0]|    [0.4,0.2,-0.4]|</span><br><span class="line">|  1| [2.0,1.0,1.0]|   [0.5,0.25,0.25]|</span><br><span class="line">|  2|[4.0,10.0,2.0]|[0.25,0.625,0.125]|</span><br><span class="line">+---+--------------+------------------+</span><br><span class="line"></span><br><span class="line">Normalized using L^inf norm</span><br><span class="line">+---+--------------+--------------+</span><br><span class="line">| id|      features|  normFeatures|</span><br><span class="line">+---+--------------+--------------+</span><br><span class="line">|  0|[1.0,0.5,-1.0]|[1.0,0.5,-1.0]|</span><br><span class="line">|  1| [2.0,1.0,1.0]| [1.0,0.5,0.5]|</span><br><span class="line">|  2|[4.0,10.0,2.0]| [0.4,1.0,0.2]|</span><br><span class="line">+---+--------------+--------------+</span><br></pre></td></tr></table></figure><h2 id="1-14-特征缩放-StandardScaler"><a href="#1-14-特征缩放-StandardScaler" class="headerlink" title="1.14 特征缩放(StandardScaler)"></a>1.14 特征缩放(StandardScaler)</h2><p>StandardScaler将每个特征标准化为具有单位标准差和/或零均值。 它需要参数：</p><ul><li>withStd：默认为True。 将数据缩放到单位标准偏差。</li><li>withMean：默认为False。 在缩放之前使用均值将数据居中。 它将构建密集输出，因此在应用稀疏输入时要小心。</li></ul><p>StandardScaler是一个Estimator，可以放在数据集上以生成StandardScalerModel; 这等于计算摘要统计。 然后，模型可以将数据集中的“矢量”列(特征)转换为具有单位标准差和/或零均值特征。</p><p>请注意，如果要素的标准差为零，则它将在该要素的Vector中返回默认的0.0值。</p><p><strong>举例</strong></p><p>以下示例演示如何以libsvm格式加载数据集，然后将每个要素标准化以具有单位标准偏差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 20:01</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : standard_scaler_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"StandardScalerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataFrame = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"../data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line">    <span class="comment"># scaler is a Estimator</span></span><br><span class="line">    scaler = StandardScaler(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"scaledFeatures"</span>, withStd=<span class="literal">True</span>, withMean=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    scalerModel = scaler.fit(dataFrame)  <span class="comment"># Transformer</span></span><br><span class="line"></span><br><span class="line">    scaledData = scalerModel.transform(dataFrame)</span><br><span class="line">    scaledData.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">|label|            features|      scaledFeatures|</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">|  0.0|(692,[127,128,129...|(692,[127,128,129...|</span><br><span class="line">|  1.0|(692,[158,159,160...|(692,[158,159,160...|</span><br><span class="line">|  1.0|(692,[124,125,126...|(692,[124,125,126...|</span><br><span class="line">|  1.0|(692,[152,153,154...|(692,[152,153,154...|</span><br><span class="line">|  1.0|(692,[151,152,153...|(692,[151,152,153...|</span><br><span class="line">|  0.0|(692,[129,130,131...|(692,[129,130,131...|</span><br><span class="line">|  1.0|(692,[158,159,160...|(692,[158,159,160...|</span><br><span class="line">|  1.0|(692,[99,100,101,...|(692,[99,100,101,...|</span><br><span class="line">|  0.0|(692,[154,155,156...|(692,[154,155,156...|</span><br><span class="line">|  0.0|(692,[127,128,129...|(692,[127,128,129...|</span><br><span class="line">|  1.0|(692,[154,155,156...|(692,[154,155,156...|</span><br><span class="line">|  0.0|(692,[153,154,155...|(692,[153,154,155...|</span><br><span class="line">|  0.0|(692,[151,152,153...|(692,[151,152,153...|</span><br><span class="line">|  1.0|(692,[129,130,131...|(692,[129,130,131...|</span><br><span class="line">|  0.0|(692,[154,155,156...|(692,[154,155,156...|</span><br><span class="line">|  1.0|(692,[150,151,152...|(692,[150,151,152...|</span><br><span class="line">|  0.0|(692,[124,125,126...|(692,[124,125,126...|</span><br><span class="line">|  0.0|(692,[152,153,154...|(692,[152,153,154...|</span><br><span class="line">|  1.0|(692,[97,98,99,12...|(692,[97,98,99,12...|</span><br><span class="line">|  1.0|(692,[124,125,126...|(692,[124,125,126...|</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><h2 id="1-15-MinMaxScaler"><a href="#1-15-MinMaxScaler" class="headerlink" title="1.15 MinMaxScaler"></a>1.15 MinMaxScaler</h2><p>MinMaxScaler将每个要素重新缩放到特定范围（通常为[0,1]）。 它需要参数：</p><ul><li>min：默认为0.0。 转换后的下限，由所有功能共享。</li><li>max：默认为1.0。 转换后的上限，由所有功能共享。</li></ul><p>MinMaxScaler计算数据集的摘要统计信息并生成MinMaxScalerModel。 然后，模型可以单独转换每个特征，使其处于给定范围内。</p><p>特征E的重新缩放值计算为，<br>$$<br>Rescaled(e_i) = \frac{e_i - E_{min}}{E_{max} - E_{min}} <em> (max-min) + min<br>$$<br>对于$E_{max} = E_{min}$的情况，$Rescaled(e_i) = 0.5 </em>(max+min)$的情况</p><p>请注意，由于零值可能会转换为非零值，因此即使对于稀疏输入，变压器的输出也将是DenseVector。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 20:08</span></span><br><span class="line"><span class="comment"># @Author   : 01373821 (mingchengyang@sf-express.com)</span></span><br><span class="line"><span class="comment"># @File     : min_max_scaler_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"MinMaxScalerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每一行是一个样本，每一列是一个特征</span></span><br><span class="line">    dataFrame = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.1</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">        (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.1</span>, <span class="number">1.0</span>]),),</span><br><span class="line">        (<span class="number">2</span>, Vectors.dense([<span class="number">3.0</span>, <span class="number">10.1</span>, <span class="number">3.0</span>]),)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    scaler = MinMaxScaler(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"scaledFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    scalerModel = scaler.fit(dataFrame)</span><br><span class="line"></span><br><span class="line">    scaledData = scalerModel.transform(dataFrame)</span><br><span class="line">    print(<span class="string">"Features scaled to range: [%f, %f]"</span> % (scaler.getMin(), scaler.getMax()))</span><br><span class="line">    scaledData.select(<span class="string">"features"</span>, <span class="string">"scaledFeatures"</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Features scaled to range: [0.000000, 1.000000]</span><br><span class="line">+--------------+--------------+</span><br><span class="line">|      features|scaledFeatures|</span><br><span class="line">+--------------+--------------+</span><br><span class="line">|[1.0,0.1,-1.0]| [0.0,0.0,0.0]|</span><br><span class="line">| [2.0,1.1,1.0]| [0.5,0.1,0.5]|</span><br><span class="line">|[3.0,10.1,3.0]| [1.0,1.0,1.0]|</span><br><span class="line">+--------------+--------------+</span><br></pre></td></tr></table></figure><h2 id="1-16-MaxAbsScaler"><a href="#1-16-MaxAbsScaler" class="headerlink" title="1.16 MaxAbsScaler"></a>1.16 MaxAbsScaler</h2><p>MaxAbsScaler通过除以每个特征中的最大绝对值，将每个要素重新缩放到范围[-1,1]。 它不会移动/居中数据，因此不会破坏任何稀疏性。</p><p>MaxAbsScaler计算数据集的摘要统计信息并生成MaxAbsScalerModel。 然后，模型可以将每个特征单独转换为范围[-1,1]。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 20:44</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : max_abs_scaler_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> MaxAbsScaler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"MaxAbsScalerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataFrame = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.1</span>, <span class="number">-8.0</span>]),),</span><br><span class="line">        (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">-4.0</span>]),),</span><br><span class="line">        (<span class="number">2</span>, Vectors.dense([<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>]),)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    scaler = MaxAbsScaler(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"scaledFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    scalerModel = scaler.fit(dataFrame)</span><br><span class="line"></span><br><span class="line">    scaledData = scalerModel.transform(dataFrame)</span><br><span class="line"></span><br><span class="line">    scaledData.select(<span class="string">"features"</span>, <span class="string">"scaledFeatures"</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+--------------+----------------+</span><br><span class="line">|      features|  scaledFeatures|</span><br><span class="line">+--------------+----------------+</span><br><span class="line">|[1.0,0.1,-8.0]|[0.25,0.01,-1.0]|</span><br><span class="line">|[2.0,1.0,-4.0]|  [0.5,0.1,-0.5]|</span><br><span class="line">|[4.0,10.0,8.0]|   [1.0,1.0,1.0]|</span><br><span class="line">+--------------+----------------+</span><br></pre></td></tr></table></figure><h2 id="1-17-Bucketizer"><a href="#1-17-Bucketizer" class="headerlink" title="1.17 Bucketizer"></a>1.17 Bucketizer</h2><p>Bucketizer将一列连续特征转换为一列特征桶，其中桶由用户指定。它需要一个参数：</p><ul><li>splits：用于将连续要素映射到存储桶的参数。对于n + 1个分裂，有n个桶。由分割[x，y)定义的桶保存除最后一个桶之外的[x，y]范围内的值，最后一个桶也包括y。拆分应该严格增加。必须明确提供-inf，inf处的值以涵盖所有Double值;否则，指定的拆分之外的值将被视为错误。分裂的两个例子是Array（Double.NegativeInfinity，0.0, 1.0，Double.PositiveInfinity）和Array（0.0, 1.0, 2.0）。</li></ul><p>请注意，如果您不知道目标列的上限和下限，则应添加Double.NegativeInfinity和Double.PositiveInfinity作为拆分的边界，以防止可能超出Bucketizer边界异常。</p><p>另请注意，您提供的分割必须严格按顺序递增，即s0 &lt;s1 &lt;s2 &lt;… &lt;sn。</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 20:49</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : bucketizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Bucketizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"BucketizerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    splits = [-float(<span class="string">"inf"</span>), <span class="number">-0.5</span>, <span class="number">0.0</span>, <span class="number">0.5</span>, float(<span class="string">"inf"</span>)]</span><br><span class="line"></span><br><span class="line">    data = [(<span class="number">-999.9</span>,), (<span class="number">-0.5</span>,), (<span class="number">-0.3</span>,), (<span class="number">0.0</span>,), (<span class="number">0.2</span>,), (<span class="number">999.9</span>,)]</span><br><span class="line">    dataFrame = spark.createDataFrame(data, [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    bucketizer = Bucketizer(splits=splits, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"bucketedFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    bucketedData = bucketizer.transform(dataFrame)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Bucketizer output with %d buckets"</span> % (len(bucketizer.getSplits())<span class="number">-1</span>))</span><br><span class="line">    bucketedData.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Bucketizer output with 4 buckets</span><br><span class="line">+--------+----------------+</span><br><span class="line">|features|bucketedFeatures|</span><br><span class="line">+--------+----------------+</span><br><span class="line">|  -999.9|             0.0|</span><br><span class="line">|    -0.5|             1.0|</span><br><span class="line">|    -0.3|             1.0|</span><br><span class="line">|     0.0|             2.0|</span><br><span class="line">|     0.2|             2.0|</span><br><span class="line">|   999.9|             3.0|</span><br><span class="line">+--------+----------------+</span><br></pre></td></tr></table></figure><h2 id="1-18-向量内积-ElementwiseProduct"><a href="#1-18-向量内积-ElementwiseProduct" class="headerlink" title="1.18 向量内积(ElementwiseProduct)"></a>1.18 向量内积(ElementwiseProduct)</h2><p>ElementwiseProduct使用基于元素的乘法将每个输入向量乘以提供的“权重”向量。 换句话说，它通过标量乘数来缩放数据集的每一列。 这表示输入矢量v和变换矢量w之间的Hadamard乘积，以产生结果矢量。<br>$$<br>\begin{pmatrix}<br>v_1 \\<br>\vdots \\<br>v_N<br>\end{pmatrix} \circ \begin{pmatrix}<br>                    w_1 \\<br>                    \vdots \\<br>                    w_N<br>                    \end{pmatrix}<br>= \begin{pmatrix}<br>  v_1 w_1 \\<br>  \vdots \\<br>  v_N w_N<br>  \end{pmatrix}<br>$$</p><p><strong>举例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/1 15:30</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : elementwise_product_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> ElementwiseProduct</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"ElementwiseProductExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = [(Vectors.dense([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]),), (Vectors.dense([<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]),)]</span><br><span class="line">    df = spark.createDataFrame(data, [<span class="string">"vector"</span>])</span><br><span class="line">    transformer = ElementwiseProduct(scalingVec=Vectors.dense([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>]),</span><br><span class="line">                                     inputCol=<span class="string">"vector"</span>, outputCol=<span class="string">"transformedVector"</span>)</span><br><span class="line">    transformer.transform(df).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+-------------+-----------------+</span><br><span class="line">|       vector|transformedVector|</span><br><span class="line">+-------------+-----------------+</span><br><span class="line">|[1.0,2.0,3.0]|    [0.0,2.0,6.0]|</span><br><span class="line">|[4.0,5.0,6.0]|   [0.0,5.0,12.0]|</span><br><span class="line">+-------------+-----------------+</span><br></pre></td></tr></table></figure><h2 id="1-19-SQLTransformer"><a href="#1-19-SQLTransformer" class="headerlink" title="1.19 SQLTransformer"></a>1.19 SQLTransformer</h2><p>SQLTransformer实现由SQL语句定义的转换。 目前我们只支持SQL语法，如“SELECT … FROM <strong>THIS</strong> …”，其中“<strong>THIS</strong>”表示输入数据集的基础表。 select子句指定要在输出中显示的字段，常量和表达式，并且可以是Spark SQL支持的任何select子句。 用户还可以使用Spark SQL内置函数和UDF对这些选定列进行操作。 例如，SQLTransformer支持如下语句：</p><ul><li>SELECT a，a + b AS a_b FROM <strong>THIS</strong></li><li>SELECT a，SQRT（b）AS b_sqrt FROM <strong>THIS</strong> WHERE a &gt; 5</li><li>SELECT a，b，SUM（c）AS c_sum FROM <strong>THIS</strong> GROUP BY a，b</li></ul><p><strong>举例</strong></p><p>假设我们有以下具有列id，v1和v2的DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> id |  v1 |  v2</span><br><span class="line">----|-----|-----</span><br><span class="line"> 0  | 1.0 | 3.0  </span><br><span class="line"> 2  | 2.0 | 5.0</span><br></pre></td></tr></table></figure><p>这是SQLTransformer的输出，其语句为“SELECT <em>，（v1 + v2）AS v3，（v1 </em> v2）AS v4 FROM <strong>THIS</strong>”：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+---+---+---+----+</span><br><span class="line">| id| v1| v2| v3|  v4|</span><br><span class="line">+---+---+---+---+----+</span><br><span class="line">|  0|1.0|3.0|4.0| 3.0|</span><br><span class="line">|  2|2.0|5.0|7.0|10.0|</span><br><span class="line">+---+---+---+---+----+</span><br></pre></td></tr></table></figure><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/1 15:35</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : sql_transformer.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> SQLTransformer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"SQLTransformerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="number">1.0</span>, <span class="number">3.0</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="number">2.0</span>, <span class="number">5.0</span>)</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"v1"</span>, <span class="string">"v2"</span>])</span><br><span class="line">    sqlTrans = SQLTransformer(</span><br><span class="line">        statement=<span class="string">"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__"</span>)</span><br><span class="line">    sqlTrans.transform(df).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><h2 id="1-20-矢量汇编-VectorAssembler"><a href="#1-20-矢量汇编-VectorAssembler" class="headerlink" title="1.20 矢量汇编(VectorAssembler)"></a>1.20 矢量汇编(VectorAssembler)</h2><p>VectorAssembler是一个Transformer，它将给定的字段列表组合到一个向量列中。 将原始特征和由不同特征变换器生成的特征组合成单个特征向量非常有用，以便训练ML模型，如逻辑回归和决策树。 VectorAssembler接受以下输入列类型：所有数字类型，布尔类型和矢量类型。 在每一行中，输入列的值将按指定的顺序连接到一个向量中。</p><p><strong>举例</strong></p><p>假设我们有一个带有id，hour，mobile，userFeatures和clicked列的DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> id | hour | mobile | userFeatures     | clicked</span><br><span class="line">----|------|--------|------------------|---------</span><br><span class="line"> 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0</span><br></pre></td></tr></table></figure><p>userFeatures是一个包含三个用户特征的矢量列。 我们希望将hour，mobile和userFeatures组合成一个单个的特征向量，并使用它来预测被点击与否。 如果我们将VectorAssembler的输入列设置为hour，mobile和userFeatures，并将输出列设置为features，转换后我们应该得到以下DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------+-------+</span><br><span class="line">|features               |clicked|</span><br><span class="line">+-----------------------+-------+</span><br><span class="line">|[18.0,1.0,0.0,10.0,0.5]|1.0    |</span><br><span class="line">+-----------------------+-------+</span><br></pre></td></tr></table></figure><p>示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/1 15:40</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : vector_assembler_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"VectorAssemblerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.createDataFrame(</span><br><span class="line">        [(<span class="number">0</span>, <span class="number">18</span>, <span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">10.0</span>, <span class="number">0.5</span>]), <span class="number">1.0</span>)],</span><br><span class="line">        [<span class="string">"id"</span>, <span class="string">"hour"</span>, <span class="string">"mobile"</span>, <span class="string">"userFeatures"</span>, <span class="string">"clicked"</span>])</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(</span><br><span class="line">        inputCols=[<span class="string">"hour"</span>, <span class="string">"mobile"</span>, <span class="string">"userFeatures"</span>],</span><br><span class="line">        outputCol=<span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">    output = assembler.transform(dataset)</span><br><span class="line">    print(<span class="string">"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'"</span>)</span><br><span class="line">    output.select(<span class="string">"features"</span>, <span class="string">"clicked"</span>).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><h2 id="1-21-矢量大小提示-VectorSizeHint"><a href="#1-21-矢量大小提示-VectorSizeHint" class="headerlink" title="1.21 矢量大小提示(VectorSizeHint)"></a>1.21 矢量大小提示(VectorSizeHint)</h2><p>有时可以明确指定VectorType列的向量大小。例如，VectorAssembler使用其输入列中的大小信息来为其输出列生成大小信息和元数据。虽然在某些情况下可以通过检查列的内容来获得此信息，但是在流数据中，在流启动之前内容不可用。 VectorSizeHint允许用户显式指定列的向量大小，以便VectorAssembler或可能需要知道向量大小的其他变换器可以将该列用作输入。</p><p>要使用VectorSizeHint，用户必须设置inputCol和size参数。将此转换器应用于dataframe会生成一个新的dataframe，其中包含inputCol的更新元数据，用于指定矢量大小。结果数据流的下游操作可以使用meatadata获得此大小。</p><p>VectorSizeHint还可以使用一个可选的handleInvalid参数，该参数在向量列包含空值或大小错误的向量时控制其行为。默认情况下，handleInvalid设置为“error”，表示应该抛出异常。此参数也可以设置为“skip”，表示应该从结果数据帧中过滤掉包含无效值的行，或“optimistic”，表示不应检查列是否存在无效值，并且应保留所有行。请注意，使用“optimistic”会导致生成的数据流处于不一致状态，应用VectorSizeHint列的元数据与该列的内容不匹配。用户应注意避免这种不一致的状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/1 15:47</span></span><br><span class="line"><span class="comment"># @Author   : 01373821 (mingchengyang@sf-express.com)</span></span><br><span class="line"><span class="comment"># @File     : vector_size_hint_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> (VectorSizeHint, VectorAssembler)</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"VectorSizeHintExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.createDataFrame(</span><br><span class="line">        [(<span class="number">0</span>, <span class="number">18</span>, <span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">10.0</span>, <span class="number">0.5</span>]), <span class="number">1.0</span>),</span><br><span class="line">         (<span class="number">0</span>, <span class="number">18</span>, <span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">10.0</span>]), <span class="number">0.0</span>)],</span><br><span class="line">        [<span class="string">"id"</span>, <span class="string">"hour"</span>, <span class="string">"mobile"</span>, <span class="string">"userFeatures"</span>, <span class="string">"clicked"</span>])</span><br><span class="line"></span><br><span class="line">    sizeHint = VectorSizeHint(</span><br><span class="line">        inputCol=<span class="string">"userFeatures"</span>,</span><br><span class="line">        handleInvalid=<span class="string">"skip"</span>,</span><br><span class="line">        size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    datasetWithSize = sizeHint.transform(dataset)</span><br><span class="line">    print(<span class="string">"Rows where 'userFeatures' is not the right size are filtered out"</span>)</span><br><span class="line">    datasetWithSize.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(</span><br><span class="line">        inputCols=[<span class="string">"hour"</span>, <span class="string">"mobile"</span>, <span class="string">"userFeatures"</span>],</span><br><span class="line">        outputCol=<span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 该数据流可以用于下游的Transformers</span></span><br><span class="line">    output = assembler.transform(datasetWithSize)</span><br><span class="line">    print(<span class="string">"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'"</span>)</span><br><span class="line">    output.select(<span class="string">"features"</span>, <span class="string">"clicked"</span>).show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Rows <span class="built_in">where</span> <span class="string">'userFeatures'</span> is not the right size are filtered out</span><br><span class="line">+---+----+------+--------------+-------+</span><br><span class="line">|id |hour|mobile|userFeatures  |clicked|</span><br><span class="line">+---+----+------+--------------+-------+</span><br><span class="line">|0  |18  |1.0   |[0.0,10.0,0.5]|1.0    |</span><br><span class="line">+---+----+------+--------------+-------+</span><br><span class="line"></span><br><span class="line">Assembled columns <span class="string">'hour'</span>, <span class="string">'mobile'</span>, <span class="string">'userFeatures'</span> to vector column <span class="string">'features'</span></span><br><span class="line">+-----------------------+-------+</span><br><span class="line">|features               |clicked|</span><br><span class="line">+-----------------------+-------+</span><br><span class="line">|[18.0,1.0,0.0,10.0,0.5]|1.0    |</span><br><span class="line">+-----------------------+-------+</span><br></pre></td></tr></table></figure><h2 id="1-22-分位数离散化器-QuantileDiscretizer"><a href="#1-22-分位数离散化器-QuantileDiscretizer" class="headerlink" title="1.22 分位数离散化器(QuantileDiscretizer)"></a>1.22 分位数离散化器(QuantileDiscretizer)</h2><p>QuantileDiscretizer采用具有连续特征的列，并输出具有分箱分类特征的列。 bin的数量由numBuckets参数设置。所使用的桶的数量可能小于该值，例如，如果输入的不同值太少而不能创建足够的不同分位数。</p><p>NaN值：在QuantileDiscretizer拟合期间，NaN值将从中移除。这将产生用于进行预测的Bucketizer模型。在转换过程中，Bucketizer会在数据集中找到NaN值时引发错误，但用户也可以选择通过设置handleInvalid来保留或删除数据集中的NaN值。如果用户选择保留NaN值，它们将被专门处理并放入自己的桶中，例如，如果使用4个桶，那么非NaN数据将被放入桶[0-3]，但是NaN将是算在一个特殊的桶[4]。</p><p>算法：使用近似算法选择bin范围（有关详细说明，请参阅<a href="http://spark.apache.org/docs/2.3.2/api/scala/index.html" target="_blank" rel="noopener">approxQuantile</a>的文档）。可以使用relativeError参数控制近似的精度。设置为零时，计算精确分位数（注意：计算精确分位数是一项昂贵的操作）。下边界和上边界将是-Infinity和+ Infinity，覆盖所有实际值。</p><p><strong>举例</strong></p><p>假设我们有一个包含列id，小时的DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> id | hour</span><br><span class="line">----|------</span><br><span class="line"> 0  | 18.0</span><br><span class="line">----|------</span><br><span class="line"> 1  | 19.0</span><br><span class="line">----|------</span><br><span class="line"> 2  | 8.0</span><br><span class="line">----|------</span><br><span class="line"> 3  | 5.0</span><br><span class="line">----|------</span><br><span class="line"> 4  | 2.2</span><br></pre></td></tr></table></figure><p>小时是Double类型的连续特征。 我们希望将连续特征变为分类特征。 给定numBuckets = 3，我们应该得到以下DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+---+----+------+</span><br><span class="line">| id|hour|result|</span><br><span class="line">+---+----+------+</span><br><span class="line">|  0|18.0|   2.0|</span><br><span class="line">|  1|19.0|   2.0|</span><br><span class="line">|  2| 8.0|   1.0|</span><br><span class="line">|  3| 5.0|   1.0|</span><br><span class="line">|  4| 2.2|   0.0|</span><br><span class="line">+---+----+------+</span><br></pre></td></tr></table></figure><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/1 15:53</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : quantile_discretizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> QuantileDiscretizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"QuantileDiscretizerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    data = [(<span class="number">0</span>, <span class="number">18.0</span>), (<span class="number">1</span>, <span class="number">19.0</span>), (<span class="number">2</span>, <span class="number">8.0</span>), (<span class="number">3</span>, <span class="number">5.0</span>), (<span class="number">4</span>, <span class="number">2.2</span>)]</span><br><span class="line">    df = spark.createDataFrame(data, [<span class="string">"id"</span>, <span class="string">"hour"</span>])</span><br><span class="line">    df = df.repartition(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    discretizer = QuantileDiscretizer(numBuckets=<span class="number">3</span>, inputCol=<span class="string">"hour"</span>, outputCol=<span class="string">"result"</span>)</span><br><span class="line"></span><br><span class="line">    result = discretizer.fit(df).transform(df)</span><br><span class="line">    result.show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><h2 id="1-23-Imputer"><a href="#1-23-Imputer" class="headerlink" title="1.23 Imputer"></a>1.23 Imputer</h2><p>Imputer转换器使用缺失值所在的列的平均值或中值来完成数据集中的缺失值。 输入列应为DoubleType或FloatType。 目前，Imputer不支持分类功能，并且可能为包含分类功能的列创建不正确的值。 Imputer可以通过.setMissingValue（custom_value）将“NaN”以外的自定义值包括在内。 例如，.setMissingValue（0）将计算所有出现的（0）。</p><p><strong>注意</strong>，输入列中的所有空值都被视为缺失，因此也会被估算。</p><p><strong>举例</strong></p><p>假设我们有一个包含a和b列的DataFrame：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">      a     |      b      </span><br><span class="line">------------|-----------</span><br><span class="line">     1.0    | Double.NaN</span><br><span class="line">     2.0    | Double.NaN</span><br><span class="line"> Double.NaN |     3.0   </span><br><span class="line">     4.0    |     4.0   </span><br><span class="line">     5.0    |     5.0</span><br></pre></td></tr></table></figure><p>在此示例中，Imputer将使用从相应列中的其他值计算的均值（默认插补策略）替换所有出现的Double.NaN（缺失值的缺省值）。 在此示例中，列a和b的替代值分别为3.0和4.0。 转换后，输出列中的缺失值将替换为相关列的替代值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+---+---+-----+-----+</span><br><span class="line">|  a|  b|out_a|out_b|</span><br><span class="line">+---+---+-----+-----+</span><br><span class="line">|1.0|NaN|  1.0|  4.0|</span><br><span class="line">|2.0|NaN|  2.0|  4.0|</span><br><span class="line">|NaN|3.0|  3.0|  3.0|</span><br><span class="line">|4.0|4.0|  4.0|  4.0|</span><br><span class="line">|5.0|5.0|  5.0|  5.0|</span><br><span class="line">+---+---+-----+-----+</span><br></pre></td></tr></table></figure><p>示例代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/8/1 15:59</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : imputer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"ImputerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (<span class="number">1.0</span>, float(<span class="string">"nan"</span>)),</span><br><span class="line">        (<span class="number">2.0</span>, float(<span class="string">"nan"</span>)),</span><br><span class="line">        (float(<span class="string">"nan"</span>), <span class="number">3.0</span>),</span><br><span class="line">        (<span class="number">4.0</span>, <span class="number">4.0</span>),</span><br><span class="line">        (<span class="number">5.0</span>, <span class="number">5.0</span>)</span><br><span class="line">    ], [<span class="string">"a"</span>, <span class="string">"b"</span>])</span><br><span class="line"></span><br><span class="line">    imputer = Imputer(inputCols=[<span class="string">"a"</span>, <span class="string">"b"</span>], outputCols=[<span class="string">"out_a"</span>, <span class="string">"out_b"</span>])</span><br><span class="line">    model = imputer.fit(df)</span><br><span class="line">    model.transform(df).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spark MLlib中关于特征处理的相关算法，大致分为以下几组：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提取(Extraction)：从“原始”数据中提取特征&lt;/li&gt;
&lt;li&gt;转换(Transformation)：缩放，转换或修改特征&lt;/li&gt;
&lt;li&gt;选择(Selection)：从较大的一组特征中选择一个子集&lt;/li&gt;
&lt;li&gt;局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文介绍第二组： 特征转换器(Transformers)&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】特征工程1-Extractors</title>
    <link href="https://buracagyang.github.io/2019/07/30/spark-features-project-1/"/>
    <id>https://buracagyang.github.io/2019/07/30/spark-features-project-1/</id>
    <published>2019-07-30T10:07:31.000Z</published>
    <updated>2019-08-08T07:37:58.192Z</updated>
    
    <content type="html"><![CDATA[<p>Spark MLlib中关于特征处理的相关算法，大致分为以下几组：</p><ul><li>提取(Extraction)：从“原始”数据中提取特征</li><li>转换(Transformation)：缩放，转换或修改特征</li><li>选择(Selection)：从较大的一组特征中选择一个子集</li><li>局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。</li></ul><p>本文介绍第一组： 特征提取器(Extractors)</p><a id="more"></a><h1 id="1-特诊提取器"><a href="#1-特诊提取器" class="headerlink" title="1. 特诊提取器"></a>1. 特诊提取器</h1><h2 id="1-1-TF-IDF"><a href="#1-1-TF-IDF" class="headerlink" title="1.1 TF-IDF"></a>1.1 TF-IDF</h2><p>词频-逆文本频率<a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="noopener">(Term frequency-inverse document frequency, (TF-IDF)</a>是在文本挖掘中广泛使用的特征向量化方法，以反映术语对语料库中的文档的重要性。 用t表示一个术语，用d表示一个文件，用D表示语料库。词频TF(t，d)是术语t出现在文件d中的次数，而文档频率DF(t，D)是包含术语t的文件数量。 如果我们仅使用词频来衡量重要性，那么过分强调经常出现但很少提供有关文档的信息的术语非常容易，例如： “a”，“the”和“of”。 如果词语在语料库中经常出现，则表示它不包含有关特定文档的特殊信息。 逆向文档频率是词语提供的信息量的数字度量：<br>$$<br>IDF(t,D) = log\frac{|D| + 1}{DF(t,D) + 1}<br>$$<br>其中|D|是语料库中的文档总数。 由于使用了对数log，如果一个术语出现在所有文档中，其IDF值将变为0。请注意，应用平滑词语以避免语料库外的术语除以零。 TF-IDF指标只是TF和IDF的产物：<br>$$<br>TF-IDF = TF(t,d) \times IDF(t,D)<br>$$<br>词频和文档频率的定义有几种变体。 在MLlib中，我们将TF和IDF分开以使其灵活。</p><p><strong>TF</strong>：HashingTF和CountVectorizer都可用于生成术语频率向量。</p><ol><li>HashingTF是一个Transformer，它接受一组词语并将这些集合转换为固定长度的特征向量。在文本处理中，“一组词语”可能是一个单词集合。 HashingTF利用散列技巧。通过应用散列函数将原始特征映射到索引。这里使用的哈希函数是<a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">MurmurHash 3</a>.然后，基于映射的索引计算术语频率。这种方法避免了计算全局词语到索引映射的需要，这对于大型语料库来说可能是昂贵的，但它遭受潜在的哈希冲突，其中不同的原始特征可能在散列之后变成相同的词语。为了减少冲突的可能性，我们可以增加目标特征维度，即哈希表的桶的数量。由于散列值的简单模数用于确定向量索引，因此建议使用2的幂作为要素维度，否则要素将不会均匀映射到向量索引。默认要素尺寸为$2^{18} = 262,144$。可选的二进制切换参数控制术语频率计数。设置为true时，所有非零频率计数都设置为1.这对于模拟二进制而非整数计数的离散概率模型特别有用。</li><li>CountVectorizer将文本文档转换为词语计数向量。</li></ol><p><strong>IDF</strong>：IDF是一个Estimator，它训练数据集并生成IDFModel。 IDFModel采用特征向量（通常从HashingTF或CountVectorizer创建）并缩放每个特征。 直观地，它降低了在语料库中频繁出现的特征。</p><p><strong>举例</strong></p><p>在下面的代码中(基于Python)，Scala和Java的示例还请参照<a href="http://spark.apache.org/docs/2.3.2/ml-features.html#bucketizer" target="_blank" rel="noopener">这里</a>；我们从一组句子开始。 我们使用Tokenizer将每个句子分成单词。 对于每个句子，我们使用HashingTF将句子散列为特征向量。 我们使用IDF重新缩放特征向量; 这通常会在使用文本作为功能时提高性能。 然后我们的特征向量可以传递给学习算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:03</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : tf_idf_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, IDF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"TfIdfExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    sentenceData = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0.0</span>, <span class="string">"Hi I heard about Spark"</span>),</span><br><span class="line">        (<span class="number">0.0</span>, <span class="string">"I wish Java could use case classes"</span>),</span><br><span class="line">        (<span class="number">1.0</span>, <span class="string">"Logistic regression models are neat"</span>)</span><br><span class="line">    ], [<span class="string">"label"</span>, <span class="string">"sentence"</span>])</span><br><span class="line"></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">    wordsData = tokenizer.transform(sentenceData)</span><br><span class="line"></span><br><span class="line">    hashingTF = HashingTF(inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"rawFeatures"</span>, numFeatures=<span class="number">20</span>)</span><br><span class="line">    featurizedData = hashingTF.transform(wordsData)</span><br><span class="line">    <span class="comment"># 也可以选择CountVectorizer得到一个词频向量</span></span><br><span class="line"></span><br><span class="line">    idf = IDF(inputCol=<span class="string">"rawFeatures"</span>, outputCol=<span class="string">"features"</span>)</span><br><span class="line">    idfModel = idf.fit(featurizedData)</span><br><span class="line">    rescaledData = idfModel.transform(featurizedData)</span><br><span class="line"></span><br><span class="line">    rescaledData.select(<span class="string">"label"</span>, <span class="string">"features"</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------------------+</span><br><span class="line">|label|            features|</span><br><span class="line">+-----+--------------------+</span><br><span class="line">|  0.0|(20,[0,5,9,17],[0...|</span><br><span class="line">|  0.0|(20,[2,7,9,13,15]...|</span><br><span class="line">|  1.0|(20,[4,6,13,15,18...|</span><br><span class="line">+-----+--------------------+</span><br></pre></td></tr></table></figure><h2 id="1-2-Word2Vec"><a href="#1-2-Word2Vec" class="headerlink" title="1.2 Word2Vec"></a>1.2 Word2Vec</h2><p>Word2Vec是一个Estimator，它采用代表文档的单词序列并训练Word2VecModel。 该模型将每个单词映射到一个<strong>唯一的固定大小的向量</strong>。 Word2VecModel使用文档中所有单词的平均值将每个文档转换为向量; 然后，此向量可用作预测，文档相似度计算等功能。</p><p><strong>举例</strong></p><p>我们从一组文档开始，每个文档都表示为一系列单词。 对于每个文档，我们将其转换为特征向量。 然后可以将该特征向量传递给学习算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:09</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : word2vec_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"Word2VecExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输入数据: 每行是一个句子或文档中的单词集合。</span></span><br><span class="line">    documentDF = spark.createDataFrame([</span><br><span class="line">        (<span class="string">"Hi I heard about Spark"</span>.split(<span class="string">" "</span>), ),</span><br><span class="line">        (<span class="string">"I wish Java could use case classes"</span>.split(<span class="string">" "</span>), ),</span><br><span class="line">        (<span class="string">"Logistic regression models are neat"</span>.split(<span class="string">" "</span>), )</span><br><span class="line">    ], [<span class="string">"text"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从单词到向量的映射。</span></span><br><span class="line">    word2Vec = Word2Vec(vectorSize=<span class="number">3</span>, minCount=<span class="number">0</span>, inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"result"</span>)</span><br><span class="line">    model = word2Vec.fit(documentDF)</span><br><span class="line"></span><br><span class="line">    result = model.transform(documentDF)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> result.collect():</span><br><span class="line">        text, vector = row</span><br><span class="line">        print(<span class="string">"Text: [%s] =&gt; \nVector: %s\n"</span> % (<span class="string">", "</span>.join(text), str(vector)))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Text: [Hi, I, heard, about, Spark] =&gt; </span><br><span class="line">Vector: [0.010823638737201692,-0.005407899245619774,-0.02091031074523926]</span><br><span class="line"></span><br><span class="line">Text: [I, wish, Java, could, use, <span class="keyword">case</span>, classes] =&gt; </span><br><span class="line">Vector: [0.04387364802615983,0.028466253940548213,-0.02133789997813957]</span><br><span class="line"></span><br><span class="line">Text: [Logistic, regression, models, are, neat] =&gt; </span><br><span class="line">Vector: [0.054717136174440385,0.009467959217727185,0.034012694098055365]</span><br></pre></td></tr></table></figure><h2 id="1-3-CountVectorizer"><a href="#1-3-CountVectorizer" class="headerlink" title="1.3 CountVectorizer"></a>1.3 CountVectorizer</h2><p>CountVectorizer和CountVectorizerModel旨在帮助将文本文档集合转换为计数向量(vectors of token counts)。当a-priori字典不可用时，CountVectorizer可用作Estimator来提取词汇表，并生成CountVectorizerModel。该模型为词汇表上的文档生成稀疏表示，然后可以将其传递给其他算法，如LDA。</p><p>在拟合过程中，CountVectorizer将选择按语料库中的术语频率排序的顶级词汇量词。可选参数minDF还通过指定词语必须出现在文档中的最小数量（或&lt;1.0）来影响拟合过程。另一个可选的二进制切换参数控制输出向量。如果设置为true，则所有非零计数都设置为1.这对于模拟二进制而非整数计数的离散概率模型尤其有用。</p><p><strong>举例</strong></p><p>假设我们有以下DataFrame，其中包含列id和文本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> id | texts</span><br><span class="line">----|----------</span><br><span class="line"> 0  | Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>)</span><br><span class="line"> 1  | Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"a"</span>)</span><br></pre></td></tr></table></figure><p>文本中的每一行都是Array [String]类型的文档。 调用CountVectorizer的拟合会生成带有词汇表（a，b，c）的CountVectorizerModel。 然后转换后的输出列“vector”包含：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> id | texts                           | vector</span><br><span class="line">----|---------------------------------|---------------</span><br><span class="line"> 0  | Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>)            | (3,[0,1,2],[1.0,1.0,1.0])</span><br><span class="line"> 1  | Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"a"</span>)  | (3,[0,1,2],[2.0,2.0,1.0])</span><br></pre></td></tr></table></figure><p>每个向量表示文档在词汇表中的词语计数(id 0: ‘a’, ‘b’, ‘c’各出现一次；id1: ‘a’, ‘b’, ‘c’各出现2， 2， 1次)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:24</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : count_vectorizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"CountVectorizerExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="string">"a b c"</span>.split(<span class="string">" "</span>)),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">"a b b c a"</span>.split(<span class="string">" "</span>))</span><br><span class="line">    ], [<span class="string">"id"</span>, <span class="string">"words"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用语料库拟合一个CountVectorizerModel</span></span><br><span class="line">    cv = CountVectorizer(inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"features"</span>, vocabSize=<span class="number">3</span>, minDF=<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">    model = cv.fit(df)</span><br><span class="line">    result = model.transform(df)</span><br><span class="line">    result.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+---------------+-------------------------+</span><br><span class="line">|id |words          |features                 |</span><br><span class="line">+---+---------------+-------------------------+</span><br><span class="line">|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|</span><br><span class="line">|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|</span><br><span class="line">+---+---------------+-------------------------+</span><br></pre></td></tr></table></figure><h2 id="1-4-FeatureHasher"><a href="#1-4-FeatureHasher" class="headerlink" title="1.4 FeatureHasher"></a>1.4 FeatureHasher</h2><p>特征散列(Feature Hashing)将一组分类或数字特征映射到指定尺寸的特征向量中（通常远小于原始特征空间的特征向量）。这是使用散列技巧将要素映射到特征向量中的索引来完成的。</p><p>FeatureHasher转换器在多个特征上运行。每个特征可能是数值特征或分类特征。不同数据类型的处理方法如下：</p><ul><li>数值特征：对于数值特征，特征名称的哈希值用于将值映射到向量中的索引。默认情况下，数值元素不被视为分类属性（即使它们是整数）。要将它们视为分类属性，请使用categoricalCols参数指定相关列。</li><li>字符串(属性)特征：对于属性特征，字符串“column_name = value”的哈希值用于映射到矢量索引，指示符值为1.0。因此，属性特征是“one-hot”编码的（类似于使用具有dropLast = false的OneHotEncoder）。</li><li>布尔特征：布尔值的处理方式与字符串特征相同。也就是说，布尔特征表示为“column_name = true”或“column_name = false”，指标值为1.0。</li></ul><p>忽略空（缺失）值（在结果特征向量中隐式为零）。</p><p>这里使用的哈希函数也是HashingTF中使用的MurmurHash 3。由于散列值的简单模数用于确定向量索引，因此建议使用2的幂作为numFeatures参数;否则，特征将不会均匀地映射到矢量索引。</p><p><strong>举例</strong></p><p>假设我们有一个DataFrame，其中包含4个输入列real，bool，stringNum和string。这些不同的数据类型作为输入将说明变换的行为以产生一列特征向量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">real| bool|stringNum|string</span><br><span class="line">----|-----|---------|------</span><br><span class="line"> 2.2| <span class="literal">true</span>|        1|   foo</span><br><span class="line"> 3.3|<span class="literal">false</span>|        2|   bar</span><br><span class="line"> 4.4|<span class="literal">false</span>|        3|   baz</span><br><span class="line"> 5.5|<span class="literal">false</span>|        4|   foo</span><br></pre></td></tr></table></figure><p>训练过程示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:34</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : feature_hasher_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> FeatureHasher</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"FeatureHasherExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.createDataFrame([</span><br><span class="line">        (<span class="number">2.2</span>, <span class="literal">True</span>, <span class="string">"1"</span>, <span class="string">"foo"</span>),</span><br><span class="line">        (<span class="number">3.3</span>, <span class="literal">False</span>, <span class="string">"2"</span>, <span class="string">"bar"</span>),</span><br><span class="line">        (<span class="number">4.4</span>, <span class="literal">False</span>, <span class="string">"3"</span>, <span class="string">"baz"</span>),</span><br><span class="line">        (<span class="number">5.5</span>, <span class="literal">False</span>, <span class="string">"4"</span>, <span class="string">"foo"</span>)</span><br><span class="line">    ], [<span class="string">"real"</span>, <span class="string">"bool"</span>, <span class="string">"stringNum"</span>, <span class="string">"string"</span>])</span><br><span class="line"></span><br><span class="line">    hasher = FeatureHasher(inputCols=[<span class="string">"real"</span>, <span class="string">"bool"</span>, <span class="string">"stringNum"</span>, <span class="string">"string"</span>],</span><br><span class="line">                           outputCol=<span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">    featurized = hasher.transform(dataset)</span><br><span class="line">    featurized.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+----+-----+---------+------+--------------------------------------------------------+</span><br><span class="line">|real|bool |stringNum|string|features                                                |</span><br><span class="line">+----+-----+---------+------+--------------------------------------------------------+</span><br><span class="line">|2.2 |<span class="literal">true</span> |1        |foo   |(262144,[174475,247670,257907,262126],[2.2,1.0,1.0,1.0])|</span><br><span class="line">|3.3 |<span class="literal">false</span>|2        |bar   |(262144,[70644,89673,173866,174475],[1.0,1.0,1.0,3.3])  |</span><br><span class="line">|4.4 |<span class="literal">false</span>|3        |baz   |(262144,[22406,70644,174475,187923],[1.0,1.0,4.4,1.0])  |</span><br><span class="line">|5.5 |<span class="literal">false</span>|4        |foo   |(262144,[70644,101499,174475,257907],[1.0,1.0,5.5,1.0]) |</span><br><span class="line">+----+-----+---------+------+--------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>然后可以将得到的特征向量传递给学习算法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spark MLlib中关于特征处理的相关算法，大致分为以下几组：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提取(Extraction)：从“原始”数据中提取特征&lt;/li&gt;
&lt;li&gt;转换(Transformation)：缩放，转换或修改特征&lt;/li&gt;
&lt;li&gt;选择(Selection)：从较大的一组特征中选择一个子集&lt;/li&gt;
&lt;li&gt;局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文介绍第一组： 特征提取器(Extractors)&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>【Spark】Pipelines</title>
    <link href="https://buracagyang.github.io/2019/07/30/spark-ml-pipelines/"/>
    <id>https://buracagyang.github.io/2019/07/30/spark-ml-pipelines/</id>
    <published>2019-07-30T08:48:06.000Z</published>
    <updated>2019-08-26T03:50:46.760Z</updated>
    
    <content type="html"><![CDATA[<p>在本节中，我们将介绍<strong>ML Pipelines</strong>的概念。 ML Pipelines提供了一组基于DataFrame构建的统一的高级API，可帮助用户创建和调整实用的机器学习流程。</p><a id="more"></a><h1 id="1-管道中的主要概念"><a href="#1-管道中的主要概念" class="headerlink" title="1. 管道中的主要概念"></a>1. 管道中的主要概念</h1><p>MLlib标准化用于机器学习算法的API，以便更轻松地将多个算法组合到单个管道或工作流程中。本节介绍Pipelines API引入的关键概念，其中管道概念主要受到<a href="http://scikit-learn.org/" target="_blank" rel="noopener">scikit-learn</a>项目的启发。</p><ul><li><p><strong>DataFrame</strong>：此ML API使用Spark SQL中的DataFrame作为ML数据集，它可以包含各种数据类型。例如，DataFrame可以具有存储文本，特征向量，标签(true labels)和预测的不同列。</p></li><li><p><strong>Transformer</strong>：Transformer是一种可以将一个DataFrame转换为另一个DataFrame的算法。例如，ML模型是变换器，其将具有特征的DataFrame转换为具有预测的DataFrame。</p></li><li><p><strong>Estimator</strong>：Estimator是一种算法，可以适应DataFrame以生成Transformer。例如，学习算法是Estimator，其在DataFrame上训练并产生模型。</p></li><li><p><strong>Pipeline</strong>：管道将多个Transformers和Estimators链接在一起以指定ML工作流程。</p></li><li><p><strong>参数</strong>：所有Transformers和Estimators现在共享一个用于指定参数的通用API。</p></li></ul><h2 id="1-1-DataFrame"><a href="#1-1-DataFrame" class="headerlink" title="1.1 DataFrame"></a>1.1 DataFrame</h2><p>机器学习可以应用于各种数据类型，例如矢量，文本，图像和结构化数据。 此API采用Spark SQL的DataFrame以支持各种数据类型。</p><p>DataFrame支持许多基本和结构化类型; 有关支持的类型列表，请参阅Spark SQL数据类型参考。 除了Spark SQL指南中列出的类型之外，DataFrame还可以使用ML Vector类型。</p><p>可以从常规RDD隐式或显式创建DataFrame。 有关示例，请参阅下面的代码示例和Spark SQL编程指南。</p><p>DataFrame中的列已命名。 下面的代码示例使用诸如“text”，“features”和“label”之类的名称。</p><h2 id="1-2-Pipeline-组件"><a href="#1-2-Pipeline-组件" class="headerlink" title="1.2 Pipeline 组件"></a>1.2 Pipeline 组件</h2><h3 id="1-2-1-Transformers"><a href="#1-2-1-Transformers" class="headerlink" title="1.2.1 Transformers"></a>1.2.1 Transformers</h3><p>Transformer是一种抽象，包括特征变换器和学习模型。 从技术上讲，Transformer实现了一个方法transform（），它通常通过附加一个或多个列将一个DataFrame转换为另一个DataFrame。 例如：</p><ul><li>特征变换器可以采用DataFrame，读取列（例如，文本），将其映射到新列（例如，特征向量），并输出附加了映射列的新DataFrame。</li><li>学习模型可以采用DataFrame，读取包含特征向量的列，预测每个要素向量的标签，并输出新的DataFrame，其中预测标签作为列附加。</li></ul><h3 id="1-2-2-Estimators"><a href="#1-2-2-Estimators" class="headerlink" title="1.2.2 Estimators"></a>1.2.2 Estimators</h3><p>估计器抽象学习算法或适合或训练数据的任何算法的概念。 从技术上讲，Estimator实现了一个方法fit()，它接受一个DataFrame并生成一个Model，它是一个Transformer。 例如，诸如LogisticRegression之类的学习算法是Estimator，并且调用fit()训练LogisticRegressionModel，LogisticRegressionModel是Model并因此是Transformer。</p><h3 id="1-2-3-Pipeline组件的属性"><a href="#1-2-3-Pipeline组件的属性" class="headerlink" title="1.2.3 Pipeline组件的属性"></a>1.2.3 Pipeline组件的属性</h3><p>Transformer.transform（）和Estimator.fit（）都是无状态的。 将来，可以通过替代概念支持有状态算法。</p><p>Transformer或Estimator的每个实例都有一个唯一的ID，可用于指定参数（如下所述）。</p><h2 id="1-3-Pipeline"><a href="#1-3-Pipeline" class="headerlink" title="1.3 Pipeline"></a>1.3 Pipeline</h2><p>在机器学习中，通常运行一系列算法来处理和学习数据。 例如，简单的文本文档处理工作流程可能包括几个阶段：</p><ul><li>将每个文档的文本拆分为单词。</li><li>将每个文档的单词转换为数字特征向量。</li><li>使用特征向量和标签学习预测模型。</li></ul><p>MLlib将此类工作流表示为管道，其由一系列以特定顺序运行的PipelineStages（变换器和估算器）组成。我们将在本节中将此简单工作流用作运行示例。</p><h3 id="1-3-1-运行原理"><a href="#1-3-1-运行原理" class="headerlink" title="1.3.1 运行原理"></a>1.3.1 运行原理</h3><p>管道被指定为不同阶段的序列，并且每个阶段是变换器或估计器。 这些阶段按顺序运行，输入DataFrame在通过每个阶段时进行转换。 对于Transformer阶段，在DataFrame上调用transform()方法。 对于Estimator阶段，调用fit()方法以生成Transformer（它成为PipelineModel或拟合管道的一部分），并在DataFrame上调用Transformer的transform()方法。</p><p>我们为简单的文本文档工作流说明了这一点。 下图是管道的训练时间使用情况。</p><p><img src="/2019/07/30/spark-ml-pipelines/ml-Pipeline.png" alt="ml-Pipeline"></p><p>上图中，顶行表示具有三个阶段的管道。前两个（Tokenizer和HashingTF）是TransformerS（蓝色），第三个（LogisticRegression）是Estimator（红色）。底行表示流经管道的数据，其中柱面表示DataFrame。在原始DataFrame上调用Pipeline.fit()方法，该原始DataFrame具有原始文本文档和标签。 Tokenizer.transform()方法将原始文本文档拆分为单词，向DataFrame添加一个带有单词的新列。 HashingTF.transform()方法将单词列转换为要素向量，将包含这些向量的新列添加到DataFrame。现在，由于LogisticRegression是一个Estimator，因此Pipeline首先调用LogisticRegression.fit()来生成LogisticRegressionModel。如果Pipeline有更多的Estimators，它会在将DataFrame传递给下一个阶段之前在DataFrame上调用LogisticRegressionModel的transform()方法。</p><p>一个Pipeline是Estimator。因此，在Pipeline的fit()方法运行之后，它会生成一个<strong>PipelineModel</strong>，<strong>它是一个Transformer</strong>。这个PipelineModel在测试时使用;下图说明了这种用法。</p><p><img src="/2019/07/30/spark-ml-pipelines/ml-PipelineModel.png" alt="ml-PipelineModel"></p><p>在上图中，PipelineModel具有与原始Pipeline相同的阶段数，但原始Pipeline中的所有Estimators都变为Transformers。 当在测试数据集上调用PipelineModel的transform()方法时，数据将按顺序通过拟合的管道传递。 每个阶段的transform()方法都会更新数据集并将其传递给下一个阶段。</p><p>Pipelines和PipelineModel有助于确保训练和测试数据经过相同的功能处理步骤。</p><h3 id="1-3-2-详细过程"><a href="#1-3-2-详细过程" class="headerlink" title="1.3.2 详细过程"></a>1.3.2 详细过程</h3><p>DAG PipelineS：管道的阶段被指定为有序数组。这里给出的例子都是线性管道(linear PipelineS)，即其中每个阶段的管道使用前一阶段产生的数据。只要数据流图形成有向无环图（DAG），就可以创建非线性管道。目前，此图基于每个阶段的输入和输出列名称（通常指定为参数）隐式指定。如果管道形成DAG，则必须按拓扑顺序指定阶段。</p><p>运行时检查：由于Pipelines可以在具有不同类型的DataFrame上运行，因此它们不能使用编译时类型检查。 Pipelines和PipelineModels代替在实际运行Pipeline之前进行运行时检查。此类型检查是使用DataFrame模式完成的，DataFrame模式是DataFrame中列的数据类型的描述。</p><p>独特的管道阶段：管道的阶段应该是唯一的实例。例如，由于Pipeline阶段必须具有唯一ID，因此不应将相同的实例myHashingTF插入到Pipeline中两次。但是，不同的实例myHashingTF1和myHashingTF2（都是HashingTF类型）可以放在同一个管道中，因为将使用不同的ID创建不同的实例。</p><h2 id="1-4-参数"><a href="#1-4-参数" class="headerlink" title="1.4 参数"></a>1.4 参数</h2><p>MLlib Estimators和Transformers使用统一的API来指定参数。</p><p>Param是一个带有自包含文档的命名参数。 ParamMap是一组（参数，值）对。</p><p>将参数传递给算法有两种主要方法：</p><ol><li>设置实例的参数。 例如，如果lr是LogisticRegression的实例，则可以调用lr.setMaxIter(10)以使lr.fit()最多使用10次迭代。 此API类似于spark.mllib包中使用的API。</li><li>将ParamMap传递给fit()或transform()。 ParamMap中的任何参数都将覆盖先前通过setter方法指定的参数。</li></ol><p>参数属于Estimators和Transformers的特定实例。 例如，如果我们有两个LogisticRegression实例lr1和lr2，那么我们可以构建一个指定了两个maxIter参数的ParamMap：ParamMap（lr1.maxIter  - &gt; 10，lr2.maxIter  - &gt; 20）。 如果管道中有两个带有maxIter参数的算法，这将非常有用。</p><h2 id="1-5-ML持久性-保存和加载管道"><a href="#1-5-ML持久性-保存和加载管道" class="headerlink" title="1.5 ML持久性:保存和加载管道"></a>1.5 ML持久性:保存和加载管道</h2><p>通常，将模型或管道保存到磁盘以供以后使用是值得的。 在Spark 1.6中，模型导入/导出功能已添加到Pipeline API中。 从Spark 2.3开始，spark.ml和pyspark.ml中基于DataFrame的API具有完整的覆盖范围。</p><p>ML持久性适用于Scala，Java和Python。 但是，R当前使用的是修改后的格式，因此保存在R中的模型只能加载回R; 这应该在将来修复，并在<a href="https://issues.apache.org/jira/browse/SPARK-15572" target="_blank" rel="noopener">SPARK-15572</a>中进行跟踪。</p><h3 id="1-5-1-ML持久性的向后兼容性"><a href="#1-5-1-ML持久性的向后兼容性" class="headerlink" title="1.5.1 ML持久性的向后兼容性"></a>1.5.1 ML持久性的向后兼容性</h3><p>通常，MLlib保持ML持久性的向后兼容性。即，如果您在一个版本的Spark中保存ML模型或Pipeline，那么您应该能够将其加载回来并在将来的Spark版本中使用它。但是，极少数例外情况如下所述。</p><p>模型持久性：Spark版本Y可以加载Spark版本X中使用Apache Spark ML持久性保存模型或管道吗？</p><ul><li>主要版本：没有保证，但是尽力而为。</li><li>次要和补丁版本：是的;这些是向后兼容的。</li><li>关于格式的注意事项：不保证稳定的持久性格式，但模型加载本身设计为向后兼容。</li></ul><p>模型行为：Spark版本X中的模型或管道在Spark版本Y中的行为是否相同？</p><ul><li>主要版本：没有保证，但是尽力而为。</li><li>次要和补丁版本：相同的行为，除了错误修复。</li></ul><p>对于模型持久性和模型行为，在Spark版本发行说明中报告了次要版本或修补程序版本的任何重大更改。如果发行说明中未报告破损，则应将其视为要修复的错误。</p><h1 id="2-代码示例"><a href="#2-代码示例" class="headerlink" title="2. 代码示例"></a>2. 代码示例</h1><p>本节给出了说明上述功能的代码示例(仅仅附上基于Python的示例代码)。 有关详细信息，请参阅<a href="http://spark.apache.org/docs/2.3.2/ml-pipeline.html#properties-of-pipeline-components" target="_blank" rel="noopener">这里</a>。</p><h2 id="2-1-示例：Estimator，Transformer和Param"><a href="#2-1-示例：Estimator，Transformer和Param" class="headerlink" title="2.1 示例：Estimator，Transformer和Param"></a>2.1 示例：Estimator，Transformer和Param</h2><p>此示例涵盖Estimator，Transformer和Param的概念。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/30 17:01</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : estimator_transformer_param_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"EstimatorTransformerParamExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从（标签，功能）元组列表中准备训练数据。</span></span><br><span class="line">    training = spark.createDataFrame([</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>])),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>])),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.3</span>, <span class="number">1.0</span>])),</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">1.2</span>, <span class="number">-0.5</span>]))], [<span class="string">"label"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建LogisticRegression实例。 这个实例是一个Estimator。</span></span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.01</span>)</span><br><span class="line">    print(<span class="string">"LogisticRegression parameters:\n"</span> + lr.explainParams() + <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ###########################################</span></span><br><span class="line">    <span class="comment"># 使用默认参数训练 LogisticRegression。</span></span><br><span class="line">    model1 = lr.fit(training)</span><br><span class="line">    <span class="comment"># ###########################################</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 由于model1是模型（即由Estimator生成的transformer），我们可以查看fit()期间使用的参数。</span></span><br><span class="line">    <span class="comment"># 这将打印参数（name: value）对，其中names是LogisticRegression实例的唯一ID</span></span><br><span class="line">    print(<span class="string">"Model 1 was fit using parameters: "</span>)</span><br><span class="line">    print(model1.extractParamMap())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ###########################################</span></span><br><span class="line">    <span class="comment"># 我们也可以使用字典作为paramMap指定参数</span></span><br><span class="line">    paramMap = &#123;lr.maxIter: <span class="number">20</span>&#125;</span><br><span class="line">    paramMap[lr.maxIter] = <span class="number">30</span>  <span class="comment"># overwriting</span></span><br><span class="line">    paramMap.update(&#123;lr.regParam: <span class="number">0.1</span>, lr.threshold: <span class="number">0.55</span>&#125;)  <span class="comment"># Specify multiple Params.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 你可以组合paramMaps，它们是dict</span></span><br><span class="line">    paramMap2 = &#123;lr.probabilityCol: <span class="string">"myProbability"</span>&#125;  <span class="comment"># 改变输出的列名</span></span><br><span class="line">    paramMapCombined = paramMap.copy()</span><br><span class="line">    paramMapCombined.update(paramMap2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 现在使用paramMapCombined参数学习一个新模型。</span></span><br><span class="line">    <span class="comment"># paramMapCombined通过lr.set *方法覆盖之前设置的所有参数。</span></span><br><span class="line">    model2 = lr.fit(training, paramMapCombined)</span><br><span class="line">    print(<span class="string">"Model 2 was fit using parameters: "</span>)</span><br><span class="line">    print(model2.extractParamMap())</span><br><span class="line">    <span class="comment"># ###########################################</span></span><br><span class="line"></span><br><span class="line">    test = spark.createDataFrame([</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense([<span class="number">-1.0</span>, <span class="number">1.5</span>, <span class="number">1.3</span>])),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense([<span class="number">3.0</span>, <span class="number">2.0</span>, <span class="number">-0.1</span>])),</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">2.2</span>, <span class="number">-1.5</span>]))], [<span class="string">"label"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用Transformer.transform()方法对测试数据进行预测。LogisticRegression.transform只会使用“features”列。</span></span><br><span class="line">    <span class="comment"># 请注意，model2.transform（）输出“myProbability”列而不是通常的'probability'列，因为我们先前重命名了lr.probabilityCol参数。</span></span><br><span class="line">    prediction = model2.transform(test)</span><br><span class="line">    result = prediction.select(<span class="string">"features"</span>, <span class="string">"label"</span>, <span class="string">"myProbability"</span>, <span class="string">"prediction"</span>).collect()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> result:</span><br><span class="line">        print(<span class="string">"features=%s, label=%s -&gt; prob=%s, prediction=%s"</span></span><br><span class="line">              % (row.features, row.label, row.myProbability, row.prediction))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>如上代码在<code>windows 10</code> | <code>Pycharm</code> | <code>Spark 2.3.2</code>中测试通过。中间日志很多，只附上最后的预测结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">features=[-1.0,1.5,1.3], label=1.0 -&gt; prob=[0.057073041710340174,0.9429269582896599], prediction=1.0</span><br><span class="line">features=[3.0,2.0,-0.1], label=0.0 -&gt; prob=[0.9238522311704104,0.07614776882958973], prediction=0.0</span><br><span class="line">features=[0.0,2.2,-1.5], label=1.0 -&gt; prob=[0.10972776114779419,0.8902722388522057], prediction=1.0</span><br></pre></td></tr></table></figure><h2 id="2-2-示例：-Pipeline"><a href="#2-2-示例：-Pipeline" class="headerlink" title="2.2 示例： Pipeline"></a>2.2 示例： Pipeline</h2><p>此示例遵循上图中所示的简单文本文档Pipeline。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/30 17:16</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : pipeline_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">"PipelineExample"</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从（id,text,label）元组列表中准备训练数据。</span></span><br><span class="line">    training = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="string">"a b c d e spark"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">"b d"</span>, <span class="number">0.0</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">"spark f g h"</span>, <span class="number">1.0</span>),</span><br><span class="line">        (<span class="number">3</span>, <span class="string">"hadoop mapreduce"</span>, <span class="number">0.0</span>)], [<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"label"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 配置ML管道，包括三个阶段：tokenizer，hashingTF和lr。</span></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">"features"</span>)</span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.001</span>)</span><br><span class="line">    pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])  <span class="comment"># pipeline</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit 训练文档</span></span><br><span class="line">    model = pipeline.fit(training)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试</span></span><br><span class="line">    test = spark.createDataFrame([</span><br><span class="line">        (<span class="number">4</span>, <span class="string">"spark i j k"</span>),</span><br><span class="line">        (<span class="number">5</span>, <span class="string">"l m n"</span>),</span><br><span class="line">        (<span class="number">6</span>, <span class="string">"spark hadoop spark"</span>),</span><br><span class="line">        (<span class="number">7</span>, <span class="string">"apache hadoop"</span>)], [<span class="string">"id"</span>, <span class="string">"text"</span>])</span><br><span class="line">    prediction = model.transform(test)</span><br><span class="line">    selected = prediction.select(<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"probability"</span>, <span class="string">"prediction"</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> selected.collect():</span><br><span class="line">        rid, text, prob, prediction = row</span><br><span class="line">        print(<span class="string">"(%d, %s) --&gt; prob=%s, prediction=%f"</span> % (rid, text, str(prob), prediction))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>测试结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(4, spark i j k) --&gt; prob=[0.1596407738787475,0.8403592261212525], prediction=1.000000</span><br><span class="line">(5, l m n) --&gt; prob=[0.8378325685476744,0.16216743145232562], prediction=0.000000</span><br><span class="line">(6, spark hadoop spark) --&gt; prob=[0.06926633132976037,0.9307336686702395], prediction=1.000000</span><br><span class="line">(7, apache hadoop) --&gt; prob=[0.9821575333444218,0.01784246665557808], prediction=0.000000</span><br></pre></td></tr></table></figure><h2 id="2-3-模型选择（超参数调整）"><a href="#2-3-模型选择（超参数调整）" class="headerlink" title="2.3 模型选择（超参数调整）"></a>2.3 模型选择（超参数调整）</h2><p>使用ML Pipelines的一大好处是超参数优化。 有关自动模型选择的更多信息，请参阅<a href="http://spark.apache.org/docs/2.3.2/ml-tuning.html" target="_blank" rel="noopener">这里</a>。</p><p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a>；</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在本节中，我们将介绍&lt;strong&gt;ML Pipelines&lt;/strong&gt;的概念。 ML Pipelines提供了一组基于DataFrame构建的统一的高级API，可帮助用户创建和调整实用的机器学习流程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="大数据" scheme="https://buracagyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>深广度搜索手写实现与networkx对比</title>
    <link href="https://buracagyang.github.io/2019/07/14/breadth-depth-first-search/"/>
    <id>https://buracagyang.github.io/2019/07/14/breadth-depth-first-search/</id>
    <published>2019-07-14T05:48:06.000Z</published>
    <updated>2019-07-30T09:33:26.205Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>前面项目在做一个遍历搜索的时候，有用到深度/广度搜索的相关知识；原理很简单，不再拾人牙慧了哈；这篇文章主要是将我自己简单实现的深广度搜索分享出来并与Python <code>networkx</code>模块中的已有实现做一个简单对比。</p><p><img src="/2019/07/14/breadth-depth-first-search/DFS.gif" alt="DFS">  <img src="/2019/07/14/breadth-depth-first-search/BFS.gif" alt="BFS"></p><a id="more"></a><h1 id="1-手写实现"><a href="#1-手写实现" class="headerlink" title="1. 手写实现"></a>1. 手写实现</h1><h2 id="1-1-网络的定义"><a href="#1-1-网络的定义" class="headerlink" title="1.1 网络的定义"></a>1.1 网络的定义</h2><p>这一步最主要的属性是<code>node_neighbors</code>， 理解成与一个node有连接边(edge)的所有nodes。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现一个最基础的网络结构</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        self.node_neighbors = &#123;&#125;  <span class="comment"># 邻居节点</span></span><br><span class="line">        self.visited = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_node</span><span class="params">(self, node)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.nodes():</span><br><span class="line">            self.node_neighbors[node] = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_nodes</span><span class="params">(self, nodelist)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> nodelist:</span><br><span class="line">            self.add_node(node)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_edge</span><span class="params">(self, edge)</span>:</span></span><br><span class="line">        u, v = edge</span><br><span class="line">        <span class="keyword">if</span> (v <span class="keyword">not</span> <span class="keyword">in</span> self.node_neighbors[u]) <span class="keyword">and</span> (u <span class="keyword">not</span> <span class="keyword">in</span> self.node_neighbors[v]):</span><br><span class="line">            self.node_neighbors[u].append(v)</span><br><span class="line">            <span class="keyword">if</span> u != v:</span><br><span class="line">                self.node_neighbors[v].append(u)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_node_neighbors</span><span class="params">(self, node_neighbors)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> node_neighbors.items():</span><br><span class="line">            self.add_node(k)</span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> v:</span><br><span class="line">                self.add_node(l)</span><br><span class="line">                self.add_edge((k, l))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nodes</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.node_neighbors.keys()</span><br></pre></td></tr></table></figure><h2 id="1-2-深度优先搜索"><a href="#1-2-深度优先搜索" class="headerlink" title="1.2 深度优先搜索"></a>1.2 深度优先搜索</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">depth_first_search</span><span class="params">(self, root=None)</span>:</span></span><br><span class="line">    order = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(node_now)</span>:</span></span><br><span class="line">        self.visited[node_now] = <span class="literal">True</span></span><br><span class="line">        order.append(node_now)</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.node_neighbors[node_now]:</span><br><span class="line">            <span class="keyword">if</span> n <span class="keyword">not</span> <span class="keyword">in</span> self.visited:</span><br><span class="line">                dfs(n)</span><br><span class="line">    <span class="keyword">if</span> root:</span><br><span class="line">        dfs(root)</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> self.nodes():</span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.visited:</span><br><span class="line">            dfs(node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><p>输出深度优先搜索的结果：[0, 1, 3, 4, 2, 5, 6]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 手写实现</span></span><br><span class="line">    node_edges = &#123;<span class="number">0</span>: [<span class="number">1</span>, <span class="number">2</span>], <span class="number">1</span>: [<span class="number">3</span>, <span class="number">4</span>], <span class="number">2</span>: [<span class="number">5</span>, <span class="number">6</span>]&#125;</span><br><span class="line">    root = <span class="number">0</span></span><br><span class="line">    g = Graph()</span><br><span class="line">    g.add_node_neighbors(node_edges)</span><br><span class="line">    print(g.depth_first_search(root))</span><br></pre></td></tr></table></figure><p><img src="/2019/07/14/breadth-depth-first-search/DFS.gif" alt="DFS"></p><h2 id="1-3-广度优先搜索"><a href="#1-3-广度优先搜索" class="headerlink" title="1.3 广度优先搜索"></a>1.3 广度优先搜索</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">breadth_first_search</span><span class="params">(self, root=None)</span>:</span></span><br><span class="line">    queue = []</span><br><span class="line">    order = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bfs</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">while</span> len(queue) &gt; <span class="number">0</span>:</span><br><span class="line">            node_now = queue.pop(<span class="number">0</span>)</span><br><span class="line">            self.visited[node_now] = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">if</span> node_now <span class="keyword">not</span> <span class="keyword">in</span> self.node_neighbors:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 遍历其所有邻居节点(包含父节点和子节点)</span></span><br><span class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> self.node_neighbors[node_now]:  </span><br><span class="line">                <span class="keyword">if</span> (n <span class="keyword">not</span> <span class="keyword">in</span> self.visited) <span class="keyword">and</span> (n <span class="keyword">not</span> <span class="keyword">in</span> queue):</span><br><span class="line">                    queue.append(n)</span><br><span class="line">                    order.append(n)</span><br><span class="line">    <span class="keyword">if</span> root:</span><br><span class="line">        queue.append(root)</span><br><span class="line">        order.append(root)</span><br><span class="line">        bfs()</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> self.nodes():</span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.visited:</span><br><span class="line">            queue.append(node)</span><br><span class="line">            order.append(node)</span><br><span class="line">            bfs()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> order</span><br></pre></td></tr></table></figure><p>输出广度优先搜索的结果：[0, 1, 2, 3, 4, 5, 6]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 手写实现</span></span><br><span class="line">    node_edges = &#123;<span class="number">0</span>: [<span class="number">1</span>, <span class="number">2</span>], <span class="number">1</span>: [<span class="number">3</span>, <span class="number">4</span>], <span class="number">2</span>: [<span class="number">5</span>, <span class="number">6</span>]&#125;</span><br><span class="line">    root = <span class="number">0</span></span><br><span class="line">    g = Graph()</span><br><span class="line">    g.add_node_neighbors(node_edges)</span><br><span class="line">    print(g.breadth_first_search(root))</span><br></pre></td></tr></table></figure><p><img src="/2019/07/14/breadth-depth-first-search/./BFS.gif" alt="BFS"></p><h1 id="2-networkx模块实现"><a href="#2-networkx模块实现" class="headerlink" title="2. networkx模块实现"></a>2. networkx模块实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bd_first_search</span><span class="params">(node_edges, mode, root)</span>:</span></span><br><span class="line">    <span class="comment"># 建立无向有序图</span></span><br><span class="line">    g = nx.OrderedGraph()</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> node_edges.items():</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> v:</span><br><span class="line">            g.add_edge(k, l)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># BDFS</span></span><br><span class="line">    edges_list = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">'breadth'</span>:</span><br><span class="line">        edges_list = list(nx.traversal.bfs_edges(g, root))</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">'depth'</span>:</span><br><span class="line">        edges_list = list(nx.traversal.dfs_edges(g, root))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"please input mode correctly!"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整理结果</span></span><br><span class="line">    nodes_list = <span class="literal">None</span></span><br><span class="line">    nodes_list = list(edges_list[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> edges_list[<span class="number">1</span>:]:</span><br><span class="line">        <span class="comment"># 可以不判断k值，定在nodes_list中</span></span><br><span class="line">        <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> nodes_list:</span><br><span class="line">            nodes_list.append(v)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nodes_list</span><br></pre></td></tr></table></figure><h2 id="2-1-输出深广度搜索结果"><a href="#2-1-输出深广度搜索结果" class="headerlink" title="2.1 输出深广度搜索结果"></a>2.1 输出深广度搜索结果</h2><p>同手写结果是一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(bd_first_search(node_edges, <span class="string">'depth'</span>, root))  <span class="comment"># [0, 1, 3, 4, 2, 5, 6]</span></span><br><span class="line">print(bd_first_search(node_edges, <span class="string">'breadth'</span>, root))  <span class="comment"># [0, 1, 2, 3, 4, 5, 6]</span></span><br></pre></td></tr></table></figure><h1 id="3-搜索效率对比"><a href="#3-搜索效率对比" class="headerlink" title="3. 搜索效率对比"></a>3. 搜索效率对比</h1><p>为了评估自己的手写实现和Python自带模块<code>networkx</code>的搜索效率，简单用Jupyter的Magic Commands <code>%%timeit</code>做评估。</p><p>首先，构建一个随机化一颗树：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">random.seed = <span class="number">2019</span></span><br><span class="line"></span><br><span class="line">node_edges = dict(zip(np.random.randint(<span class="number">1</span>, <span class="number">1000</span>, <span class="number">100</span>), [<span class="number">0</span>] * <span class="number">100</span>))</span><br><span class="line">root = list(node_edges.keys())[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> node_edges:</span><br><span class="line">    node_edges[k] = np.random.randint(<span class="number">1</span>, <span class="number">1000</span>, random.randint(<span class="number">1</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure><h2 id="3-1-深度优先搜索对比结果"><a href="#3-1-深度优先搜索对比结果" class="headerlink" title="3.1 深度优先搜索对比结果"></a>3.1 深度优先搜索对比结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%%timeit</span><br><span class="line"><span class="comment"># 法一：手写实现</span></span><br><span class="line">g = Graph()</span><br><span class="line">g.add_node_neighbors(node_edges)</span><br><span class="line">result1 = g.depth_first_search(root)</span><br></pre></td></tr></table></figure><p>手写实现的结果是：7.08 ms ± 11.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">%%timeit</span><br><span class="line"><span class="comment"># 法二：networkx</span></span><br><span class="line">result2 = bd_first_search(node_edges, <span class="string">'depth'</span>, root)</span><br></pre></td></tr></table></figure><p>用<code>networkx</code>实现的结果是：15 ms ± 63 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</p><h2 id="3-2-广度优先搜索对比结果"><a href="#3-2-广度优先搜索对比结果" class="headerlink" title="3.2 广度优先搜索对比结果"></a>3.2 广度优先搜索对比结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%%timeit -n <span class="number">100</span></span><br><span class="line"><span class="comment"># 法一：手写实现</span></span><br><span class="line">g = Graph()</span><br><span class="line">g.add_node_neighbors(node_edges)</span><br><span class="line">result1 = g.breadth_first_search(root)</span><br></pre></td></tr></table></figure><p>手写实现的结果是：24.2 ms ± 61.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">%%timeit -n <span class="number">100</span></span><br><span class="line"><span class="comment"># 法二：networkx</span></span><br><span class="line">result2 = bd_first_search(node_edges, <span class="string">'depth'</span>, root)</span><br></pre></td></tr></table></figure><p>用<code>networkx</code>实现的结果是：14 ms ± 129 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</p><p>从上面的对比结果可以看出几个问题：</p><ul><li><p>手写实现的深/广度优先搜索，其耗时有较大差异，BFS的耗时是DFS的3倍以上；</p></li><li><p><code>networkx</code>模块的深/广度优先搜索的效率相差不大；</p></li><li><p>当采用DFS时：手写实现较<code>networkx</code>的要快，耗时大概是其1/2；当采用BFS时：手写实现较<code>networkx</code>的要慢，耗时大概是其2倍；</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前面项目在做一个遍历搜索的时候，有用到深度/广度搜索的相关知识；原理很简单，不再拾人牙慧了哈；这篇文章主要是将我自己简单实现的深广度搜索分享出来并与Python &lt;code&gt;networkx&lt;/code&gt;模块中的已有实现做一个简单对比。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/14/breadth-depth-first-search/DFS.gif&quot; alt=&quot;DFS&quot;&gt;  &lt;img src=&quot;/2019/07/14/breadth-depth-first-search/BFS.gif&quot; alt=&quot;BFS&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
  </entry>
  
  <entry>
    <title>信息论2-交叉熵和散度</title>
    <link href="https://buracagyang.github.io/2019/06/21/information-theory-2/"/>
    <id>https://buracagyang.github.io/2019/06/21/information-theory-2/</id>
    <published>2019-06-21T06:21:58.000Z</published>
    <updated>2019-07-14T06:52:21.445Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>主要总结了交叉熵、KL散度、JS散度和wasserstein距离(也称推土机距离，EMD)的相关知识，其中EMD的直观表示可以参见下图：</p><p><img src="/2019/06/21/information-theory-2/EMD.png" alt="EMD"></p><h1 id="1-交叉熵"><a href="#1-交叉熵" class="headerlink" title="1. 交叉熵"></a>1. 交叉熵</h1><p>对应分布为$p(x)$的随机变量，熵$H(p)$表示其最优编码长度。<strong>交叉熵（Cross Entropy）</strong>是按照概率分布$q$的最优编码对真实分布为$p$的信息进行编码的长度，</p><a id="more"></a><p>交叉熵定义为<br>$$<br>H(p, q) = \Bbb{E}_p[−log q(x)] = −\sum_{x}p(x)logq(x) \tag{1}<br>$$<br>在给定$p$的情况下，如果$q$和$p$越接近，交叉熵越小；如果$q$和$p$越远，交叉熵就越大。</p><h1 id="2-KL散度"><a href="#2-KL散度" class="headerlink" title="2. KL散度"></a>2. KL散度</h1><p><strong>KL散度（Kullback-Leibler Divergence）</strong>，也叫<strong>KL距离</strong>或<strong>相对熵(Relative Entropy)</strong>，是用概率分布q来近似p时所造成的信息损失量。KL散度是按照概率分布q的最优编码对真实分布为p的信息进行编码，其平均编码长度$H(p, q)$和$p$的最优平均编码长度$H(p)$之间的差异。对于离散概率分布$p$和$q$，从$q$到$p$的KL散度定义为<br>$$<br>D_{KL}(p∥q) = H(p,q) − H(p) = \sum_{x}p(x)log\frac{p(x)}{q(x)} \tag{2}<br>$$<br>其中为了保证连续性，定义$0 log \frac{0}{0} = 0, 0 log \frac{0}{q} = 0$。</p><p>KL散度可以是衡量两个概率分布之间的距离。KL散度总是非负的，$D_{KL}(p∥q) ≥0$。只有当$p = q$时，$D_{KL}(p∥q) = 0$。如果两个分布越接近，KL散度越小；如果两个分布越远，KL散度就越大。但KL散度并不是一个真正的度量或距离，一是KL散度不满足距离的对称性，二是KL散度不满足距离的三角不等式性质。</p><h1 id="3-JS散度"><a href="#3-JS散度" class="headerlink" title="3. JS散度"></a>3. JS散度</h1><p><strong>JS散度（Jensen–Shannon Divergence）</strong>是一种对称的衡量两个分布相似度的度量方式，定义为<br>$$<br>D_{JS}(p∥q) = \frac{1}{2}D_{KL}(p∥m) + \frac{1}{2}D_{KL}(q∥m) \tag{3}<br>$$<br>其中$m = \frac{1}{2}(p + q)$。</p><p>JS 散度是KL散度一种改进。但两种散度都存在一个问题，即如果两个分布p, q 没有重叠或者重叠非常少时，KL散度和JS 散度都很难衡量两个分布的距离。</p><h1 id="4-Wasserstein距离"><a href="#4-Wasserstein距离" class="headerlink" title="4. Wasserstein距离"></a>4. Wasserstein距离</h1><p><strong>Wasserstein 距离（Wasserstein Distance）</strong>也用于衡量两个分布之间的距离。对于两个分布$q_1, q_2，p^{th}-Wasserstein$距离定义为<br>$$<br>W_p(q_1, q_2) =<br>\left (<br>\inf_{\gamma(x, y) \in \Gamma(q_1, q_2)}\Bbb{E}_{(x,y)\sim \gamma(x,y)}[d(x,y)^p]<br>\right )^{1/p} \tag{4}<br>$$</p><p>其中$Gamma(q_1, q_2)$是边际分布为$q_1$和$q_2$的所有可能的联合分布集合，$d(x, y)$为$x$和$y$的距离，比如$\ell_p$距离等。</p><p>如果将两个分布看作是两个土堆，联合分布$\gamma(x, y)$看作是从土堆$q_1$的位置$x$到土堆$q_2$的位置$y$的搬运土的数量，并有<br>$$<br>\begin{eqnarray}<br>\sum_{x}\gamma(x, y) = q_2(y) \tag{5} \\<br>\sum_{y}\gamma(x, y) = q_1(x) \tag{6}<br>\end{eqnarray}<br>$$<br>$q_1$和$q_2$为$\gamma(x, y)$的两个边际分布。</p><p>$\Bbb{E}_{(x,y) \sim \gamma(x,y)}[d(x, y)^p]$可以理解为在联合分布$\gamma(x, y)$下把形状为$q_1$的土堆搬运到形状为$q_2$的土堆所需的工作量，<br>$$<br>\Bbb{E}_{(x,y) \sim \gamma(x,y)}[d(x, y)^p] = \sum_{(x,y)}\gamma(x, y)d(x, y)^p \tag{7}<br>$$<br>其中从土堆$q_1$中的点$x$到土堆$q_2$中的点$y$的移动土的数量和距离分别为$\gamma(x, y)$和$d(x, y)^p$。因此，Wasserstein距离可以理解为搬运土堆的最小工作量，也称为<strong>推土机距离（Earth-Mover’s Distance，EMD）</strong>。</p><p>Wasserstein距离相比KL散度和JS 散度的优势在于：即使两个分布没有重叠或者重叠非常少，Wasserstein 距离仍然能反映两个分布的远近。</p><p>对于$\Bbb{R}^n$空间中的两个高斯分布$p = \cal{N}(\mu1,Σ1)$和$q = \cal{N}(\mu2,Σ2)$，它们的$2^{nd}-Wasserstein$距离为<br>$$<br>D_W(p∥q) = ||μ1 − μ2||_2^2 + tr<br>\left (<br>\begin {matrix}<br>\sum_1 + \sum_2 - 2(\sum_2^{1/2}\sum_1\sum_2^{1/2})^{1/2}<br>\end {matrix}<br>\right ) \tag{8}<br>$$<br>当两个分布的的方差为0时，$2^{nd}-Wasserstein$距离等价于欧氏距离($||μ1 − μ2||_2^2$)。</p><h2 id="4-1-EMD示例"><a href="#4-1-EMD示例" class="headerlink" title="4.1 EMD示例"></a>4.1 EMD示例</h2><p>求解两个分布的EMD可以通过一个<strong>Linear Programming（LP）</strong>问题来解决，可以将这个问题表达为一个规范的问题：寻找一个向量$x \in \Bbb{R}$，最小化损失$z = c^Tx, c\in \Bbb{R}^n$，使得$Ax = b, A \in \Bbb{R}^{m\times n},b \in \Bbb{R}^m, x \geq 0$，显然，在求解EMD时有：<br>$$<br>x = vec(\Gamma) \\<br>c = vec(D)<br>$$<br>其中$\Gamma$是$q_1$和$q_2$的联合概率分布，$D$是移动距离。</p><p>首先生成两个分布$q_1$和$q_2$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> colors</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> linprog</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> linprog</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"></span><br><span class="line">l = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">q1 = np.array([<span class="number">13</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">21</span>, <span class="number">15</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">15</span>])</span><br><span class="line">q2 = np.array([<span class="number">1</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">17</span>, <span class="number">12</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">15</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line">q1 = q1 / np.sum(q1)</span><br><span class="line">q2 = q2 / np.sum(q2)</span><br><span class="line"></span><br><span class="line">plt.bar(range(l), q1, <span class="number">1</span>, color=<span class="string">'blue'</span>, alpha=<span class="number">1</span>, edgecolor=<span class="string">'black'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.bar(range(l), q1, <span class="number">1</span>, color=<span class="string">'green'</span>, alpha=<span class="number">1</span>, edgecolor=<span class="string">'black'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2019/06/21/information-theory-2/q1.svg" alt="q1"></p><p><img src="/2019/06/21/information-theory-2/q2.svg" alt="q2"></p><p>计算其联合概率分布和距离矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">D = np.ndarray(shape=(l, l))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(l):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(l):</span><br><span class="line">        D[i, j] = abs(range(l)[i] - range(l)[j])</span><br><span class="line"></span><br><span class="line">A_1 = np.zeros((l, l, l))</span><br><span class="line">A_2 = np.zeros((l, l, l))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(l):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(l):</span><br><span class="line">        A_1[i, i, j] = <span class="number">1</span></span><br><span class="line">        A_2[i, j, i] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">A = np.concatenate((A_1.reshape((l, l**<span class="number">2</span>)), A_2.reshape((l, l**<span class="number">2</span>))), axis=<span class="number">0</span>)  <span class="comment"># 20x100</span></span><br><span class="line">b = np.concatenate((q1, q2), axis=<span class="number">0</span>)  <span class="comment"># 20x1</span></span><br><span class="line">c = D.reshape((l**<span class="number">2</span>))  <span class="comment"># 100x1</span></span><br><span class="line"></span><br><span class="line">opt_res = linprog(c, A_eq=A, b_eq=b, bounds=[<span class="number">0</span>, <span class="literal">None</span>])</span><br><span class="line">emd = opt_res.fun</span><br><span class="line">gamma = opt_res.x.reshape((l, l))</span><br><span class="line">print(<span class="string">"EMD: "</span>, emd)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gamma</span></span><br><span class="line">plt.imshow(gamma, cmap=cm.gist_heat, interpolation=<span class="string">'nearest'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># D</span></span><br><span class="line">plt.imshow(D, cmap=cm.gist_heat, interpolation=<span class="string">'nearest'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2019/06/21/information-theory-2/gamma.svg" alt="gamma"></p><p><img src="/2019/06/21/information-theory-2/distances.svg" alt="distances"></p><p>最终得到EMD=0.8252404410039889</p><h2 id="4-2-利用对偶问题求解EMD"><a href="#4-2-利用对偶问题求解EMD" class="headerlink" title="4.2 利用对偶问题求解EMD"></a>4.2 利用对偶问题求解EMD</h2><p>事实上，4.1节说的求解方式在很多情形下是不适用的，在示例中我们只用了10个状态去描述分布，但是在很多应用中，输入的状态数很容易的就到达了上万维，甚至近似求$\gamma$都是不可能的。</p><p>但实际上我们并不需要关注$\gamma$，我们仅需要知道具体的EMD数值，我们必须能够计算梯度$\nabla_{P_1}EMD(P_1, P_2)$，因为$P_1$和$P_2$仅仅是我们的约束条件，这是不可能以任何直接的方式实现的。</p><p>但是，这里有另外一个更加方便的方法去求解EMD；任何LP问题都有两种表示问题的方法：原始问题(4.1所述)和对偶问题。所以刚才的问题转化成对偶问题如下：<br>$$<br>\begin {eqnarray}<br>maxmize \qquad &amp;\tilde{z}=b^T.y \\<br>st. \qquad &amp;A^T.y \leq c<br>\end {eqnarray} \tag{9}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">opt_res = linprog(-b, A.T, c, bounds=(<span class="literal">None</span>, <span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line">emd = -opt_res.fun</span><br><span class="line">f = opt_res.x[<span class="number">0</span>:l]</span><br><span class="line">g = opt_res.x[l:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(dual_result)</span></span><br><span class="line">print(<span class="string">"dual EMD: "</span>, emd)</span><br></pre></td></tr></table></figure><p>得到其结果：EMD=0.8252404410039867</p><p>或者另一种方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">emd = np.sum(np.multiply(q1, f)) + np.sum(np.multiply(q2, g))</span><br><span class="line">print(<span class="string">"emd: "</span>, emd)</span><br></pre></td></tr></table></figure><p>得到其结果，EMD=0.8252404410039877</p><p>最后，再看一下两个分布的对应转换情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># q1</span></span><br><span class="line">r = range(l)</span><br><span class="line">current_bottom = np.zeros(l)</span><br><span class="line">cNorm = colors.Normalize(vmin=<span class="number">0</span>, vmax=l)</span><br><span class="line">colorMap = cm.ScalarMappable(norm=cNorm, cmap=cm.terrain)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">    plt.bar(r, gamma[r, i], <span class="number">1</span>, color=colorMap.to_rgba(r), bottom=current_bottom, edgecolor=<span class="string">'black'</span>)</span><br><span class="line">    current_bottom = current_bottom + gamma[r, i]</span><br><span class="line"></span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2019/06/21/information-theory-2/earth_move_q1.svg" alt="earth_move_q1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># q2</span></span><br><span class="line">r = range(l)</span><br><span class="line">current_bottom = np.zeros(l)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">    plt.bar(r, gamma[i, r], <span class="number">1</span>, color=colorMap.to_rgba(i), bottom=current_bottom, edgecolor=<span class="string">'black'</span>)</span><br><span class="line">    current_bottom = current_bottom + gamma[i, r]</span><br><span class="line"></span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2019/06/21/information-theory-2/earth_move_q2.svg" alt="earth_move_q2"></p><p>主要参考:</p><ul><li><a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></li><li><a href="https://vincentherrmann.github.io/blog/wasserstein/" target="_blank" rel="noopener">https://vincentherrmann.github.io/blog/wasserstein/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;主要总结了交叉熵、KL散度、JS散度和wasserstein距离(也称推土机距离，EMD)的相关知识，其中EMD的直观表示可以参见下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/06/21/information-theory-2/EMD.png&quot; alt=&quot;EMD&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;1-交叉熵&quot;&gt;&lt;a href=&quot;#1-交叉熵&quot; class=&quot;headerlink&quot; title=&quot;1. 交叉熵&quot;&gt;&lt;/a&gt;1. 交叉熵&lt;/h1&gt;&lt;p&gt;对应分布为$p(x)$的随机变量，熵$H(p)$表示其最优编码长度。&lt;strong&gt;交叉熵（Cross Entropy）&lt;/strong&gt;是按照概率分布$q$的最优编码对真实分布为$p$的信息进行编码的长度，&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>信息论1-熵</title>
    <link href="https://buracagyang.github.io/2019/06/21/information-theory-1/"/>
    <id>https://buracagyang.github.io/2019/06/21/information-theory-1/</id>
    <published>2019-06-21T05:52:58.000Z</published>
    <updated>2019-06-24T08:37:39.650Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p><strong>信息论（Information Theory）</strong>是数学、物理、统计、计算机科学等多个学科的交叉领域。信息论是由Claude Shannon 最早提出的，主要研究信息的量化、存储和通信等方法。这里，“信息”是指一组消息的集合。假设在一个噪声通道上发送消息，我们需要考虑如何对每一个信息进行编码、传输以及解码，使得接收者可以尽可能准确地重构出消息。</p><p>在机器学习相关领域，信息论也有着大量的应用。比如特征抽取、统计推断、自然语言处理等。</p><a id="more"></a><h1 id="1-自信息和熵"><a href="#1-自信息和熵" class="headerlink" title="1. 自信息和熵"></a>1. 自信息和熵</h1><p><strong>熵（Entropy）</strong>最早是物理学的概念，用于表示一个热力学系统的无序程度。在信息论中，熵用来衡量一个随机事件的不确定性。假设对一个随机变量$X$（取值集合为$\cal{X}$，概率分布为$p(x), x \in \cal{X}$）进行编码，<strong>自信息（Self Information）</strong> $I(x)$是变量$X = x$时的信息量或编码长度，定义为<br>$$<br>I(x) = −log(p(x)) \tag{1}<br>$$<br>那么随机变量$X$的平均编码长度，即熵定义为<br>$$<br>H(X) = \Bbb{E}_X[I(x)] = \Bbb{E}_X[−log(p(x))] = −\sum_{x \in \cal{X}}p(x) log p(x) \tag{2}<br>$$<br>其中当$p(x_i) = 0$时，我们定义$0 log 0 = 0$，与极限一致，$\lim_{p\to 0+} p log p = 0$。</p><p>熵是一个随机变量的平均编码长度，即自信息的数学期望。熵越高，则随机变量的信息越多，熵越低；则信息越少。如果变量$X$当且仅当在$x$时$p(x) = 1$，则熵为0。也就是说，对于一个<strong>确定的信息(不确定概率为0)</strong>，其熵为0，信息量也为0。如果其概率分布为一个均匀分布，则熵最大。假设一个随机变量X 有三种可能值$x_1, x_2, x_3$，不同概率分布对应的熵如下：</p><table><thead><tr><th style="text-align:center">p(x1)</th><th style="text-align:center">p(x2)</th><th style="text-align:center">p(x3)</th><th style="text-align:center">熵</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">1/2</td><td style="text-align:center">1/4</td><td style="text-align:center">1/4</td><td style="text-align:center">$\frac{3}{2}(log2)$</td></tr><tr><td style="text-align:center">1/3</td><td style="text-align:center">1/3</td><td style="text-align:center">1/3</td><td style="text-align:center">log3</td></tr></tbody></table><h1 id="2-联合熵和条件熵"><a href="#2-联合熵和条件熵" class="headerlink" title="2. 联合熵和条件熵"></a>2. 联合熵和条件熵</h1><p>对于两个离散随机变量$X$和$Y$ ，假设$X$取值集合为$cal{X}$；$Y$取值集合为$\cal{Y}$，其联合概率分布满足为$p(x, y)$，</p><p>则$X$和$Y$的<strong>联合熵（Joint Entropy）</strong>为<br>$$<br>H(X, Y) = −\sum_{x \in \cal{X}} \sum_{y \in \cal{Y}}p(x, y) log p(x, y) \tag{3}<br>$$<br>$X$和$Y$的<strong>条件熵（Conditional Entropy）</strong>为<br>$$<br>H(X|Y) = −\sum_{x \in \cal{X}} \sum_{y \in \cal{Y}}p(x, y) log p(x|y) = −\sum_{x \in \cal{X}} \sum_{y \in \cal{Y}}p(x, y) log \frac{p(x,y)}{p(y)} \tag{4}<br>$$<br>根据其定义，条件熵也可以写为<br>$$<br>H(X|Y) = H(X, Y) − H(Y) \tag{5}<br>$$</p><h1 id="3-互信息"><a href="#3-互信息" class="headerlink" title="3. 互信息"></a>3. 互信息</h1><p><strong>互信息（Mutual Information）</strong>是衡量已知一个变量时，另一个变量不确定性的减少程度。两个离散随机变量X 和Y 的互信息定义为<br>$$<br>I(X; Y ) =\sum_{x \in \cal{X}} \sum_{y \in \cal{Y}}p(x, y) \frac{log p(x, y)}{p(x)p(y)} \tag{6}<br>$$<br>互信息的一个性质为<br>$$<br>\begin{eqnarray}<br>I(X;Y) &amp;=&amp; H(X) − H(X|Y) \tag{7} \\<br>&amp;=&amp; H(Y) − H(Y|X) \tag{8} \\<br>&amp;=&amp; H(X) + H(Y) - H(X, Y) \tag{9}<br>\end{eqnarray}<br>$$</p><p>如果X和Y相互独立，即X不对Y提供任何信息，反之亦然，因此它们的互信息最小， 即$I(X;Y)$为零。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;信息论（Information Theory）&lt;/strong&gt;是数学、物理、统计、计算机科学等多个学科的交叉领域。信息论是由Claude Shannon 最早提出的，主要研究信息的量化、存储和通信等方法。这里，“信息”是指一组消息的集合。假设在一个噪声通道上发送消息，我们需要考虑如何对每一个信息进行编码、传输以及解码，使得接收者可以尽可能准确地重构出消息。&lt;/p&gt;
&lt;p&gt;在机器学习相关领域，信息论也有着大量的应用。比如特征抽取、统计推断、自然语言处理等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数学优化3-拉格朗日乘数法与KKT条件</title>
    <link href="https://buracagyang.github.io/2019/06/19/mathematical-optimization-3/"/>
    <id>https://buracagyang.github.io/2019/06/19/mathematical-optimization-3/</id>
    <published>2019-06-19T12:47:06.000Z</published>
    <updated>2019-09-27T07:52:42.397Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>主要介绍一下数学优化中的拉格朗日乘数法和KKT条件，其实在 <a href="https://blog.csdn.net/buracag_mc/article/details/76762249" target="_blank" rel="noopener">拙文</a> 中已经有关于KKT条件的简要介绍和自己的个人总结，这里再一起回顾一下。</p><a id="more"></a><p><strong>拉格朗日乘数法（Lagrange Multiplier）</strong>是约束优化问题的一种有效求解方法。约束优化问题可以表示为<br>$$<br>\begin{eqnarray}<br>\min_{x} \qquad &amp;f(x) \\<br>subject \quad to \qquad &amp;h_i(x) = 0, i = 1, … ,m \\<br>\qquad &amp;g_j(x) ≤ 0, j = 1, . . . , n<br>\end{eqnarray} \tag{1}<br>$$</p><p>其中$h_i(x)$为等式约束函数，$g_j(x)$为不等式约束函数。x的可行域为<br>$$<br>\cal{D} = domf\cap \bigcap_{i=1}^{m} domh_i \cap \bigcap_{j=1}^{n} domg_j \subseteq \Bbb{R}^d \tag{2}<br>$$<br>其中$domf$是函数f的定义域。</p><h1 id="1-等式约束优化问题"><a href="#1-等式约束优化问题" class="headerlink" title="1. 等式约束优化问题"></a>1. 等式约束优化问题</h1><p>如果公式(1) 中只有等式约束，我们可以构造一个拉格朗日函数Λ(x, λ):<br>$$<br>\Lambda(x, \lambda) = f(x) + \sum_{i=1}^{m}\lambda_i h_i(x) \tag{3}<br>$$<br>其中$\lambda$为拉格朗日乘数。如果$f(x^∗)$是原始约束优化问题的局部最优值，那么存在一个$λ^∗$使得$(x^∗, λ^∗)$为拉格朗日函数$Λ(x, λ)$的平稳点（stationary point）。因此，只需要令$\frac{\partialΛ(x,λ)}{\partial x} = 0$和$\frac{\partialΛ(x,λ)}{\partial \lambda} = 0$，得到<br>$$<br>\nabla f(x) + \sum_{i=1}^{m}\lambda_i \nabla h_i(x) = 0 \tag{4}<br>$$</p><p>$$<br>h_i(x) = 0, \qquad i=0, …, m \tag{5}<br>$$</p><p>上面方程组的解即为原始问题的可能解。在实际应用中，需根据问题来验证是否为极值点。</p><p>拉格朗日乘数法是将一个有$d$个变量和$m$个等式约束条件的最优化问题转换为一个有$d + m$个变量的函数求平稳点的问题。拉格朗日乘数法所得的平稳点会包含原问题的所有极值点，但并不保证每个平稳点都是原问题的极值点。</p><h1 id="2-不等式约束优化问题"><a href="#2-不等式约束优化问题" class="headerlink" title="2. 不等式约束优化问题"></a>2. 不等式约束优化问题</h1><p>对于公式(1) 中定义的一般约束优化问题，其拉格朗日函数为<br>$$<br>\Lambda(x, a, b) = f(x) + \sum_{i=1}^{m}a_i h_i(x) + \sum_{j=1}^{n}b_j g_j(x) \tag{6}<br>$$<br>其中$a = [a_1, … , a_m]^T$为等式约束的拉格朗日乘数，$b = [b_1, … , b_n]^T$为不等式约束的拉格朗日乘数。</p><p>当约束条件不满足时，有$\max_{a,b} \Lambda(x, a, b) = \infty$；当约束条件满足时并且$b ≥ 0$时，$\max_{a,b} \Lambda(x, a, b) = f(x)$。因此原始约束优化问题等价于<br>$$<br>\min_x \max_{a,b} \Lambda(x, a, b) \tag{7}<br>$$</p><p>$$<br>subject \quad to \qquad b ≥ 0 \tag{8}<br>$$</p><p>这个min-max优化问题称为<strong>主问题（Primal Problem）</strong>。</p><p><strong>对偶问题</strong> 主问题的优化一般比较困难，我们可以通过交换min-max 的顺序来简化。定义拉格朗日对偶函数为<br>$$<br>\Gamma(a, b) = \inf_{x \in D}\Lambda (x, a, b) \tag{9}<br>$$</p><p>$\Gamma(a, b)$是一个凹函数，即使$f(x)$是非凸的。</p><p>当$b \geq 0$时，对于任意的$\tilde{x} \in \cal{D}$，有<br>$$<br>\Gamma(a, b) = \inf_{x\in D}\Lambda(x, a, b) \leq \Lambda(\tilde{x}, a, b) ≤ f(\tilde{x}) \tag{10}<br>$$<br>令$p^∗$是原问题的最优值，则有<br>$$<br>\Gamma(a, b) \leq p^∗ \tag{11}<br>$$<br>即拉格朗日对偶函数$Γ(a, b)$为原问题最优值的下界。</p><p>优化拉格朗日对偶函数$Γ(a, b)$并得到原问题的最优下界，称为<strong>拉格朗日对偶问题（Lagrange Dual Problem）</strong>。<br>$$<br>\begin{eqnarray}<br>\max_{a,b} \qquad &amp;\Gamma(a, b) \tag{12}  \\<br>subject \quad to \qquad &amp;b ≥ 0 \tag{13}<br>\end{eqnarray}<br>$$<br>拉格朗日对偶函数为凹函数，因此拉格朗日对偶问题为<strong>凸优化问题</strong>。</p><p>令$d^∗$表示拉格朗日对偶问题的最优值，则有$d^∗ \leq p^∗$，这个性质称为<strong>弱对偶性（Weak Duality）</strong>。如果$d^∗ = p^∗$，这个性质称为<strong>强对偶性（Strong Duality）</strong>。</p><p>当强对偶性成立时，令$x^∗$和$a^∗, b^∗$分别是原问题和对偶问题的最优解，那么它们满足以下条件：<br>$$<br>\begin{eqnarray}<br>&amp; \nabla f(x^∗) + \sum_{i=1}^ma_i^∗ \nabla h_i(x^∗) + \sum_{j=1}^{n}b_j^∗\nabla g_j(x^∗) = 0 \tag{14} \\<br>&amp; h_i(x^∗) = 0, \quad i = 0, … ,m \tag{15} \\<br>&amp; g_j(x^∗) \leq 0, \quad j = 0, … , n \tag{16} \\<br>&amp; b_j^∗ g_j(x^∗) = 0, \quad j = 0, … , n \tag{17} \\<br>&amp; b_j^∗ \geq 0, \quad j = 0, … , n \tag{18}<br>\end{eqnarray}<br>$$<br>称为不等式约束优化问题的<strong>KKT条件（Karush-Kuhn-Tucker Conditions）</strong>。KKT条件是拉格朗日乘数法在不等式约束优化问题上的泛化。当原问题是凸优化问题时，满足KKT条件的解也是原问题和对偶问题的最优解。</p><p>KKT条件中需要关注的是公式(17)，称为互补松弛条件（Complementary Slackness）。如果最优解$x^∗$出现在不等式约束的边界上$g_j(x) = 0$，则$b_j^∗ &gt; 0$；如果$x^∗$出现在不等式约束的内部$g_j(x) &lt; 0$，则$b_j^∗$= 0$。互补松弛条件说明当最优解出现在不等式约束的内部，则约束失效。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;主要介绍一下数学优化中的拉格朗日乘数法和KKT条件，其实在 &lt;a href=&quot;https://blog.csdn.net/buracag_mc/article/details/76762249&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;拙文&lt;/a&gt; 中已经有关于KKT条件的简要介绍和自己的个人总结，这里再一起回顾一下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数学优化2-优化算法</title>
    <link href="https://buracagyang.github.io/2019/06/18/mathematical-optimization-2/"/>
    <id>https://buracagyang.github.io/2019/06/18/mathematical-optimization-2/</id>
    <published>2019-06-18T05:17:45.000Z</published>
    <updated>2019-08-09T08:10:26.436Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>优化问题一般都是通过迭代的方式来求解：通过猜测一个初始的估计$x_0$，然后不断迭代产生新的估计$x_1, x_2, …  x_t$，希望$x_t$最终收敛到期望的最优解$x^∗$。</p><p>一个好的优化算法应该是在一定的时间或空间复杂度下能够快速准确地找到最优解。同时，好的优化算法受初始猜测点的影响较小，通过迭代能稳定地找到最优解$x^∗$的邻域，然后迅速收敛于$x^∗$。</p><p>优化算法中常用的迭代方法有线性搜索和置信域方法等。线性搜索的策略是寻找方向和步长，具体算法有梯度下降法、牛顿法、共轭梯度法等。在<a href="https://blog.csdn.net/buracag_mc/article/details/77620686" target="_blank" rel="noopener">文章</a>中也简要介绍过梯度下降的概念，这里为使得整个体系完整故重新记录一下。</p><a id="more"></a><h1 id="1-全局最优和局部最优"><a href="#1-全局最优和局部最优" class="headerlink" title="1. 全局最优和局部最优"></a>1. 全局最优和局部最优</h1><p>对于很多非线性优化问题，会存在若干个局部的极小值。<strong>局部最小值</strong>，或<strong>局部最优解</strong>$x^∗$定义为：存在一个$\delta &gt; 0$，对于所有的满足$∥x−x^*∥ \leq \delta$的x，公式$f(x^∗) \leq f(x)$成立。也就是说，在$x^∗$的附近区域内，所有的函数值都大于或者等于$f(x^∗)$。</p><p>对于所有的$x \in A$，都有$f(x^∗) \leq f(x)$成立，则$x^∗$为全局最小值，或全局最优解。一般的，求局部最优解是容易的，但很难保证其为全局最优解。对于线性规划或凸优化问题，局部最优解就是全局最优解。</p><p>要确认一个点$x^∗$是否为局部最优解，通过比较它的邻域内有没有更小的函数值是不现实的。如果函数$f(x)$是二次连续可微的，我们可以通过检查目标函数在点$x^∗$的梯度$∇f(x^∗)$和Hessian矩阵$\nabla^2f(x^∗)$来判断。</p><blockquote><p><strong>定理1 局部最小值的一阶必要条件：</strong> 如果$x^∗$为局部最优解并且函数$f$在$x^∗$的邻域内一阶可微，则在$∇f(x^∗) = 0$。</p></blockquote><p><strong>证明.</strong> 如果函数$f(x)$是连续可微的，根据泰勒展开公式（Taylor’s Formula），函数$f(x)$的一阶展开可以近似为<br>$$<br>f(x^∗ + \Delta x) = f(x^∗) + \Delta x^T \nabla f(x^∗) \tag{1}<br>$$<br>假设$∇f(x^∗) \neq 0$，则可以找到一个$\Delta x$（比如$\Delta x = −\alpha ∇f(x^∗)$，$\alpha$为很小的正数），使得<br>$$<br>f(x^∗ + \Delta x) − f(x^∗) = \Delta x^T \nabla f(x^∗) \leq 0 \tag{2}<br>$$</p><p>这和局部最优的定义矛盾。</p><blockquote><p><strong>定理2 局部最优解的二阶必要条件：</strong> 如果$x^∗$为局部最优解并且函数$f$在$x^∗$的领域内二阶可微，则$\nabla f(x^∗)=0, \nabla^2 f(x^*)$为半正定矩阵。</p></blockquote><p><strong>证明.</strong> 如果函数$f(x)$是二次连续可微的，函数$f(x)$的二阶展开可以近似为<br>$$<br>f(x^∗ + \Delta x) = f(x^∗) + \Delta x^T \nabla f(x^∗) + \frac{1}{2}\Delta x^T (\nabla^2f(x^∗))\Delta x \tag{3}<br>$$<br>由一阶必要性定理可知$\nabla f(x^∗) = 0$，则<br>$$<br>f(x^∗ + \Delta x) − f(x^∗) = \frac{1}{2}\Delta x^T (\nabla^2 f(x^∗))\Delta x \geq 0 \tag{4}<br>$$<br>即Hessian矩阵$\nabla^2f(x^∗)$为半正定矩阵。</p><h1 id="2-梯度下降法"><a href="#2-梯度下降法" class="headerlink" title="2. 梯度下降法"></a>2. 梯度下降法</h1><p><strong>梯度下降法（Gradient Descent Method）</strong>，也叫<strong>最速下降法（Steepest Descend Method）</strong>，经常用来求解无约束优化的极小值问题。</p><p>对于函数$f(x)$，如果$f(x)$在点$x_t$附近是连续可微的，那么$f(x)$下降最快的方向是$f(x)$在$x_t$点的梯度方法的反方向。根据泰勒一阶展开公式，<br>$$<br>f(x_{t+1}) = f(x_t + \Delta x) \approx f(x_t) + \Delta x^T \nabla f(x_t) \tag{5}<br>$$<br>要使得$f(x_{t+1}) &lt; f(x_t)$，就得使$\Delta x^T\nabla f(x_t) &lt; 0$。我们取$\Delta x = −\alpha \nabla f(x_t)$。如果$\alpha &gt; 0$为一个够小数值时，那么$f(x_{t+1}) &lt; f(x_t)$ 成立。</p><p>这样我们就可以从一个初始值$x_0$出发，通过迭代公式<br>$$<br>x_{t+1} = x_t − \alpha_t\nabla f(x_t), t \geq 0 \tag{6}<br>$$<br>生成序列$x_0, x_1, x_2, …$ 使得<br>$$<br>f(x_0) \geq f(x_1) \geq f(x_2) \geq … \tag{7}<br>$$<br>如果顺利的话，序列($x_n$) 收敛到局部最优解$x^∗$。注意每次迭代步长$\alpha$可以改变，但其取值必须合适，如果过大就不会收敛，如果过小则收敛速度太慢。</p><p>梯度下降法的示例过程可以参见下图：</p><p><img src="/2019/06/18/mathematical-optimization-2/sample.gif" alt="sample"></p><p>梯度下降法为一阶收敛算法，当靠近极小值时梯度变小，收敛速度会变慢，并且可能以“之字形”的方式下降。如果目标函数为二阶连续可微，我们可以采用牛顿法。牛顿法为二阶收敛算法，收敛速度更快，但是每次迭代需要计算Hessian矩阵的逆矩阵，复杂度较高。相反，如果我们要求解一个最大值问题，就需要向梯度正方向迭代进行搜索，逐渐接近函数的局部极大值点，这个过程则被称为梯度上升法（GradientAscent）。</p><p>后面准备专门整理一份梯度下降中关于批量梯度下降(BGD)、随机梯度下降(SGD)、小批量梯度下降(MBGD)、Momentum、Adagrad等资料。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;优化问题一般都是通过迭代的方式来求解：通过猜测一个初始的估计$x_0$，然后不断迭代产生新的估计$x_1, x_2, …  x_t$，希望$x_t$最终收敛到期望的最优解$x^∗$。&lt;/p&gt;
&lt;p&gt;一个好的优化算法应该是在一定的时间或空间复杂度下能够快速准确地找到最优解。同时，好的优化算法受初始猜测点的影响较小，通过迭代能稳定地找到最优解$x^∗$的邻域，然后迅速收敛于$x^∗$。&lt;/p&gt;
&lt;p&gt;优化算法中常用的迭代方法有线性搜索和置信域方法等。线性搜索的策略是寻找方向和步长，具体算法有梯度下降法、牛顿法、共轭梯度法等。在&lt;a href=&quot;https://blog.csdn.net/buracag_mc/article/details/77620686&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;文章&lt;/a&gt;中也简要介绍过梯度下降的概念，这里为使得整个体系完整故重新记录一下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>数学优化1-数学优化的类型</title>
    <link href="https://buracagyang.github.io/2019/06/17/mathematical-optimization-1/"/>
    <id>https://buracagyang.github.io/2019/06/17/mathematical-optimization-1/</id>
    <published>2019-06-17T11:45:42.000Z</published>
    <updated>2019-12-17T12:11:31.243Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p><strong>数学优化（Mathematical Optimization）</strong>问题，也叫最优化问题，是指在一定约束条件下，求解一个目标函数的最大值（或最小值）问题。</p><p>数学优化问题的定义为：给定一个目标函数（也叫代价函数）$f : \cal{A} → \Bbb{R}$，寻找一个变量（也叫参数）$x^* \in \cal{D}$，使得对于所有$\cal{D}$中的$x，f(x^∗) ≤ f(x)$（最小化）；或者$f(x^∗) \geq f(x)$（最大化），其中$\cal{D}$为变量$x$的约束集，也叫可行域；$\cal{D}$中的变量被称为是可行解。</p><a id="more"></a><h1 id="1-离散优化和连续优化"><a href="#1-离散优化和连续优化" class="headerlink" title="1. 离散优化和连续优化"></a>1. 离散优化和连续优化</h1><p>根据输入变量$x$的值域是否为实数域，数学优化问题可以分为离散优化问题和连续优化问题。</p><h2 id="1-1-离散优化问题"><a href="#1-1-离散优化问题" class="headerlink" title="1.1 离散优化问题"></a>1.1 离散优化问题</h2><p><strong>离散优化（Discrete Optimization）</strong>问题是目标函数的输入变量为离散变量，比如为整数或有限集合中的元素。离散优化问题主要有两个分支：</p><ol><li><strong>组合优化（Combinatorial Optimization）</strong>：其目标是从一个有限集合中找出使得目标函数最优的元素。在一般的组合优化问题中，集合中的元素之间存在一定的关联，可以表示为图结构。典型的组合优化问题有旅行商问题、最小生成树问题、图着色问题等。很多机器学习问题都是组合优化问题，比如特征选择、聚类问题、超参数优化问题以及<strong>结构化学习（Structured Learning）</strong>中标签预测问题等。</li><li><strong>整数规划（Integer Programming）</strong>：输入变量$x \in \Bbb{Z}^d$为整数。一般常见的整数规划问题为<strong>整数线性规划（Integer Linear Programming，ILP）</strong>。整数线性规划的一种最直接的求解方法是：（1）去掉输入必须为整数的限制，将原问题转换为一般的线性规划问题，这个线性规划问题为原问题的松弛问题；（2）求得相应松弛问题的解；（3）把松弛问题的解四舍五入到最接近的整数。但是这种方法得到的解一般都不是最优的，因此原问题的最优解不一定在松弛问题最优解的附近。另外，这种方法得到的解也不一定满足约束条件。</li></ol><p>离散优化问题的求解一般都比较困难，优化算法的复杂度都比较高。</p><h2 id="1-2-连续优化问题"><a href="#1-2-连续优化问题" class="headerlink" title="1.2 连续优化问题"></a>1.2 连续优化问题</h2><p><strong>连续优化（Continuous Optimization）</strong>问题是目标函数的输入变量为连续变量$x \in \Bbb{R}^d$，即目标函数为实函数。下文的内容主要以连续优化为主。</p><h1 id="2-无约束优化和约束优化"><a href="#2-无约束优化和约束优化" class="headerlink" title="2. 无约束优化和约束优化"></a>2. 无约束优化和约束优化</h1><p>在连续优化问题中，根据是否有变量的约束条件，可以将优化问题分为无约束优化问题和约束优化问题。</p><p><strong>无约束优化问题（Unconstrained Optimization）</strong>的可行域为整个实数域$\cal{D} = \Bbb{R}^d$，可以写为<br>$$<br>\min_{x} f(x) \tag{1}<br>$$<br>其中$x \in \Bbb{R}^d$为输入变量，$f : \Bbb{R}^d \to \Bbb{R}$为目标函数。</p><p><strong>约束优化问题（Constrained Optimization）</strong>中变量x需要满足一些等式或不等式的约束。约束优化问题通常使用拉格朗日乘数法来进行求解。</p><h1 id="3-线性优化和非线性优化"><a href="#3-线性优化和非线性优化" class="headerlink" title="3. 线性优化和非线性优化"></a>3. 线性优化和非线性优化</h1><p>如果在公式(1) 中，目标函数和所有的约束函数都为线性函数，则该问题为<strong>线性规划问题（Linear Programming）</strong>。相反，如果目标函数或任何一个约束函数为非线性函数，则该问题为<strong>非线性规划问题（Nonlinear Programming）</strong>。</p><p>在非线性优化问题中，有一类比较特殊的问题是<strong>凸优化问题（Convex Programming）</strong>。在凸优化问题中，变量x 的可行域为凸集，即对于集合中任意两点，它们的连线全部位于在集合内部。目标函数f也必须为凸函数，即满足<br>$$<br>f(\alpha x + (1 − \alpha)y) \leq \alpha f(x) + (1 − \alpha)f(y), ∀\alpha \in [0, 1] \tag{2}<br>$$</p><p>凸优化问题是一种特殊的约束优化问题，需满足目标函数为凸函数，并且等式约束函数为线性函数，不等式约束函数为凹函数。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数学优化（Mathematical Optimization）&lt;/strong&gt;问题，也叫最优化问题，是指在一定约束条件下，求解一个目标函数的最大值（或最小值）问题。&lt;/p&gt;
&lt;p&gt;数学优化问题的定义为：给定一个目标函数（也叫代价函数）$f : \cal{A} → \Bbb{R}$，寻找一个变量（也叫参数）$x^* \in \cal{D}$，使得对于所有$\cal{D}$中的$x，f(x^∗) ≤ f(x)$（最小化）；或者$f(x^∗) \geq f(x)$（最大化），其中$\cal{D}$为变量$x$的约束集，也叫可行域；$\cal{D}$中的变量被称为是可行解。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>概率论2-随机过程</title>
    <link href="https://buracagyang.github.io/2019/06/14/probability-theory-2/"/>
    <id>https://buracagyang.github.io/2019/06/14/probability-theory-2/</id>
    <published>2019-06-14T12:09:53.000Z</published>
    <updated>2019-06-21T05:53:35.092Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p><strong>随机过程（Stochastic Process）</strong> 是一组随机变量$X_t$的集合，其中$t$属于一个索引（index）集合$\cal{T}$。索引集合$\cal{T}$可以定义在时间域或者空间域，但一般为时间域，以实数或正数表示。当t为实数时，随机过程为连续随机过程；当t为整数时，为离散随机过程。</p><p>日常生活中的很多例子包括股票的波动、语音信号、身高的变化等都可以看作是随机过程。常见的和时间相关的随机过程模型包括<strong>伯努利过程、随机游走（Random Walk）、马尔可夫过程</strong>等。和空间相关的随机过程通常称为<strong>随机场（Random Field）</strong>。比如一张二维的图片，每个像素点（变量）通过空间的位置进行索引，这些像素就组成了一个随机过程。</p><a id="more"></a><h1 id="1-马尔可夫过程"><a href="#1-马尔可夫过程" class="headerlink" title="1. 马尔可夫过程"></a>1. 马尔可夫过程</h1><p><strong>马尔可夫性质</strong> 在随机过程中，<strong>马尔可夫性质（Markov Property）</strong>是指一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态。以离散随机过程为例，假设随机变量$X_0,X_1, … ,X_T$构成一个随机过程。这些随机变量的所有可能取值的集合被称为<strong>状态空间（State Space）</strong>。如果$X_{t+1}$对于过去状态的条件概率分布仅是$X_t$的一个函数，则<br>$$<br>P(X_{t+1} = x_{t+1}|X_{0:t} = x_{0:t}) = P(X_{t+1} = x_{t+1}|X_t = x_t) \tag{1}<br>$$<br>其中$X{0:t}$表示变量集合$X_0,X_1, … ,X_t，x_{0:t}$表示为在状态空间中的状态序列。</p><blockquote><p>马尔可夫性质也可以描述为给定当前状态时，将来的状态与过去状态是条件独立的。</p></blockquote><h2 id="1-1-马尔可夫链"><a href="#1-1-马尔可夫链" class="headerlink" title="1.1 马尔可夫链"></a>1.1 马尔可夫链</h2><p>离散时间的马尔可夫过程也称为<strong>马尔可夫链（Markov Chain）</strong>。如果一个马尔可夫链的条件概率<br>$$<br>P(X_{t+1} = s_i|X_t = s_j) = T(s_i, s_j) \tag{2}<br>$$<br>在不同时间都是不变的，即和时间$t$无关，则称为<strong>时间同质的马尔可夫链（Time-Homogeneous Markov Chains）</strong>。如果状态空间是有限的，$T(s_i, s_j)$也可以用一个矩阵$T$表示，称为<strong>状态转移矩阵（Transition Matrix）</strong>，其中元素$t_{ij}$表示状态$s_i$转移到状态$s_j$的概率。</p><p><strong>平稳分布</strong> 假设状态空间大小为$M$，向量$\pi = [\pi_1, … , 、\pi_M]^T$ 为状态空间中的一个分布，满足$0 ≤ \pi_i ≤ 1$ 和$\sum_{i=1}^{M}\pi_i =1$。</p><p>对于状态转移矩阵为$T$的时间同质的马尔可夫链，如果存在一个分布$\pi$满足<br>$$<br>\pi = T \pi \tag{3}<br>$$<br>即分布$\pi$就称为该马尔可夫链的<strong>平稳分布（Stationary Distribution）</strong>。根据特征向量的定义可知，$\pi$为矩阵$T$的（归一化）的对应特征值为1的特征向量。</p><p>如果一个马尔可夫链的状态转移矩阵T满足<strong>所有状态可遍历性</strong>以及<strong>非周期性</strong>，那么对于任意一个初始状态分布$\pi^{(0)}$，将经过一定时间的状态转移之后，都会收敛到平稳分布，即<br>$$<br>\pi = \lim_{N \to \infty}T^Nπ^{(0)} \tag{4}<br>$$</p><blockquote><p>定理1 - <strong>细致平稳条件（Detailed Balance Condition）</strong>： 如果一个马尔科夫链满足<br>$$<br>\pi_it_{ij} = \pi_jt_{ji} \tag{5}<br>$$<br>则一定会收敛到平稳分布$\pi$。</p><p>细致平稳条件保证了从状态$i$转移到状态$j$的数量和从状态$j$转移到状态$i$的数量相一致，相互抵消，所以数量不发生改变。</p><p>细致平稳条件只是马尔科夫链收敛的充分条件，不是必要条件。</p></blockquote><h1 id="2-高斯过程"><a href="#2-高斯过程" class="headerlink" title="2. 高斯过程"></a>2. 高斯过程</h1><p><strong>高斯过程（Gaussian Process）</strong>也是一种应用广泛的随机过程模型。假设有一组连续随机变量$X_0,X_1, … ,X_T$ ，如果由这组随机变量构成的任一有限集合$X_{t_1,… ,t_k} = [X_{t_1} , … ,X_{t_n}]^T$都服从一个多元正态分布，那么这组随机变量为一个随机过程。高斯过程也可以定义为：如果$X_{t_1, … ,t_n}$ 的任一线性组合都服从一元正态分布，那么这组随机变量为一个随机过程。</p><p><strong>高斯过程回归</strong> 高斯过程回归（Gaussian Process Regression）是利用高斯过程来对一个函数分布进行建模。和机器学习中参数化建模（比如贝叶斯线性回归）相比，高斯过程是一种非参数模型，可以拟合一个黑盒函数，并给出拟合结果的置信度[Rasmussen, 2004]。</p><p>假设一个未知函数$f(x)$服从高斯过程，且为平滑函数。如果两个样本$x_1, x_2$比较接近，那么对应的$f(x_1), f(x_2)$也比较接近。假设从函数$f(x)$中采样有限个样本$X = [x_1, x_2, … , x_N]$，这$N$个点服从一个多元正态分布，<br>$$<br>[f(x_1), f(x_2), … , f(x_N)]^T \sim N(\mu(X),K(X,X)) \tag{6}<br>$$<br>其中$\mu(X) = [\mu(x_1), \mu(x_2), … , \mu(x_N)]^T$是均值向量，$K(X,X) = [k(x_i, x_j )]_{N×N}$是协方差矩阵，$k(x_i, x_j)$为核函数，可以衡量两个样本的相似度。</p><p>在高斯过程回归，一个常用的核函数是平方指数（Squared Exponential）函数<br>$$<br>k(x_i, x_j) = exp(\frac{−∥x_i − x_j∥^2}{2l^2}) \tag{7}<br>$$<br>其中$l$为超参数。当$x_i$和$x_j$越接近，其核函数的值越大，表明$f(x_i)$和$f(x_j)$越相关。</p><p>假设$f(x)$的一组带噪声的观测值为${(x_n, y_n)}_{n=1}^N$，其中$y_n \sim N(f(x_n), \sigma^2)$为正态分布，$\sigma$为噪声方差。</p><p>对于一个新的样本点$x^∗$，我们希望预测函数$y^∗ = f(x^∗)$。令$y = [y_1, y_2, … , y_n]$为已有的观测值，根据高斯过程的假设，$[y; y^∗]$ 满足</p><p><img src="/2019/06/14/probability-theory-2/fig1.png" alt="fig1"></p><p>其中$K(x^*,X) = [k(x^∗, x_1), … , k(x^∗, x^n)]$。</p><p>根据上面的联合分布，$y^∗$的后验分布为<br>$$<br>p(y^∗|X, y) = N(\hat{\mu}, \hat{\sigma}^2) \tag{9}<br>$$<br>其中均值$\hat{\mu}$和方差$\hat{\sigma}$为</p><p><img src="/2019/06/14/probability-theory-2/fig2.png" alt="fig2"></p><p>从公式(10) 可以看出，均值函数$\mu(x)$可以近似地互相抵消。在实际应用中，一般假设$\mu(x) = 0$，均值$\hat{\mu}$可以将简化为<br>$$<br>\hat{\mu} = K(x^∗,X)(K(X,X) + \sigma^2 I)^{−1}y \tag{12}<br>$$<br>高斯过程回归可以认为是一种有效的贝叶斯优化方法，广泛地应用于机器学习中。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;随机过程（Stochastic Process）&lt;/strong&gt; 是一组随机变量$X_t$的集合，其中$t$属于一个索引（index）集合$\cal{T}$。索引集合$\cal{T}$可以定义在时间域或者空间域，但一般为时间域，以实数或正数表示。当t为实数时，随机过程为连续随机过程；当t为整数时，为离散随机过程。&lt;/p&gt;
&lt;p&gt;日常生活中的很多例子包括股票的波动、语音信号、身高的变化等都可以看作是随机过程。常见的和时间相关的随机过程模型包括&lt;strong&gt;伯努利过程、随机游走（Random Walk）、马尔可夫过程&lt;/strong&gt;等。和空间相关的随机过程通常称为&lt;strong&gt;随机场（Random Field）&lt;/strong&gt;。比如一张二维的图片，每个像素点（变量）通过空间的位置进行索引，这些像素就组成了一个随机过程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>概率论1-随机事件和概率</title>
    <link href="https://buracagyang.github.io/2019/06/14/probability-theory-1/"/>
    <id>https://buracagyang.github.io/2019/06/14/probability-theory-1/</id>
    <published>2019-06-14T02:15:42.000Z</published>
    <updated>2019-06-21T05:53:25.791Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>主要回顾概率论中关于样本空间、随机事件和常见概率分布的基础知识。</p><h1 id="1-样本空间"><a href="#1-样本空间" class="headerlink" title="1. 样本空间"></a>1. 样本空间</h1><p><strong>样本空间</strong> 是一个随机试验所有可能结果的集合。例如，如果抛掷一枚硬币，那么样本空间就是集合{正面，反面}。如果投掷一个骰子，那么样本空间就是{1, 2, 3, 4, 5, 6}。随机试验中的每个可能结果称为样本点。</p><p>有些试验有两个或多个可能的样本空间。例如，从52 张扑克牌中随机抽出一张，样本空间可以是数字（A到K），也可以是花色（黑桃，红桃，梅花，方块）。如果要完整地描述一张牌，就需要同时给出数字和花色，这时样本空间可以通过构建上述两个样本空间的笛卡儿乘积来得到。</p><a id="more"></a><h1 id="2-随机事件"><a href="#2-随机事件" class="headerlink" title="2. 随机事件"></a>2. 随机事件</h1><p><strong>随机事件</strong>（或简称<strong>事件</strong>） 指的是一个被赋予概率的事物集合，也就是样本空间中的一个子集。<strong>概率(Probability)</strong>表示一个随机事件发生的可能性大小，为0 到1 之间的一个非负实数。比如，一个0.5 的概率表示一个事件有50%的可能性发生。</p><p>对于一个机会均等的抛硬币动作来说，其样本空间为“正面”或“反面”。我们可以定义各个随机事件，并计算其概率。比如，</p><ul><li>{正面}，其概率为0.5；</li><li>{反面}，其概率为0.5；</li><li>空集∅，不是正面也不是反面，其概率为0；</li><li>{正面| 反面}，不是正面就是反面，其概率为1</li></ul><h1 id="3-随机变量"><a href="#3-随机变量" class="headerlink" title="3. 随机变量"></a>3. 随机变量</h1><p>在随机试验中，试验的结果可以用一个数$X$来表示，这个数$X$是随着试验结果的不同而变化的，是样本点的一个函数。我们把这种数称为<strong>随机变量（Random Variable）</strong>。例如，随机掷一个骰子，得到的点数就可以看成一个随机变量$X$，$X$的取值为{1, 2, 3, 4, 5, 6}。</p><p>如果随机掷两个骰子，整个事件空间Ω可以由36 个元素组成：<br>$$<br>Ω = \{(i, j)|i = 1, … , 6; j = 1, … , 6\} \tag{1}<br>$$<br>一个随机事件也可以定义多个随机变量。比如在掷两个骰子的随机事件中，可以定义随机变量$X$为获得的两个骰子的点数和，也可以定义随机变量$Y$为获得的两个骰子的点数差。随机变量$X$可以有11个整数值，而随机变量Y 只有6个。<br>$$<br>\begin{eqnarray}<br>X(i, j) &amp;:=&amp; i + j, x = 2, 3, … , 12 \tag{2} \\<br>Y (i, j) &amp;:=&amp; | i − j |, y = 0, 1, 2, 3, 4, 5 \tag{3}<br>\end{eqnarray}<br>$$</p><p>其中$i, j$分别为两个骰子的点数。</p><h2 id="3-1-离散随机变量"><a href="#3-1-离散随机变量" class="headerlink" title="3.1 离散随机变量"></a>3.1 离散随机变量</h2><p>如果随机变量$X$所有可能取的值为有限可列举的，有$n$个有限取值${x_1, … , x_n}$,则称$X$为离散随机变量</p><p>要了解$X$的统计规律，就必须知道它取每种可能值$x_i$的概率，即<br>$$<br>P(X = x_i) = p(x_i), \qquad ∀i \in [1, n] \tag{4}<br>$$<br>$p(x_1), … , p(x_n)$称为离散型随机变量$X$的<strong>概率分布（Probability Distribution）</strong>或<strong>分布</strong>，并且满足<br>$$<br>\begin{eqnarray}<br>\sum_{i=1}^{n}p(x_i) &amp;=&amp; 1 \\<br>p(x_i) &amp;\geq&amp; 0, \qquad \forall i \in [1, n]<br>\end{eqnarray}\tag{5}<br>$$<br>常见的离散随机变量的概率分布有：</p><p><strong>伯努利分布</strong> 在一次试验中，事件A出现的概率为$\mu$，不出现的概率为$1−\mu$。若用变量$X$表示事件A出现的次数，则$X$的取值为0和1，其相应的分布为:<br>$$<br>p(x) = μ^x(1 − μ)^{(1−x)} \tag{6}<br>$$<br>这个分布称为<strong>伯努利分布（Bernoulli Distribution）</strong>,又名两点分布或者<strong>0-1分布</strong>。</p><p><strong>二项分布</strong> 在n次伯努利分布中，若以变量$X$表示事件A出现的次数，则$X$的取值为{0, · · · , n}，其相应的分布为<strong>二项分布（Binomial Distribution）</strong>。<br>$$<br>P(X = k) = \tbinom{n}{k}μ^k(1 − μ)^{n−k}, \quad k = 1, … , n \tag{7}<br>$$<br>其中$\tbinom{n}{k}$为二项式系数（这就是二项分布的名称的由来），表示从$n$个元素中取出$k$个元素而不考虑其顺序的<strong>组合</strong>的总数。</p><h2 id="3-2-连续随机变量"><a href="#3-2-连续随机变量" class="headerlink" title="3.2 连续随机变量"></a>3.2 连续随机变量</h2><p>与离散随机变量不同，一些随机变量$X$的取值是不可列举的，由全部实数或者由一部分区间组成，比如<br>$$<br>X = \{x|a ≤ x ≤ b\}, -\infty &lt; a &lt; b &lt; \infty \tag{8}<br>$$<br>则称$X$为<strong>连续随机变量</strong>。连续随机变量的值是不可数及无穷尽的。</p><p>对于连续随机变量$X$，它取一个具体值$x_i$的概率为0，这个离散随机变量截然不同。因此用列举连续随机变量取某个值的概率来描述这种随机变量不但做不到，也毫无意义。</p><p>连续随机变量$X$的概率分布一般用<strong>概率密度函数（Probability Density Function，PDF）</strong> p(x)来描述。p(x)为可积函数，并满足<br>$$<br>\begin{eqnarray}<br>\int_{-\infty}^{\infty} p(x)dx &amp;=&amp; 1 \\<br>p(x) &amp;≥&amp; 0<br>\end{eqnarray} \tag{9}<br>$$<br>给定概率密度函数p(x)，便可以计算出随机变量落入某一个区间的概率，而p(x)本身反映了随机变量取落入x的非常小的邻近区间中的概率大小。常见的连续随机变量的概率分布有：</p><p><strong>均匀分布</strong> 若a, b为有限数，[a, b]上的<strong>均匀分布（Uniform Distribution）</strong>的概率密度函数定义为<br>$$<br>p(x) = \begin{cases}<br>\frac{1}{b-a} &amp; a\leq x \leq b \\<br>0 &amp; x&gt;b或x&lt;a<br>\end{cases} \tag{10}<br>$$</p><p><strong>正态分布</strong> 正态分布（Normal Distribution），又名<strong>高斯分布（Gaussian Distribution）</strong>，是自然界最常见的一种分布，并且具有很多良好的性质，在很多领域都有非常重要的影响力，其概率密度函数为<br>$$<br>p(x) = \frac{1}{\sqrt{2\pi}\sigma}exp(− \frac{(x − μ)^2}{2\sigma^2}) \tag{11}<br>$$<br>其中$\sigma &gt; 0$，$\mu$和$\sigma$均为常数。若随机变量$X$服从一个参数为$\mu$和$\sigma$的概率分布，简记为<br>$$<br>X \sim \cal N(\mu, \sigma^2) \tag{12}<br>$$<br>当$\mu = 0，\sigma = 1$时，称为<strong>标准正态分布（Standard Normal Distribution）</strong>。</p><h2 id="3-3-累积分布函数"><a href="#3-3-累积分布函数" class="headerlink" title="3.3 累积分布函数"></a>3.3 累积分布函数</h2><p>对于一个随机变量$X$，其<strong>累积分布函数（Cumulative Distribution Function，CDF）</strong>是随机变量$X$的取值小于等于$x$的概率。<br>$$<br>cdf(x) = P(X \leq x) \tag{13}<br>$$<br>以连续随机变量$X$为例，累积分布函数定义为<br>$$<br>cdf(x) =\int_{-\infty}^{x}p(t)dt \tag{14}<br>$$<br>其中p(x)为概率密度函数。下图给出了标准正态分布的累计分布函数和概率密度函数。</p><p><img src="/2019/06/14/probability-theory-1/pdf-cdf.png" alt="pdf-cdf"></p><h1 id="4-随机向量"><a href="#4-随机向量" class="headerlink" title="4. 随机向量"></a>4. 随机向量</h1><p><strong>随机向量</strong> 是指一组随机变量构成的向量。如果$X_1,X_2, … ,X_n$ 为$n$个随机变量, 那么称$[X_1,X_2, … ,X_n]$为一个$n$维随机向量。一维随机向量称为随机变量。随机向量也分为<strong>离散随机向量</strong>和<strong>连续随机向量</strong>。</p><h2 id="4-1离散随机向量"><a href="#4-1离散随机向量" class="headerlink" title="4.1离散随机向量"></a>4.1离散随机向量</h2><p>离散随机向量的<strong>联合概率分布（Joint Probability Distribution）</strong>为<br>$$<br>P(X_1 = x_1,X_2 = x_2, … ,X_n = x_n) = p(x_1, x_2, … , x_n) \tag{15}<br>$$<br>其中$x_i \in \omega_i$为变量$X_i$的取值，$\omega_i$为变量$X_i$的样本空间。和离散随机变量类似，离散随机向量的概率分布满足<br>$$<br>\begin{eqnarray}<br>&amp;p(x_1, x_2, … , x_n) \geq 0, \quad ∀x_1 \in \omega_1, x_2 \in \omega_2, … , x_n \in \omega_n \tag{16} \\<br>&amp;\sum_{x_1 \in \omega_1}\sum_{x_2 \in \omega_2}…\sum_{x_n \in \omega_n}p(x_1, x_2, … , x_n) = 1 \tag{17}<br>\end{eqnarray}<br>$$<br><strong>多项分布</strong> 一个常见的离散向量概率分布为<strong>多项分布（Multinomial Distribution）</strong>。多项分布是二项分布在随机向量的推广。假设一个袋子中装了很多球，总共有$K$个不同的颜色。我们从袋子中取出$n$个球。每次取出一个时，就在袋子中放入一个同样颜色的球（或者说有放回的抽样）。这样保证同一颜色的球在不同试验中被取出的概率是相等的。令$X$为一个$K$维随机向量，每个元素$X_k(k = 1, … ,K)$为取出的$n$个球中颜色为$k$的球的数量，则$X$服从多项分布，其概率分布为<br>$$<br>p(x_1, … , x_K|\mu) = \frac{n!}{x_1! … x_K!}μ_1^{x_1} … μ_K^{x_K} \tag{18}<br>$$<br>其中$\mu = [\mu_1, … , \mu_K]^T$分别为每次抽取的球的颜色为1, … ,K的概率；$x_1, … , x_K$为非负整数，并且满足$\sum_{k=1}^{K}x_k = n$。</p><p>多项分布的概率分布也可以用gamma函数表示：<br>$$<br>p(x_1, … , x_K|\mu) = \frac{\Gamma(\sum_k x_k+1)}{\prod_k \Gamma(x_k+1)}\prod_{k=1}^{K}\mu_k^{x_k} \tag{19}<br>$$<br>其中$\Gamma(z) = \int_{0}^{\infty}\frac{t^{z−1}}{exp(t)}dt$为gamma函数。这种表示形式和狄利克雷分布(  Dirichlet Distribution)类似，而狄利克雷分布可以作为多项分布的共轭先验。</p><h2 id="4-2-连续随机向量"><a href="#4-2-连续随机向量" class="headerlink" title="4.2 连续随机向量"></a>4.2 连续随机向量</h2><p>连续随机向量的其<strong>联合概率密度函数（Joint Probability Density Function）</strong>满足<br>$$<br>\begin{eqnarray}<br>p(x) = p(x_1, … , x_n) ≥ 0 \tag{20} \\<br>\int_{-\infty}^{+\infty} … \int_{-\infty}^{+\infty}p(x_1, … , x_n)dx_1 … dx_n = 1 \tag{21}<br>\end{eqnarray}<br>$$<br><strong>多元正态分布</strong> 一个常见的连续随机向量分布为<strong>多元正态分布（Multivariate Normal</strong><br><strong>Distribution）</strong>，也称为<strong>多元高斯分布（Multivariate Gaussian Distribution）</strong>。若$n$维随机向量$X = [X_1, … ,X_n]^T$服从$n$元正态分布，其密度函数为<br>$$<br>p(x) = \frac{1}{(2π)^{n/2}|\sum|^{1/2}} exp(-\frac{1}{2}(x−\mu)^T\sum^{−1}(x−\mu)) \tag{22}<br>$$<br>其中$\mu$为多元正态分布的均值向量，$\sum$为多元正态分布的协方差矩阵，$|\sum|$表示$\sum$的行列式。</p><p><strong>各项同性高斯分布</strong> 如果一个多元高斯分布的协方差矩阵简化为$\sum = \sigma^2I$，即每一个维随机变量都独立并且方差相同，那么这个多元高斯分布称为<strong>各项同性高斯分布（Isotropic Gaussian Distribution）</strong>。</p><p><strong>Dirichlet 分布</strong> 一个$n$维随机向量$X$的Dirichlet 分布为<br>$$<br>p(x|\alpha) = \frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1) … \Gamma(\alpha_n)} \prod_{i=1}^{n}x_i^{\alpha_i - 1} \tag{23}<br>$$</p><p>其中$\alpha = [\alpha_1, … , \alpha_K]^T$为Dirichlet分布的参数。</p><h1 id="5-边际分布"><a href="#5-边际分布" class="headerlink" title="5. 边际分布"></a>5. 边际分布</h1><p>对于二维离散随机向量$(X, Y)$，假设$X$取值空间为$\Omega_x$，$Y$取值空间为$\Omega_y$。其联合概率分布满足<br>$$<br>p(x, y) \geq 0,\sum_{x\in \Omega_x}\sum_{y \in \Omega_y}p(x_i, y_j) = 1 \tag{24}<br>$$<br>对于联合概率分布p(x, y)，我们可以分别对x和y进行求和。</p><p>(1) 对于固定的x，<br>$$<br>\sum_{y\in \Omega_y}p(x, y) = P(X = x) = p(x) \tag{25}<br>$$<br>(2) 对于固定的y，<br>$$<br>\sum_{x \in \Omega_x}p(x, y) = P(Y = y) = p(y) \tag{26}<br>$$<br>由离散随机向量$(X, Y)$的联合概率分布，对$Y$的所有取值进行求和得到$X$的概率分布；而对$X$的所有取值进行求和得到$Y$的概率分布。这里p(x)和p(y)就称为p(x, y)的<strong>边际分布（Marginal Distribution）</strong>。</p><p>对于二维连续随机向量(X, Y)，其边际分布为：<br>$$<br>\begin{eqnarray}<br>p(x) = \int_{-\infty}^{+\infty}p(x, y)dy \tag{27} \\<br>p(y) = \int_{-\infty}^{+\infty}p(x, y)dx \tag{28}<br>\end{eqnarray}<br>$$<br>一个二元正态分布的边际分布仍为正态分布。</p><h1 id="6-条件概率分布"><a href="#6-条件概率分布" class="headerlink" title="6. 条件概率分布"></a>6. 条件概率分布</h1><p>对于离散随机向量$(X, Y)$，已知$X = x$的条件下，随机变量$Y = y$的<strong>条件概率（Conditional Probability）</strong>为：<br>$$<br>p(y|x) = P(Y = y|X = x) = \frac{p(x, y)}{p(x)} \tag{29}<br>$$<br>这个公式定义了随机变量$Y$关于随机变量X的条件概率分布（Conditional Probability Distribution），简称条件分布。</p><p>对于二维连续随机向量$(X, Y)$，已知$X = x$的条件下，随机变量$Y = y$的<strong>条件概率密度函数（Conditional Probability Density Function）</strong>为<br>$$<br>p(y|x) = \frac{p(x, y)}{p(x)} \tag{30}<br>$$<br>同理，已知$Y = y$的条件下，随机变量$X = x$的条件概率密度函数为<br>$$<br>p(x|y) = \frac{p(x, y)}{p(y)} \tag{31}<br>$$</p><p>通过公式(30) 和(31)，我们可以得到两个条件概率p(y|x) 和p(x|y) 之间的关系。<br>$$<br>p(y|x) = \frac{p(x|y)p(y)}{p(x)} \tag{32}<br>$$<br>这个公式称为<strong>贝叶斯定理（Bayes’ Theorem）</strong>，或贝叶斯公式。</p><h1 id="7-独立与条件独立"><a href="#7-独立与条件独立" class="headerlink" title="7. 独立与条件独立"></a>7. 独立与条件独立</h1><p>对于两个离散（或连续）随机变量$X$和$Y$，如果其联合概率（或联合概率密度函数）p(x, y) 满足<br>$$<br>p(x, y) = p(x)p(y) \tag{33}<br>$$<br>则称X 和Y相互<strong>独立（independence）</strong>，记为$X \perp !!! \perp Y$。</p><p>对于三个离散（或连续）随机变量X、Y 和Z，如果条件概率（或联合概率密度函数）p(x, y|z) 满足<br>$$<br>p(x, y|z) = P(X = x, Y = y|Z = z) = p(x|z)p(y|z) \tag{34}<br>$$</p><p>则称在给定变量$Z$时，$X$和$Y$<strong>条件独立（conditional independence）</strong>，记为$X \perp !!! \perp Y|Z$。</p><h1 id="8-期望和方差"><a href="#8-期望和方差" class="headerlink" title="8. 期望和方差"></a>8. 期望和方差</h1><p><strong>期望</strong> 对于离散变量$X$，其概率分布为$p(x_1), … , p(x_n)$，$X$的期望（Expectation）或均值定义为<br>$$<br>\Bbb{E}[X] = \sum_{i=1}^{n}x_ip(x_i) \tag{35}<br>$$<br>对于连续随机变量$X$，概率密度函数为$p(x)$，其期望定义为<br>$$<br>\Bbb{E}[X] = \int_{\Bbb{R}}xp(x) dx \tag{36}<br>$$<br><strong>方差</strong> 随机变量$X$的方差（Variance）用来定义它的概率分布的离散程度，定义为<br>$$<br>var(X) = \Bbb{E}[X − \Bbb{E}(X)]^2 \tag{37}<br>$$<br>随机变量$X$的方差也称为它的二阶矩。$\sqrt{var(X)}$则称为$X$的根方差或标准差。</p><p><strong>协方差</strong> 两个连续随机变量X和Y的<strong>协方差（Covariance）</strong>用来衡量两个随机变量的分布之间的总体变化性，定义为<br>$$<br>cov(X, Y) = \Bbb{E}[(X − \Bbb(X))((Y − \Bbb{E}(Y))] \tag{38}<br>$$<br>协方差经常也用来衡量两个随机变量之间的线性相关性。如果两个随机变量的协方差为0，那么称这两个随机变量是<strong>线性不相关</strong>。两个随机变量之间没有这里的线性相关性，并非表示它们之间独立的，可能存在某种非线性的函数关系。反之，如果X 与Y是统计独立的，那么它们之间的协方差一定为0。</p><p><strong>协方差矩阵</strong> 两个m和n维的连续随机向量X和Y，它们的协方差（Covariance）为m × n的矩阵，定义为<br>$$<br>cov(X,Y) = \Bbb{E}[(X − \Bbb{E}(X))(Y − \Bbb{E}(Y))^T] \tag{39}<br>$$<br>协方差矩阵$cov(X,Y)$的第$(i, j)$个元素等于随机变量$X_i$和$Y_j$的协方差。两个向量变量的协方差$cov(X,Y)$与$cov(Y,X)$互为转置关系。如果两个随机向量的协方差矩阵为对角阵，那么称这两个随机向量是无关的。</p><p>单个随机向量X的协方差矩阵定义为<br>$$<br>cov(X) = cov(X,X) \tag{40}<br>$$</p><h2 id="8-1-Jensen不等式"><a href="#8-1-Jensen不等式" class="headerlink" title="8.1 Jensen不等式"></a>8.1 Jensen不等式</h2><p>如果$X$是随机变量，$g$是凸函数，则<br>$$<br>g(\Bbb{E}[X]) \leq \Bbb{E}[g(X)] \tag{41}<br>$$</p><p>等式当且仅当$X$是一个常数或$g$是线性时成立。</p><h2 id="8-2-大数定律和中心极限定理"><a href="#8-2-大数定律和中心极限定理" class="headerlink" title="8.2 大数定律和中心极限定理"></a>8.2 大数定律和中心极限定理</h2><p><strong>大数定律（Law Of Large Numbers）</strong> 是指$n$个样本$X_1, … ,X_n$是独立同分布的，即$E[X_1] = … = E[X_n] = \mu$，那么其均值收敛于期望值$\mu$<br>$$<br>\lim_{n \to \infty} \bar{X}_n = \lim_{n\to \infty} \frac{1}{n}(X_1 + … + X_n) \to \mu \tag{42}<br>$$<br><strong>中心极限定理(Central Limit Theorem)</strong> 是指$n$个样本$X_1, … ,X_n$是独立同分布的，则对任意x，分布函数<br>$$<br>F_n(x) = P(\frac{\sum_{i=1}^{n}X_i - n\mu}{\sigma \sqrt{n}} \leq x)<br>$$<br>满足：</p><p>$\lim_{n \to \infty}  F_n(x)$ 近似服从标准正态分布 $\cal{N}(0, 1)$。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;主要回顾概率论中关于样本空间、随机事件和常见概率分布的基础知识。&lt;/p&gt;
&lt;h1 id=&quot;1-样本空间&quot;&gt;&lt;a href=&quot;#1-样本空间&quot; class=&quot;headerlink&quot; title=&quot;1. 样本空间&quot;&gt;&lt;/a&gt;1. 样本空间&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;样本空间&lt;/strong&gt; 是一个随机试验所有可能结果的集合。例如，如果抛掷一枚硬币，那么样本空间就是集合{正面，反面}。如果投掷一个骰子，那么样本空间就是{1, 2, 3, 4, 5, 6}。随机试验中的每个可能结果称为样本点。&lt;/p&gt;
&lt;p&gt;有些试验有两个或多个可能的样本空间。例如，从52 张扑克牌中随机抽出一张，样本空间可以是数字（A到K），也可以是花色（黑桃，红桃，梅花，方块）。如果要完整地描述一张牌，就需要同时给出数字和花色，这时样本空间可以通过构建上述两个样本空间的笛卡儿乘积来得到。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>微积分2-常见函数的导数</title>
    <link href="https://buracagyang.github.io/2019/06/12/calculus-2/"/>
    <id>https://buracagyang.github.io/2019/06/12/calculus-2/</id>
    <published>2019-06-12T12:44:46.000Z</published>
    <updated>2019-07-28T08:55:50.444Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>在微积分1中已经附上了一个常见函数形式的导数，下文主要是关于向量函数及其导数，以及在机器学习和神经网络中常见的Logistic函数、Softmax函数的导数形式。</p><a id="more"></a><h1 id="1-向量函数及其导数"><a href="#1-向量函数及其导数" class="headerlink" title="1. 向量函数及其导数"></a>1. 向量函数及其导数</h1><p>$$<br>\begin{eqnarray}<br>\frac{\partial x}{\partial x} &amp;=&amp; I \tag{1.1} \\<br>\frac{\partial Ax}{\partial x} &amp;=&amp; A^T \tag{1.2} \\<br>\frac{\partial x^TA}{\partial x} &amp;=&amp; A \tag{1.3}<br>\end{eqnarray}<br>$$</p><h1 id="2-按位计算的向量函数及其导数"><a href="#2-按位计算的向量函数及其导数" class="headerlink" title="2. 按位计算的向量函数及其导数"></a>2. 按位计算的向量函数及其导数</h1><p>假设一个函数$f(x)$的输入是标量$x$。对于一组$K$个标量$x_1, … , x_K$，我们可以通过$f(x)$得到另外一组$K$个标量$z_1, … , z_K$，<br>$$<br>z_k = f(x_k), ∀k = 1, … ,K \tag{1.4}<br>$$<br>为了简便起见，我们定义$x = [x_1, … , x_K]^T，z = [z_1, … , z_K]^T$，<br>$$<br>z = f(x) \tag{1.5}<br>$$<br>其中$f(x)$是按位运算的，即$[f(x)]_i = f(x_i)$。</p><p>当$x$为标量时，$f(x)$的导数记为$f′(x)$。当输入为$K$维向量$x = [x_1, … , x_K]^T$时，其导数为一个对角矩阵。<br>$$<br>\begin{eqnarray}<br>\frac{\partial f(x)}{\partial x} &amp;=&amp; [\frac{\partial f(x_j)}{\partial x_i}]_{K \times K} \ <br>&amp;=&amp; \begin {bmatrix}<br>&amp;f’(x_1)&amp; \quad &amp;0&amp; \quad &amp;…&amp; \quad &amp;0&amp; \\<br>&amp;0&amp; \quad &amp;f’(x_2)&amp; \quad &amp;…&amp; \quad &amp;0&amp; \\<br>&amp;\vdots&amp; \quad &amp;\vdots&amp; \quad &amp;\vdots&amp; \quad &amp;\vdots&amp; \quad \\<br>&amp;0&amp; \quad &amp;0&amp; \quad &amp;…&amp; \quad &amp;f’(x_K)&amp; \\<br>\end {bmatrix} \\<br>&amp;=&amp; diag(f’(x))<br>\end{eqnarray}  \tag{1.6}<br>$$</p><h1 id="3-Logistic函数的导数"><a href="#3-Logistic函数的导数" class="headerlink" title="3. Logistic函数的导数"></a>3. Logistic函数的导数</h1><p>关于logistic函数其实在博文<a href="https://buracagyang.github.io/2019/05/29/logistic-loss-function/">‘Logistic loss函数’</a>中已经有所介绍，接下来要说是更广义的logistic函数的定义：<br>$$<br>logistic(x) = \frac{L}{1 + exp(−k(x − x_0))} \tag{1.7}<br>$$<br>其中，$x_0$是中心点，$L$是最大值，$k$是曲线的倾斜度。下图给出了几种不同参数的Logistic函数曲线。当$x$趋向于$−\infty$时，logistic(x)接近于0；当$x$趋向于$+\infty$时，logistic(x) 接近于$L$。</p><p><img src="/2019/06/12/calculus-2/logistic.png" alt="logistic"></p><p>当参数为($k = 1,  x_0 = 0, L = 1$) 时，Logistic 函数称为标准Logistic 函数，记为f(x)。<br>$$<br>f(x) = \frac{1}{1 + exp(−x)} \tag{1.8}<br>$$<br>标准logistic函数有两个重要的性质如下：<br>$$<br>\begin{eqnarray}<br>f(x) &amp;=&amp; 1 - f(x) \tag{1.9} \\<br>f’(x) &amp;=&amp; f(x)(1 - f(x)) \tag{1.10}<br>\end{eqnarray}<br>$$<br>当输入为$K$维向量$x=[x_1, …, x_K]^T$时，其导数为：<br>$$<br>f’(x) = diag(f(x) \odot (1 − f(x))) \tag{1.11}<br>$$</p><h1 id="4-Softmax函数的导数"><a href="#4-Softmax函数的导数" class="headerlink" title="4. Softmax函数的导数"></a>4. Softmax函数的导数</h1><p>Softmax函数是将多个标量映射为一个概率分布。对于$K$个标量$x_1, … , x_K$，softmax 函数定义为<br>$$<br>z_k = softmax(x_k) = \frac{exp(x_k)}{\sum_{i=1}^{K}exp(x_i)} \tag{1.12}<br>$$<br>这样，我们可以将$K$个变量$x_1, … , x_K$转换为一个分布：$z_1, … , z_K$，满足<br>$$<br>z_k \in [0, 1], ∀k, \quad  \sum_{k=1}^{K}z_k = 1 \tag{1.13}<br>$$<br>当Softmax函数的输入为$K$维向量$x$时，<br>$$<br>\begin{eqnarray}<br>\hat{z} &amp;=&amp; softmax(x) \\<br>&amp;=&amp; \frac{1}{\sum_{k=1}^{K}exp(x_k)}\begin{bmatrix}<br>exp(x_1) \\<br>\vdots \\<br>exp(x_K) \\<br>\end{bmatrix} \\<br>&amp;=&amp; \frac{exp(x)}{\sum_{k=1}^{K}exp(x)} \ <br>&amp;=&amp; \frac{exp(x)}{1_K^Texp(x)} \\<br>\end{eqnarray} \tag{1.14}<br>$$<br>其中$1_K = [1, … , 1]_{K×1}$是$K$维的全1向量。</p><p>Softmax函数的导数为<br>$$<br>\begin{eqnarray}<br>\frac{\partial softmax(x)}{\partial x} &amp;=&amp; \frac{\partial(\frac{exp(x)}{1_K^Texp(x)})}{\partial x} \tag{1.15} \\<br>&amp;=&amp; \frac{1}{1_K^Texp(x)}\frac{\partial exp(x)}{\partial(x)} + \frac{\partial(\frac{1}{1_K^Texp(x)})}{\partial x}(exp(x))^T \tag{1.16} \\<br>&amp;=&amp; \frac{diag(exp(x))}{1_K^Texp(x)} - (\frac{1}{(1_K^Texp(x))^2})\frac{\partial(1_K^Texp(x))}{\partial x}(exp(x))^T \tag{1.17} \\<br>&amp;=&amp; \frac{diag(exp(x))}{1_K^Texp(x)} - (\frac{1}{(1_K^Texp(x))^2})diag(exp(x))1_K(exp(x))^T \tag{1.18} \\<br>&amp;=&amp; \frac{diag(exp(x))}{1_K^Texp(x)} - (\frac{1}{(1_K^Texp(x))^2})exp(x)(exp(x))^T \tag{1.19} \\<br>&amp;=&amp; diag(\frac{exp(x)}{1_K^Texp(x)}) - \frac{exp(x)}{1_K^Texp(x)}.\frac{(exp(x))^T}{1_K^Texp(x)} \tag{1.20} \\<br>&amp;=&amp; diag(softmax(x)) - softmax(x).softmax(x)^T \tag{1.21}<br>\end{eqnarray}<br>$$<br>其中式(1.16)请参考 <a href="https://buracagyang.github.io/2019/06/12/calculus-1/">‘微积分1-导数’</a> 式(1.13)。</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在微积分1中已经附上了一个常见函数形式的导数，下文主要是关于向量函数及其导数，以及在机器学习和神经网络中常见的Logistic函数、Softmax函数的导数形式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>微积分1-导数</title>
    <link href="https://buracagyang.github.io/2019/06/12/calculus-1/"/>
    <id>https://buracagyang.github.io/2019/06/12/calculus-1/</id>
    <published>2019-06-12T09:23:57.000Z</published>
    <updated>2019-07-28T08:55:43.551Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>微积分1，主要回顾关于微积分中关于导数的相关知识。错误之处，还望诸君不吝指教。</p><a id="more"></a><h1 id="1-导数基础"><a href="#1-导数基础" class="headerlink" title="1. 导数基础"></a>1. 导数基础</h1><p><strong>导数（Derivative）</strong> 是微积分学中重要的基础概念。<br>对于定义域和值域都是实数域的函数$f : \mathbb{R} \to \mathbb{R}$，若$f(x)$在点$x_0$的某个邻域$\triangle x$内，极限定义如下<br>$$<br>f’(x_0) = \lim_{\triangle x \to 0} \frac{f(x_0 + \triangle x) − f(x_0)}{\triangle x} \tag{1.1}<br>$$<br>若极限存在，则称函数$f(x)$在点$x_0$处可导，$f′(x_0)$称为其导数，或导函数，也可以记为$\frac{df(x_0)}{dx}$。在几何上，导数可以看做函数曲线上的切线斜率。</p><p>给定一个连续函数，计算其导数的过程称为微分（Differentiation）。微分的逆过程为积分（Integration）。函数$f(x)$的积分可以写为<br>$$<br>F(x) = \int f(x)dx \tag{1.2}<br>$$<br>其中$F(x)$称为$f(x)$的原函数。</p><p>若函数$f(x)$在其定义域包含的某区间内每一个点都可导，那么也可以说函数$f(x)$在这个区间内可导。如果一个函数$f(x)$在定义域中的所有点都存在导数，则$f(x)$为可微函数（Differentiable Function）。<strong>可微函数一定连续，但连续函数不一定可微</strong>。例如函数$|x|$为连续函数，但在点x = 0处不可导。下表是几个常见函数的导数：</p><table><thead><tr><th style="text-align:center">函数</th><th style="text-align:center">函数形式</th><th style="text-align:center">导数</th></tr></thead><tbody><tr><td style="text-align:center">常数函数</td><td style="text-align:center">$f(x) = C$，其中C为常数</td><td style="text-align:center">$f’(x) = 0$</td></tr><tr><td style="text-align:center">幂函数</td><td style="text-align:center">$f(x) = x^r$， 其中r是非零实数</td><td style="text-align:center">$f’(x) = rx^{r-1}$</td></tr><tr><td style="text-align:center">指数函数</td><td style="text-align:center">$f(x) = exp(x)$</td><td style="text-align:center">$f’(x) = exp(x)$</td></tr><tr><td style="text-align:center">对数函数</td><td style="text-align:center">$f(x) = log_ax$</td><td style="text-align:center">$f’(x) = \frac{1}{xlna}$</td></tr></tbody></table><p><strong>高阶导数</strong> 对一个函数的导数继续求导，可以得到高阶导数。函数$f(x)$的导数$f′(x)$称为一阶导数，$f′(x)$的导数称为二阶导数，记为$f′′(x)$或$\frac{d^2f(x)}{dx^2}$。</p><p><strong>偏导数</strong> 对于一个多元变量函数$f : \mathbb{R}^d \to \mathbb{R}$，它的偏导数（Partial Derivative ）是关于其中一个变量$x_i$的导数，而保持其他变量固定，可以记为$f’_{x_i} (x)，\bigtriangledown_{x_i}f(x)，\frac{∂f(x)}{∂x_i}或\frac{∂}{∂x_i}f(x)$。</p><h1 id="2-矩阵微积分"><a href="#2-矩阵微积分" class="headerlink" title="2. 矩阵微积分"></a>2. 矩阵微积分</h1><p>为了书写简便，我们通常把<strong>单个函数对多个变量</strong> 或者 <strong>多元函数对单个变量</strong>的偏导数写成向量和矩阵的形式，使其可以被当成一个整体被处理。<strong>矩阵微积分（Matrix Calculus）</strong>是多元微积分的一种表达方式，即使用矩阵和向量来表示因变量每个成分关于自变量每个成分的偏导数。</p><p>矩阵微积分的表示通常有两种符号约定：<strong>分子布局（Numerator Layout）</strong>和<strong>分母布局（Denominator Layout）</strong>。两者的区别是一个标量关于一个向量的导数是写成列向量还是行向量。</p><h2 id="2-1-标量关于向量的偏导数"><a href="#2-1-标量关于向量的偏导数" class="headerlink" title="2.1 标量关于向量的偏导数"></a>2.1 标量关于向量的偏导数</h2><p>对于一个$d$维向量$x \in \mathbb{R}^p$，函数$y = f(x) = f(x_1, … , x_p) \in \mathbb{R}$，则$y$关于$x$的偏导数为</p><p>分母布局 :<br>$$<br>\frac{\partial y}{\partial x} = [\frac{\partial y}{\partial x_1}, …, \frac{\partial y}{\partial x_p}]^T \qquad \in \mathbb{R}^{p \times 1} \tag{1.3}<br>$$<br>分子布局：<br>$$<br>\frac{\partial y}{\partial x} = [\frac{\partial y}{\partial x_1}, …, \frac{\partial y}{\partial x_p}] \qquad \in \mathbb{R}^{1 \times p} \tag{1.4}<br>$$<br>在分母布局中，$\frac{∂y}{∂x}$为列向量，而在分子布局中， $\frac{∂y}{∂x}$为行向量。下文如无特殊说明，均采用分母布局。</p><h2 id="2-2-向量关于标量的偏导数"><a href="#2-2-向量关于标量的偏导数" class="headerlink" title="2.2 向量关于标量的偏导数"></a>2.2 向量关于标量的偏导数</h2><p>对于一个标量$x \in \mathbb{R}$，函数$y = f(x) \in \mathbb{R}^q，则$y$关于$x$的偏导数为</p><p>分母布局：<br>$$<br>\frac{\partial y}{\partial x} = [\frac{\partial y_1}{\partial x}, …, \frac{\partial y_q}{\partial x}] \qquad \in \mathbb{R}^{1 \times q} \tag{1.5}<br>$$<br>分子布局：<br>$$<br>\frac{\partial y}{\partial x} = [\frac{\partial y_1}{\partial x}, …, \frac{\partial y_q}{\partial x}]^T \qquad \in \mathbb{R}^{q \times 1} \tag{1.6}<br>$$</p><p>在分母布局中，$\frac{∂y}{∂x}$为行向量，而在分子布局中， $\frac{∂y}{∂x}$为列向量。</p><h2 id="2-3-向量关于向量的偏导数"><a href="#2-3-向量关于向量的偏导数" class="headerlink" title="2.3 向量关于向量的偏导数"></a>2.3 向量关于向量的偏导数</h2><p>对于一个$d$维向量$x \in \mathbb{R}^p$，函数$y = f(x) \in \mathbb{R}^q$ 的值也为一个向量，则$f(x)$关于$x$的偏导数（分母布局）为<br>$$<br>\frac{\partial f(x)}{\partial x} =<br>\begin {bmatrix}<br>&amp;\frac{\partial y_1}{\partial x_1}&amp; &amp;…&amp; &amp;\frac{\partial y_q}{\partial x_1}&amp; \\<br>&amp;\vdots&amp; &amp;\vdots&amp; &amp;\vdots&amp; \\<br>&amp;\frac{\partial y_1}{\partial x_p}&amp; &amp;…&amp; &amp;\frac{\partial y_q}{\partial x_p}&amp; \\<br>\end {bmatrix} \in \mathbb{R}^{p \times q} \tag{1.7}<br>$$<br>称之为<strong>雅克比矩阵（Jacobian Matrix）</strong>。</p><h1 id="3-导数法则"><a href="#3-导数法则" class="headerlink" title="3. 导数法则"></a>3. 导数法则</h1><p>复合函数的导数的计算可以通过以下法则来简化。</p><h2 id="3-1-加-减-法则"><a href="#3-1-加-减-法则" class="headerlink" title="3.1 加(减)法则"></a>3.1 加(减)法则</h2><p>若$x \in \mathbb{R}^p，y = f(x) \in \mathbb{R}^q，z = g(x) \in \mathbb{R}^q$，则<br>$$<br>\frac{\partial(y+z)}{\partial x} = \frac{\partial y}{\partial x} + \frac{\partial z}{\partial x} \in \mathbb{R}^{p×q} \tag{1.8}<br>$$</p><h2 id="3-2-乘法法则"><a href="#3-2-乘法法则" class="headerlink" title="3.2 乘法法则"></a>3.2 乘法法则</h2><p>(1) 若$x \in \mathbb{R}^p，y = f(x) \in \mathbb{R}^q，z = g(x) \in \mathbb{R}^q$，则<br>$$<br>\frac{∂y^Tz}{∂x} = \frac{∂y}{∂x}z + \frac{∂z}{∂x}y \in \mathbb{R}^p \tag{1.9}<br>$$</p><p>(2) 若$x \in \mathbb{R}^p，y = f(x) \in \mathbb{R}^s，z = g(x) \in \mathbb{R}^t，A \in \mathbb{R}^{s×t}$ 和 $x$ 无关，则<br>$$<br>\frac{∂y^TAz}{∂x} = \frac{∂y}{∂x}Az + \frac{∂z}{∂x}A^Ty \in \mathbb{R}^p \tag{1.10}<br>$$<br>(3) 若$x \in \mathbb{R}^p，y = f(x) \in \mathbb{R}，z = g(x) \in \mathbb{R}^q$，则<br>$$<br>\frac{∂yz}{∂x} = y\frac{∂z}{∂x} + \frac{∂y}{∂x}z^T \in \mathbb{R}^{p×q} \tag{1.11}<br>$$</p><h2 id="3-3-链式法则"><a href="#3-3-链式法则" class="headerlink" title="3.3 链式法则"></a>3.3 链式法则</h2><p><strong>链式法则（Chain Rule）</strong>是在微积分中求复合函数导数的一种常用方法。</p><p>(1) 若$x \in \mathbb{R}，u = u(x) \in \mathbb{R}^s，g = g(u) \in \mathbb{R}^t$，则<br>$$<br>\frac{∂g}{∂x} = \frac{∂u}{∂x}\frac{∂g}{∂u} \in \mathbb{R}^{1×t} \tag{1.12}<br>$$</p><p>(2) 若$x \in \mathbb{R}^p，y = g(x) \in \mathbb{R}^s，z = f(y) \in \mathbb{R}^t$，则<br>$$<br>\frac{∂z}{∂x} = \frac{∂y}{∂x}\frac{∂z}{∂y} \in \mathbb{R}^{p×t} \tag{1.13}<br>$$</p><p>(3) 若$X \in \mathbb{R}^{p×q}$为矩阵，$y = g(X) \in \mathbb{R}^s，z = f(y) \in \mathbb{R}$，则<br>$$<br>\frac{∂z}{∂X_{ij}} = \frac{∂y}{∂X_{ij}}\frac{∂z}{∂y} \in \mathbb{R} \tag{1.14}<br>$$<br>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;微积分1，主要回顾关于微积分中关于导数的相关知识。错误之处，还望诸君不吝指教。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>线性代数2-矩阵</title>
    <link href="https://buracagyang.github.io/2019/06/12/linear-algebra-2/"/>
    <id>https://buracagyang.github.io/2019/06/12/linear-algebra-2/</id>
    <published>2019-06-12T06:47:09.000Z</published>
    <updated>2019-12-20T06:20:55.980Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>线性代数2，主要回顾关于矩阵的相关知识。错误之处，还望诸君不吝指教。</p><a id="more"></a><h1 id="1-线性映射"><a href="#1-线性映射" class="headerlink" title="1. 线性映射"></a>1. 线性映射</h1><p><strong>线性映射（Linear Mapping）</strong>是指从线性空间V 到线性空间W的一个映射函数$f : V \to W$，并满足：对于$V$中任何两个向量$u$和$v$以及任何标量$c$，有<br>$$<br>\begin{eqnarray}<br>f(u+v) &amp;=&amp; f(u) + f(v), \tag{1.1} \\<br>f(cv) &amp;=&amp; cf(v). \tag{1.2}<br>\end{eqnarray}<br>$$</p><p>两个有限维欧式空间的映射函数$f: \mathbb{R}^n \to \mathbb{R}^m$可以表示为<br>$$<br>y = Ax \triangleq<br>\begin {bmatrix}<br>a_{11}x_1 + a_{12}x_2 + … + a_{1n}x_n \\<br>a_{21}x_1 + a_{22}x_2 + … + a_{2n}x_n \\<br>\vdots \\<br>a_{m1}x_1 + a_{m2}x_2 + … + a_{mn}x_n \\<br>\end {bmatrix}, \tag{1.3}<br>$$<br>其中$A$定义为$m × n$的<strong>矩阵（Matrix）</strong>，是一个由$m$行$n$列元素排列成的矩形阵列。一个矩阵A从左上角数起的第$i$行第$j$列上的元素称为第$i, j$项，通常记为$[A]_{ij}或 a _{ij}$。矩阵$A$定义了一个从$\mathbb{R}^n$ 到 $\mathbb{R}^m$ 的线性映射；向量 $x \in \mathbb{R}^n$ 和 $y \in \mathbb{R}^m$ 分别为两个空间中的<strong>列向量</strong>，即大小分别为$n \times 1$和$m \times 1$的矩阵。<br>$$<br>x =\begin {bmatrix}<br>x_1 \\<br>x_2 \\<br>\vdots \\<br>x_n \\<br>\end {bmatrix}, y = \begin {bmatrix}<br>y_1 \\<br>y_2 \\<br>\vdots \\<br>y_m \\<br>\end {bmatrix}, \tag{1.4}<br>$$<br>一般为方便起见，书籍中约定逗号隔离的向量表示$[x_1, x_2, … , x_n]$为行向量，列向量通常用分号隔开的表示$x =  [x_1; x_2; … ; x_n]$，或行向量的转置$[x_1, x_2, … , x_n]^T$。</p><h1 id="2-矩阵操作"><a href="#2-矩阵操作" class="headerlink" title="2. 矩阵操作"></a>2. 矩阵操作</h1><p><strong>加</strong> 如果$A$和$B$都为$m×n$的矩阵，则$A$和$B$的加也是$m×n$的矩阵，其每个元素是$A$和$B$相应元素相加。<br>$$<br>[A + B]_{ij} = a_{ij} + b_{ij} \tag{1.5}<br>$$</p><p><strong>乘积</strong> 假设有两个$A$和$B$分别表示两个线性映射$g : \mathbb{R}^m \to \mathbb{R}^k$ 和 $f: \mathbb{R}^n \to \mathbb{R}^m，则其复合线性映射为：<br>$$<br>(g \circ f)(x) = g(f(x)) = g(Bx) = A(Bx) = (AB)x, \tag{1.6}<br>$$<br>其中$AB$表示矩阵$A$和$B$的乘积，定义为<br>$$<br>[AB]_{ij} = \sum_{k=1}^na_{ik}b_{kj} \tag{1.7}<br>$$<br>两个矩阵的乘积仅当第一个矩阵的列数和第二个矩阵的行数相等时才能定义。如$A$是$k × m$矩阵和$B$是$m × n$矩阵，则乘积$AB$是一个$k × n$的矩阵。矩阵的乘法也满足结合律和分配律：</p><ul><li><p>结合律： $(AB)C = A(BC)$,</p></li><li><p>分配律： $(A + B)C = AC + BC，C(A + B) = CA + CB$.</p></li></ul><p><strong>Hadamard 积</strong> $A$和$B$的<em>Hadamard</em>积，也称为<em>逐点乘积</em>，为$A$和$B$中对应的元素相乘。<br>$$<br>[A \odot B]_{ij} = a_{ij}b_{ij} \tag{1.8}<br>$$<br>一个标量$c$与矩阵$A$乘积为$A$的每个元素是$A$的相应元素与$c$的乘积<br>$$<br>[cA]_{ij} = ca_{ij} \tag{1.9}<br>$$</p><p><strong>转置</strong> $m×n$矩阵$A$的<strong>转置（Transposition）</strong>是一个$n×m$的矩阵，记为$A^T$，$A^T$的第$i$行第$j$列的元素是原矩阵A的第$j$行第$i$列的元素<br>$$<br>[A^T]_{ij} = [A]_{ji} \tag{1.10}<br>$$<br><strong>向量化</strong> 矩阵的向量化是将矩阵表示为一个列向量。这里，<strong>vec</strong>是向量化算子。设$A = [a_{ij}]_{m×n}$，则<br>$$<br>vec(A) = [a_{11}, a_{21}, … , a_{m1}, a_{12}, a_{22}, … , a_{m2}, … , a_{1n}, a_{2n}, … , a_{mn}]^T \tag{1.11}<br>$$</p><p><strong>迹</strong> $n$ x $n$矩阵$A$的对角线元素之和称为它的<strong>迹（Trace）</strong>，记为tr(A)。尽管矩阵的乘法不满足交换律，但它们的迹相同，即tr(AB) = tr(BA)。</p><p><strong>行列式</strong> $n$ x $n$矩阵$A$的行列式是一个将其映射到标量的函数，通常记作$det(A)$或$|A|$。行列式可以看做是有向面积或体积的概念在欧氏空间中的推广。在$n$维欧氏空间中，行列式描述的是一个线性变换对“体积”所造成的影响。一个$n × n$的矩阵$A$的行列式定义为：<br>$$<br>det(A) = \sum_{\sigma \in S_n}(-1)^k\prod a_i,\sigma(i) \tag{1.12}<br>$$<br>解释一下，$S_n$是$\{1,2,…,n\}$的所有排列的集合，$\sigma$是其中一个排列，$\sigma(i)$是元素i在排列$\sigma$中的位置，k表示$\sigma$中的逆序对的数量。</p><p>其中逆序对的定义为：在排列$\sigma$中，如果有序数对$(i, j)$满足$1 \leq i &lt; j \leq n$但$\sigma(i) &gt; \sigma(j)$，则其为$\sigma$的一个逆序对。举个例子(左侧为排列， 右侧为逆序对数量)：<br>$$<br>eg：[4, 3, 1, 2, 5] \to 5<br>$$</p><p><strong>秩</strong> 一个矩阵$A$的列秩是$A$的线性无关的列向量数量，行秩是$A$的线性无关的行向量数量。一个矩阵的列秩和行秩总是相等的，简称为<strong>秩（Rank）</strong>。</p><p>一个$m × n$的矩阵$A$的秩最大为$min(m, n)$。若$rank(A) = min(m, n)$，则称矩阵为满秩的。如果一个矩阵不满秩，说明其包含线性相关的列向量或行向量，其行列式为0。两个矩阵的乘积$AB$的秩$rank(AB) \leq min(rank(A), rank(B))$。</p><p><strong>范数</strong> 在“线性代数1-向量和向量空间”中已经提及<br>$$<br>\ell_p(v) = \parallel v \parallel_p = {(\sum_{i=1}^{n}|v_i|^p)}^{1/p}, \tag{1.13}<br>$$</p><h1 id="3-矩阵类型"><a href="#3-矩阵类型" class="headerlink" title="3. 矩阵类型"></a>3. 矩阵类型</h1><p><strong>对称矩阵</strong> 对称矩阵（Symmetric Matrix）指其转置等于自己的矩阵，即满足$A = A^T$。</p><p><strong>对角矩阵</strong> 对角矩阵（Diagonal Matrix）是一个主对角线之外的元素皆为0 的矩阵。对角线上的元素可以为0 或其他值。一个$n × n$的对角矩阵$A$满足<br>$$<br>[A]_{ij} = 0 \qquad if \quad i\neq j \quad \forall i,j \in \{1, …, n\} \tag{1.14}<br>$$<br>对角矩阵A也可以记为diag(a)，a 为一个n维向量，并满足<br>$$<br>[A]_{ii} = a_i \tag{1.15}<br>$$</p><p>其中$n × n$的对角矩阵$A = diag(a)$和$n$维向量b的乘积为一个$n$维向量<br>$$<br>Ab = diag(a)b = a \odot b \tag{1.16}<br>$$<br>其中$\odot$表示点乘，即$(a \odot b)_i = a_ib_i$。</p><p><strong>单位矩阵</strong> 单位矩阵（Identity Matrix）是一种特殊的的对角矩阵，其主对角线元素为1，其余元素为0。$n$阶单位矩阵$I_n$，是一个$n × n$的方块矩阵。可以记为$I_n = diag(1, 1, …, 1)$。一个m × n的矩阵A和单位矩阵的乘积等于其本身。<br>$$<br>AI_n = I_mA = A \tag{1.17}<br>$$<br><strong>逆矩阵</strong> 对于一个$n × n$的方块矩阵$A$，如果存在另一个方块矩阵$B$使得<br>$$<br>AB = BA = I_n \tag{1.18}<br>$$<br>其中$I_n$为单位阵，则称$A$是可逆的。矩阵$B$称为矩阵A的逆矩阵（Inverse Matrix），记为$A^{−1}$。</p><blockquote><p>一个方阵的行列式等于0当且仅当该方阵不可逆时。</p></blockquote><p><strong>正定矩阵</strong> 对于一个$n×n$的对称矩阵$A$，如果对于所有的非零向量$x \in \mathbb{R}^n$都满足<br>$$<br>x^TAx &gt; 0 \tag{1.19}<br>$$<br>则$A$为<strong>正定矩阵（Positive-Definite Matrix）</strong>。如果$x^TAx \geq 0$，则$A$是<strong>半正定矩阵（Positive-Semidefinite Matrix）</strong>。</p><p><strong>正交矩阵</strong> 正交矩阵（Orthogonal Matrix）$A$为一个方块矩阵，其逆矩阵等于其转置矩阵。<br>$$<br>A^T = A^{-1} \tag{1.20}<br>$$<br>等价于$A^TA = AA^T = I_n$。</p><p><strong>Gram矩阵</strong> 向量空间中一组向量$v_1, v_2 , … , v_n$的Gram 矩阵（Gram Matrix）;G是内积的对称矩阵，其元素$G_{ij}$为${v_i}^T v_j$。</p><h1 id="4-特征值与特征矢量"><a href="#4-特征值与特征矢量" class="headerlink" title="4. 特征值与特征矢量"></a>4. 特征值与特征矢量</h1><p>如果一个标量$\lambda$和一个非零向量v满足<br>$$<br>Av = \lambda v \tag{1.21}<br>$$</p><p>则$\lambda$和$v$分别称为矩阵$A$的<strong>特征值（Eigenvalue）</strong>和<strong>特征向量（Eigenvector）</strong>。</p><h1 id="5-矩阵分解"><a href="#5-矩阵分解" class="headerlink" title="5. 矩阵分解"></a>5. 矩阵分解</h1><p>一个矩阵通常可以用一些比较“简单”的矩阵来表示，称为<strong>矩阵分解（Matrix Decomposition, Matrix Factorization）</strong>。</p><p><strong>奇异值分解</strong> 一个$m×n$的矩阵$A$的奇异值分解（Singular Value Decomposition，SVD）定义为<br>$$<br>A = U\sum V^T \tag{1.22}<br>$$<br>其中$U$和$V$分别为$m × m$和$n × n$的正交矩阵，$\sum$为$m × n$的对角矩阵，其对角线上的元素称为奇异值（Singular Value）。</p><p><strong>特征分解</strong> 一个$n × n$的方块矩阵$A$的特征分解（Eigendecomposition）定义为<br>$$<br>A = Q\Lambda Q^{-1} \tag{1.23}<br>$$<br>其中$Q$为$n×n$的方块矩阵，其每一列都为$A$的特征向量，Λ为对角阵，其每一个对角元素为$A$的特征值。<br>如果$A$为对称矩阵，则A可以被分解为<br>$$<br>A = Q\Lambda Q^T \tag{1.24}<br>$$<br>其中Q为正交阵。</p><p>主要参考 <a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;线性代数2，主要回顾关于矩阵的相关知识。错误之处，还望诸君不吝指教。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>线性代数1-向量和向量空间</title>
    <link href="https://buracagyang.github.io/2019/06/11/linear-algebra-1/"/>
    <id>https://buracagyang.github.io/2019/06/11/linear-algebra-1/</id>
    <published>2019-06-11T09:36:42.000Z</published>
    <updated>2019-08-07T06:32:47.756Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>后续几篇笔记主要想回顾整理一下需要用到的数学基础知识，主要包括了线性代数、微积分、概念论、数学优化和信息论等内容。相对比较基础，权当复习回顾完善整个知识体系结构。错误之处，还望诸君不吝指教。</p><a id="more"></a><h1 id="1-向量"><a href="#1-向量" class="headerlink" title="1. 向量"></a>1. 向量</h1><p><strong>标量（Scalar）</strong>是一个实数，只有大小，没有方向。而<strong>向量（Vector）</strong>是由一组实数组成的有序数组，同时具有大小和方向。例，一个n维<strong>向量a</strong> 是由n个有序实数组成，表示为：<br>$$<br>a = [a_1, a_2, …, a_n], \tag{1.1}<br>$$<br>其中$a_i$称为向量a的第$i$个分量，或第$i$维。向量符号通常用黑体小写字母$a, b, c$或小写希腊字母$\alpha,\beta, \gamma$ 等来表示。</p><h1 id="2-向量空间"><a href="#2-向量空间" class="headerlink" title="2. 向量空间"></a>2. 向量空间</h1><p><strong>向量空间（Vector Space）</strong>，也称<strong>线性空间（Linear Space）</strong>，是指由向量组成的集合，并满足以下两个条件：</p><ul><li><p>向量加法：向量空间$V$中的两个向量<strong>a</strong>和<strong>b</strong>，它们的和<strong>a + b</strong>也属于空间$V$；</p></li><li><p>标量乘法：向量空间$V$中的任一向量<strong>a</strong>和任一标量$c$，它们的乘积$c · a$也属于空间$V$。</p></li></ul><p><strong>欧氏空间</strong> 一个常用的线性空间是<strong>欧氏空间（Euclidean Space）</strong>。一个欧氏空间表示通常为$\mathbb{R}^n$，其中n为空间<strong>维度（Dimension）</strong>。欧氏空间中向量的加法和标量乘法定义为：<br>$$<br>\begin{eqnarray}<br>[a_1, a_2, … , a_n] + [b_1, b_2, … , b_n] &amp;=&amp; [a_1 + b_1, a_2 + b_2, … , a_n + b_n], \tag{1.2} \\<br>c[a_1, a_2, … , a_n] &amp;=&amp; [ca_1, ca_2, … , ca_n] \tag{1.3}<br>\end{eqnarray}<br>$$<br>其中$a, b, c \in{\mathbb{R}}$为一个标量。</p><p><strong>线性子空间</strong> 向量空间$V$的线性子空间$U$是$V$的一个子集，并且满足向量空间的条件（向量加法和标量乘法）。</p><p><strong>线性无关</strong> 线性空间$V$中的一组向量${v_1, v_2, … , v_n}$，如果对任意的一组标量$\lambda_1, \lambda_2, … , \lambda_n$，满足$\lambda_1v_1 + \lambda_2v_2 + ·… + \lambda_nv_n = 0$，则必然$\lambda_1 = \lambda_2 = … =\lambda_n = 0$，那么${v_1, v_2, … , v_n}$是线性无关的，也称为线性独立的。</p><p><strong>基向量</strong> 向量空间$V$的<strong>基（Base）</strong>$B = {e_1, e_2, … , e_n}$ 是$V$的有限子集，其元素之间线性无关。向量空间$V$所有的向量都可以按唯一的方式表达为$B$中向量的线性组合。对任意$v \in V$，存在一组标量$(\lambda_1, \lambda_2, … , \lambda_n)$ 使得:<br>$$<br>v = \lambda_1e_1 + \lambda_2e_2 + … + \lambda_ne_n \tag{1.4}<br>$$<br>其中基$B$中的向量称为基向量（Base Vector）。如果基向量是有序的，则标量$(\lambda_1, \lambda_2, … , \lambda_n)$ 称为向量$v$关于基$B$的<strong>坐标（Coordinates）</strong>。</p><p>n维空间$V$的一组<strong>标准基（Standard Basis）</strong>为:<br>$$<br>\begin{eqnarray}<br>e_1 &amp;=&amp; [1, 0, …, 0], \tag{1.5} \\<br>e_2 &amp;=&amp; [0, 1, …, 0], \tag{1.6} \\<br>&amp;…&amp;, \tag{1.7} \\<br>e_n &amp;=&amp; [0, 0, …, 1], \tag{1.8}<br>\end{eqnarray}<br>$$</p><p>向量空间$V$中的任一向量$v = [v_1, v_2, … , v_n]$可以唯一的表示为:<br>$$<br>[v_1, v_2, … , v_n] = v_1e_1 + v_2e_2 + … + v_ne_n, \tag{1.9}<br>$$<br>其中$v_1, v_2, … , v_n$也称为向量$v$的<strong>笛卡尔坐标（Cartesian Coordinate）</strong>。向量空间中的每个向量可以看作是一个线性空间中的笛卡儿坐标。</p><p>内积<strong> 一个n维线性空间中的两个向量$a$和$b$，其内积为:<br>$$<br>⟨a, b⟩ = \sum_{i=1}^{n}a_ib_i, \tag{1.10}<br>$$</strong>正交<strong> 如果向量空间中两个向量的内积为0，则它们</strong>正交（Orthogonal）**。如果向量空间中一个向量$v$与子空间$U$中的每个向量都正交，那么向量$v$和子空间$U$正交。</p><h1 id="3-常见的向量"><a href="#3-常见的向量" class="headerlink" title="3. 常见的向量"></a>3. 常见的向量</h1><p><strong>全0向量</strong>指所有元素都为0的向量，用<strong>0</strong>表示。全0向量为笛卡尔坐标系中的原点。</p><p><strong>全1向量</strong>指所有值为1的向量，用<strong>1</strong>表示。</p><p><strong>one-hot向量</strong>为有且只有一个元素为1，其余元素都为0 的向量。one-hot向量是在数字电路中的一种状态编码，指对任意给定的状态，状态寄存器中只有1位为1，其余位都为0。</p><h1 id="4-范数"><a href="#4-范数" class="headerlink" title="4. 范数"></a>4. 范数</h1><p><strong>范数（Norm）</strong>是一个表示向量“长度”的函数，为向量空间内的所有向量赋予非零的正长度或大小。对于一个n维向量<strong>v</strong>，一个常见的范数函数为$\ell_p$范数<br>$$<br>\ell_p(v) = \parallel v \parallel_p = {(\sum_{i=1}^{n}|v_i|^p)}^{1/p}, \tag{1.11}<br>$$<br>其中$p \geq 0$为一个标量的参数。常见的$p$的取值有1，2，$\infty$等。</p><p>$\ell_1$<strong>范数 </strong>， $p = 1$<br>$$<br>\ell_1(v) = \sum_{i=1}^{n}|v_i|, \tag{1.12}<br>$$<br>$\ell_2$<strong>范数 </strong>， $p = 2$<br>$$<br>\ell_2(v) = \sqrt{\sum_{i=1}^{n}|v_i|^2} = \sqrt{v^Tv}, \tag{1.13}<br>$$<br>$\ell_2$范数又称为<strong>Euclidean范数</strong>或者<strong>Frobenius范数</strong>。从几何角度，向量也可以表示为从原点出发的一个有向线段，其$\ell_2$范数为线段的长度，也常称为向量的模。</p><p>$\ell_{\infty}$<strong>范数 </strong>， $p = \infty$,表示为各个元素的最大绝对值<br>$$<br>\ell_{\infty}(v) = ||v||_{\infty} = max\{v_1,v_2, …, v_n\}, \tag{1.14}<br>$$</p><p>主要参考<a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">https://github.com/nndl/nndl.github.io</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;后续几篇笔记主要想回顾整理一下需要用到的数学基础知识，主要包括了线性代数、微积分、概念论、数学优化和信息论等内容。相对比较基础，权当复习回顾完善整个知识体系结构。错误之处，还望诸君不吝指教。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="基础知识" scheme="https://buracagyang.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>分位数回归简介</title>
    <link href="https://buracagyang.github.io/2019/06/03/quantile-regression/"/>
    <id>https://buracagyang.github.io/2019/06/03/quantile-regression/</id>
    <published>2019-06-03T06:24:43.000Z</published>
    <updated>2019-06-03T10:51:29.009Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>最近在做一个比较有意思(难搞…)的项目。大致介绍一下相关背景：根据历史的一个工作情况(历史表现，也就是有多少人做了多少工作量)，以及未来的一个预估工作量(预测值)，我们需要预估一个<strong>合理的</strong>人员投入;一言概之，根据历史表现和预测件量预估人员投入。</p><a id="more"></a><p><strong>时序问题？</strong><br>咋一看，这不就是一个时序问题嘛！人力投入如下：<br>$$<br>Y_t = f(T_t, S_t, C_t, I_t)<br>$$<br>其中$T_t$代表长期趋势特征，$S_t$代表季节性或者季节变动，$C_t$代表周期性或循环波动，$I_t$代表随机性或不规则波动。接下来获取特征和历史人员投入，这不就可以预估得到了未来人力投入嘛。</p><p>但是，我们再仔细考虑一下。事情还不仅仅是如此简单。原因有两点：</p><ul><li>与常见的销量、件量等的预测不同，人力的投入不仅仅是一个时序数据，内生的跟工作量强相关；</li><li>预估人员投入的一个很重要的目标是，求得一个合理的人员投入(范围)。</li></ul><p><strong>常规机器学习问题？</strong><br>或者，再稍微拓展一下，由于人员投入是跟工作量是强相关的，我们可不可以用机器学习的思路来解决这个问题。也即：<br>$$<br>Y_t = f(workload, other_features)<br>$$<br>其实也是存在问题的，在上述的有监督学习中，对于每一个instance我们是需要有一个监督值的。对于该场景下，貌似每个instance都存在一个人力投入值；但是我们的目标是需要预估一个<strong>合理的</strong>人力投入，如果单纯地去拟合当前的人力投入，岂不是认为目前的投入即是最优的了，既然如此就没有做这个任务的必要了。</p><p><strong>经济学模型和其他尝试</strong><br>我们也曾尝试从经典的柯布-道格拉斯生产函数形式、<a href="https://doi.org/10.1080/03610926.2014.1001495" target="_blank" rel="noopener">部分随机人力规划系统</a>以及<a href="https://doi.org/10.1016/j.simpat.2015.07.004" target="_blank" rel="noopener">基于强化学习</a>等的的一些思路进行过分析过，均因效果不甚理想或者业务场景不相符而被pass掉。</p><p>最后，考虑到我们的主要目标是预估一个<strong>合理的</strong>人力投入，我们引入了衡量工作质量的一个变量。通过综合考虑质量和效能的关系，以保证预估出的人员数量，在保证工作量的情况或者说在降低人力投入量后工作质量不至于太差，反之亦然。最后，我们用了一个比较简单的方法来解决这个事情 – 分位数回归（Quantile Regression, QR）。</p><p>在介绍分为数回归的知识点之前，需要简要说一下推导过程不然显得太过突兀：<br>定义工作量为$W$,业务指标准时完成量为$W1$,员工数量为$P$，显然，<br>$$<br> \frac{W1}{W} = \frac{W1}{P}\frac{P}{W}<br>$$<br>这里的$\frac{W1}{W}$用来衡量质量情况，$\frac{P}{W}$的倒数$\frac{W}{P}$用来衡量效能情况。我们可以认为，在同一个类型下(工作场景、工作时间)，实际工作效能$\frac{W1}{P}$是一个相对客观的不变的值，令其为$k$。接下来我们便可以用分位数回归的方法求得系数也即$k$值，然后根据需要的质量情况，得到最终的效能范围，再结合预测件量情况，即可得到一个较为合理的人员投入范围。</p><p>首先，我们知道随机变量X的分布函数为：<br>$$<br>F(x) = P(X\leq x)<br>$$<br>则随机变量X的$\tau$分位数的定义为：<br>$$<br>Q_\tau(X) = arginf\{x\in R ; F(x)\geq\tau\}(0&lt;\tau&lt;1)<br>$$<br>若将分布函数F(x)的逆定义为：<br>$$<br>F_X^{-1}(\tau) = inf\{y\in R ; F(y)\geq\tau\}<br>$$</p><p>故：<br>$$<br>Q_\tau(X) = F_X^{-1}(\tau)<br>$$<br>和传统的线性回归估计方法不同的是，分位数回归估计的是一组自变量X与因变量Y的分位数之间线性关系的建模方法，偏向于条件分位数的变化。故OLS在数据出现尖峰(异常值)、长尾分布或者显著异方差等情况时，OLS结果不稳定,但是分位数的估计量确相对稳健。</p><p>设随机向量(X, Y),其中Y在X=x的情况下的条件累积分布函数为$F_{Y|X=x}$(y|x)，则其$\tau$条件分位数定义为：<br>$$<br>Q_\tau(Y|X=x) = arginf\{y\in R ; F(y|x)\geq\tau\}(0&lt;\tau&lt;1)<br>$$</p><p>这里直接附上对于OLS和分位数回归的相关对比：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">OLS</th><th style="text-align:center">分位数回归估计</th></tr></thead><tbody><tr><td style="text-align:center">原理</td><td style="text-align:center">以平均数为基准，求解最短距离</td><td style="text-align:center">以不同的分位数为基准，求解最短距离</td></tr><tr><td style="text-align:center">前提条件</td><td style="text-align:center">独立、正态、同方差</td><td style="text-align:center">独立</td></tr><tr><td style="text-align:center">假设要求</td><td style="text-align:center">强假设</td><td style="text-align:center">弱假设</td></tr><tr><td style="text-align:center">求解方法</td><td style="text-align:center">OLS</td><td style="text-align:center">加权最小一乘估计</td></tr><tr><td style="text-align:center">检验类型</td><td style="text-align:center">参数检验</td><td style="text-align:center">非参数检验</td></tr><tr><td style="text-align:center">异方差</td><td style="text-align:center">影响大</td><td style="text-align:center">影响小</td></tr><tr><td style="text-align:center">拟合曲线</td><td style="text-align:center">一条拟合曲线</td><td style="text-align:center">一簇拟合曲线</td></tr></tbody></table><p><strong>分位数回归参数估计的思想</strong></p><hr><p>与线性回归不同的是，QR估计量的特点在于，是通过样本到回归曲线的垂直距离的加权和求得；其中权重设置为，在拟合曲线之下的样本权重为$1 - \tau$，拟合曲线之上的样本权重为$\tau$， 即：<br>$$<br>L(\theta) = \min_{\xi\subset{R}}\{\sum_{i:Y_i\ge\xi}\tau|Y_i - \xi| + \sum_{i:Y_i\le\xi}(1 - \tau)|Y_i - \xi|\}<br>$$</p><p>上式可等价为：<br>$$<br>L(\theta) = \min_{\xi\subset{R}}\sum_{i=1}^n\rho_\tau(Y_i - \xi)<br>$$<br>其中，$\rho_\tau(u)=u(\tau-I(u&lt;0))$, $I(Z)$为示性函数。</p><p>QR的损失函数$L(\theta)$不是对称的，是由两条从原点出发的分别位于第一和第二象限的射线组成，显然其斜率比为$\tau:1-\tau$。</p><p>以上，仅是关于分位数回归知识的大概简介，最主要的部分是关于损失函数的设计。</p><p>最后，应用到该项目中时，我们对原始数据进行了离散化的处理，以及经过斯皮尔曼检验后的数据进行训练。由于其是一个计算密集型的任务，应用到全国众多网点时(数万),可以开多个线程池进行并行处理。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;最近在做一个比较有意思(难搞…)的项目。大致介绍一下相关背景：根据历史的一个工作情况(历史表现，也就是有多少人做了多少工作量)，以及未来的一个预估工作量(预测值)，我们需要预估一个&lt;strong&gt;合理的&lt;/strong&gt;人员投入;一言概之，根据历史表现和预测件量预估人员投入。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>Logistic loss函数</title>
    <link href="https://buracagyang.github.io/2019/05/29/logistic-loss-function/"/>
    <id>https://buracagyang.github.io/2019/05/29/logistic-loss-function/</id>
    <published>2019-05-29T09:16:09.000Z</published>
    <updated>2019-06-03T10:51:02.378Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>前面在浏览sklearn中关于<a href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression" title="Logistic Regression" target="_blank" rel="noopener">Logistic Regression</a>部分，看到关于带正则项的LR目标损失函数的定义形式的时候，对具体表达式有点困惑，后查阅资料，将思路整理如下。</p><a id="more"></a><h1 id="1-sklearn文档中的LR损失函数"><a href="#1-sklearn文档中的LR损失函数" class="headerlink" title="1. sklearn文档中的LR损失函数"></a>1. sklearn文档中的LR损失函数</h1><p>先看sklearn对于LR目标损失函数(带L2)的定义：<br>$$<br>\min_{w, c} \frac{1}{2}w^T w + C \sum_{i=1}^n \log(\exp(- y_i (X_i^T w + c)) + 1)<br>$$</p><p>看到这个表达形式，其实是有两个疑问：</p><ul><li><p>logistic loss的表达形式</p></li><li><p>正则项的惩罚系数</p></li></ul><p>对于第二个问题，其实比较容易解释。通常我们在最小化结构风险时，会给我们的惩罚项乘上一个惩罚系数λ(通常1 &lt; λ &lt; 0)，<br>$$<br>\min_{w, λ} \sum_{i=1}^nloss(y, y_i) + λw^T w<br>$$<br>一般，为方便处理，做一个技巧性地处理，对多项式乘上一个正数 1/2λ, 得到：<br>$$<br>\min_{w, λ} \frac{1}{2λ}\sum_{i=1}^nloss(y, y_i) + \frac{1}{2}w^T w<br>$$<br>令C = 1/2λ即可。</p><p>但是对于第一个形式，当时比较困惑；特意翻看了一下我以前记录的关于<a href="https://blog.csdn.net/buracag_mc/article/details/77620686" title="LR损失函数" target="_blank" rel="noopener">LR以及LR损失函数</a>的一些笔记。</p><h1 id="2-LR损失函数"><a href="#2-LR损失函数" class="headerlink" title="2. LR损失函数"></a>2. LR损失函数</h1><p>为了方便说明笔者当时的疑惑所在，便将当时脑海里存在的logistic loss函数形式 和 sklearn中LR损失函数的推导方法分别记为旧思路和新思路吧。</p><h2 id="2-1-logistic基础知识"><a href="#2-1-logistic基础知识" class="headerlink" title="2.1 logistic基础知识"></a>2.1 logistic基础知识</h2><p>如指数分布、高斯分布等分布一样，logistic是一种变量的分布，它也有自己的概率分布函数和概率密度函数，其中概率分布函数如下：<br>$$<br>F(x) = P(X \leq x) = \frac{1}{1+e^{-(x-\mu)/\gamma}}<br>$$</p><p>对概率分布函数求导，记得到对应的概率密度函数：<br>$$<br>f(x) = \frac{e^{-(x- \mu)/ \gamma}}{\gamma(1+e^{-(x-\mu)/\gamma})^2}<br>$$</p><p>其中，$\mu$就是分布对应的均值，$\gamma$是对应的形状参数。</p><p>下文，为简介方便起见，将$-(x-\mu)/\gamma$ 替换为 $-x$,故记为：<br>$$<br>F(x) = \frac{1}{1+exp(-x)}<br>$$</p><p>对应示例图如下：<br><img src="/2019/05/29/logistic-loss-function/20170827141819860.png" alt="这里写图片描述"></p><p>logistic有一个很重要的性质是：<br>$$<br>F(-x) = \frac{1}{1+exp(x)} = \frac{1}{1+\frac{1}{exp(-x)}} =<br>\frac{exp(-x)}{1+exp(-x)}=1-\frac{1}{1+exp(-x)}=1-F(x)<br>$$</p><p>通常，应用到LR中，有如下形式：</p><blockquote><p><strong>(1)</strong><br>$$<br>P(Y=1|\beta,x) = \frac{1}{1+exp(-\beta x)} = \frac{e^{\beta x}}{1+e^{\beta x}}<br>$$<br>$$<br>P(Y=0|\beta,x) = 1 - \frac{1}{1+exp(-\beta x)} = \frac{1}{1+e^{\beta x}}<br>$$</p></blockquote><blockquote><p>一个事件的几率(odds)，定义为该事件发生与不发生的概率比值，若事件发生概率为p：</p></blockquote><p>$$<br>odds = \frac{p}{1-p}<br>$$</p><p>那么该事件的对数几率（log odds或者logit）如下：<br>$$<br>logit(p)=log\frac{p}{1−p}<br>$$</p><p>那么，对于上述二项，Y=1的对数几率就是：<br>$$<br>log \frac{P(Y=1|\beta,x)}{1−P(Y=1|\beta,x)}=log \frac{P(Y=1|\beta,x)}{P(Y=0|\beta,x)}=\beta x<br>$$</p><p>也就是说，输出Y=1的对数几率是由输入x的线性函数表示的模型，这就是逻辑回归模型。易知，当 $\beta x$的值越大，$P(Y=1|\beta,x)$越接近1；$\beta x$越小,$P(Y=1|\beta,x)$ 越接近0。</p><p>其实，LR就是一个线性分类的模型。与线性回归不同的是：LR将线性方程输出的很大范围的数压缩到了[0,1]区间上；更优雅地说：<strong>LR就是一个被logistic方程归一化后的线性回归</strong>。</p><h2 id="2-2-旧思路"><a href="#2-2-旧思路" class="headerlink" title="2.2 旧思路"></a>2.2 旧思路</h2><p>旧思路要从LR的参数求解过程说起。</p><p>我们知道统计学中一种很常用的方法是根据最大化似然函数的值来估计总体参数。在机器学习领域，我们听到的更多是损失函数的概念，常通过构建损失函数，然后最小化损失函数估计目标参数。在这里，<strong>最大化对数似然函数与最小化对数似然损失函数其实是等价的</strong>，下面我们可以看到。</p><ul><li><p>假设我们有n个独立的训练样本$\{(x_1,y_1),(x_2,y_2),(x_3,y_3),…,(x_n,y_n)\},y={0,1}$,那么每一个观察到的样本$(x_i,y_i)$出现的概率是：<br>$$<br>P(y_i,x_i) = P(y_i=1 | x_i)^{y_i}(1-P(y_i=1 | x_i))^{1-y_i}<br>$$<br>显然，$y_i$为1时，保留前半部分；$y_i$为0时，保留后半部分。</p></li><li><p>构建似然函数：<br>$$<br>L(\beta) = \prod P(y_i=1|x_i)^{y_i}(1-P(y_i=1|x_i))^{1-y_i}<br>$$</p></li><li><p>OK,对似然函数取对数，得到对数似然函数：</p></li></ul><p>$$LL(\beta) = log(L(\beta))= log(\prod P(y_i=1|x_i)^{y_i}(1-P(y_i=1|x_i))^{1-y_i}) $$</p><p> $= \sum_{i=1}^{n}(y_i log P(y_i=1|x_i) + (1-y_i)log(1-P(y_i=1|x_i)))$</p><p> $= \sum_{i=1}^{n}y_i log \frac{P(y_i=1|x_i)}{1-P(y_i=1|x_i)} + \sum_{i=1}^{n}log(1-P(y_i=1|x_i))$</p><p> $= \sum_{i=1}^{n}y_i(\beta x) + \sum_{i=1}^{n}logP(y_i=0|x_i)$</p><p> $= \sum_{i=1}^{n}y_i(\beta x) - \sum_{i=1}^{n}log(1+e^{\beta x})$</p><ul><li><p>用 $LL(\beta)$ 对 $\beta$ 求偏导，得：<br>$\frac{\partial LL(\beta)}{\partial \beta}<br>= \sum_{i=1}^{n}y_ix_i - \sum_{i=1}^{n} \frac{e^{\beta x_i}}{1+e^{\beta x_i}}.x_i$</p><p>$= \sum_{i=1}^{n}(y_i - P(y_i=1|x_i))x_i$<br>该式是无法解析求解，故会用到一些优化算法进行求解(梯度下降、牛顿法等)，这不是本文重点，便不再赘述。</p></li></ul><p>咋一看的确与sklearn中的形式差别有点大，所以请看新思路。</p><h2 id="2-3-新思路"><a href="#2-3-新思路" class="headerlink" title="2.3 新思路"></a>2.3 新思路</h2><p>在式(1)中， $x$表示特征向量，$\beta$表示相应的超参数，此时$y\in({0, 1})$表示样本对应的标签(label)。</p><p>这里，特别要讲的是另一种表达形式，将标签与预测函数在形式上统一了：</p><blockquote><p><strong>(2)</strong><br>$$<br>P(g=\pm1 |\beta, x) = \frac{1}{1+exp(-g\beta x)}<br>$$</p></blockquote><p>此时的样本标签$g\in({1, -1})$。</p><p>虽然式(1)与式(2)看起来似乎不同，但是我们可以有如下证明：<br>$$<br>P(Y=1|\beta,x) = \frac{e^{\beta x}}{1+e^{\beta x}} =  \frac{1}{1+exp(-\beta x)} = P(g=1 |\beta, x)<br>$$<br>同理，我们可以证明$P(Y=0|\beta,x)$ 和 $P(g=-1|\beta,x)$是等价的。</p><p>既然两种形式是等价的，为了适应更加广泛的分类loss最小化的框架，故采用第二种形式来表示LR.毕竟<strong>Simple is better than complex.</strong></p><p>首先定义$x_i$为特征向量，$y_i$为样本标签,则目标损失函数可以表示为：<br>$$<br>arg\min_{\beta}\sum_{i=1}L(y_i, f(x_i))<br>$$<br>其中，f是我们的回归方程，L是目标损失函数。</p><p>对应到LR中，我们有<br>$$<br>f(x) = \beta x<br>$$<br>$$<br>L(y, f(x)) = log(1 + exp(-yf(x)))<br>$$<br>如果将LR的第二种表达形式带入到损失函数L中，可得：<br>$$<br>L(y, f(x)) = log(1 + exp(-yf(x))) = log(\frac{1}{P(y|\beta,x)})<br>$$</p><p>再进一步：<br>$$<br>arg\min_{\beta}\sum_{i=1}L(y_i, f(x_i)) = arg\min_{\beta}\sum_{i=1}log(\frac{1}{P(y_i|\beta,x_i)})<br>$$<br>$$<br>= arg\max_{\beta}\sum_{i=1}log(P(y_i|\beta,x_i))= arg\max_{\beta}\prod_{i=1}P(y_i|\beta,x_i)<br>$$<br><strong>等式最后即为极大似然估计的表达形式。</strong></p><h1 id="3-思考"><a href="#3-思考" class="headerlink" title="3. 思考"></a>3. 思考</h1><p>其实到这儿，我们不难发现在旧思路中，推导极大化对数似然函数中的第二步：<br>$= \sum_{i=1}^{n}(y_i log P(y_i=1|x_i) + (1-y_i)log(1-P(y_i=1|x_i)))$</p><p>与新思路中的：<br>$$<br>=arg\max_{\beta}\sum_{i=1}log(P(y_i|\beta,x_i))<br>$$<br><strong>本质是统一的。</strong></p><p>最后</p><blockquote><p><strong>“Simple is better than complex.”   – The Zen of Python, by Tim Peters</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前面在浏览sklearn中关于&lt;a href=&quot;https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression&quot; title=&quot;Logistic Regression&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Logistic Regression&lt;/a&gt;部分，看到关于带正则项的LR目标损失函数的定义形式的时候，对具体表达式有点困惑，后查阅资料，将思路整理如下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
      <category term="机器学习" scheme="https://buracagyang.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Python中定义类的相关知识</title>
    <link href="https://buracagyang.github.io/2019/05/29/python-basic-about-class/"/>
    <id>https://buracagyang.github.io/2019/05/29/python-basic-about-class/</id>
    <published>2019-05-29T09:12:54.000Z</published>
    <updated>2019-06-03T10:51:24.181Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>主要介绍了在python中，抽象类的定义、多态的概念、类中属性的封装以及类中常见的修饰器。</p><a id="more"></a><h1 id="1-抽象类"><a href="#1-抽象类" class="headerlink" title="1. 抽象类"></a>1. 抽象类</h1><p>与Java一样，Python也有抽象类的概念，抽象类是一个特殊的类。其特殊之处在于</p><ul><li>只能被继承，不能被实例化；</li><li>子类必须完全覆写(实现)其“抽象方法”和“抽象属性”后才能被实例化。</li></ul><p>可以有两种实现方式: 利用NotImplementedError实现和利用abctractmethod实现</p><h2 id="1-1-NotImplementedError"><a href="#1-1-NotImplementedError" class="headerlink" title="1.1 NotImplementedError"></a>1.1 NotImplementedError</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#########################################</span></span><br><span class="line"><span class="comment"># 利用NotImplementedError</span></span><br><span class="line"><span class="comment">#########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Payment</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildPay</span><span class="params">(Payment)</span>:</span></span><br><span class="line">    <span class="comment"># 必须实现pay方法,否则报错NotImplementedError</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"TestPay pay"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">payed</span><span class="params">(self, money)</span>:</span></span><br><span class="line">print(<span class="string">"Payed: &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">child_pay = ChildPay()</span><br><span class="line">child_pay.payed(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><h2 id="1-2-abctractmethod"><a href="#1-2-abctractmethod" class="headerlink" title="1.2 abctractmethod"></a>1.2 abctractmethod</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABCMeta, abstractmethod</span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># abstractmethod</span></span><br><span class="line"><span class="comment"># 子类必须全部重写父类的abstractmethod方法</span></span><br><span class="line"><span class="comment"># 非abstractmethod方法可以不实现重写</span></span><br><span class="line"><span class="comment"># 带abstractmethod方法的类不能实例化</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Payment</span><span class="params">(metaclass=ABCMeta)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span></span></span><br><span class="line">self.name = name</span><br><span class="line"></span><br><span class="line"><span class="meta">@abstractmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"Payment get &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">total</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"Payment total &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildPay</span><span class="params">(Payment)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pay</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"ChildPay pay &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, money)</span>:</span></span><br><span class="line">        print(<span class="string">"ChildPay get &#123;&#125;"</span>.format(money))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">child_pay = ChildPay(<span class="string">"safly"</span>)</span><br><span class="line">child_pay.pay(<span class="number">100</span>)</span><br><span class="line">child_pay.get(<span class="number">200</span>)</span><br><span class="line">child_pay.total(<span class="number">400</span>)</span><br><span class="line"><span class="comment"># 不能实例化</span></span><br><span class="line"><span class="comment"># TypeError: Can't instantiate abstract class Payment</span></span><br><span class="line"><span class="comment"># with abstract methods get, pay</span></span><br><span class="line"><span class="comment"># a = Payment("safly")</span></span><br></pre></td></tr></table></figure><h1 id="2-多态概念"><a href="#2-多态概念" class="headerlink" title="2. 多态概念"></a>2. 多态概念</h1><p>向不同的对象发送同一条消息(obj.func(): 是调用了obj的方法func, 又称向obj发送了一条消息func)，不同的对象在接受时会产生不同的行为（即不同的处理方法）。</p><p>也就是说，每个对象可以用自己的方式去响应共同的消息。所谓消息，就是调用函数，不同的对象可以执行不同的函数。</p><p>例： 男生.放松了()， 女生.放松了()，男生是打篮球，女生是看综艺，虽然二者消息一样，但是处理方法不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABCMeta, abstractmethod</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">(metaclass=ABCMeta)</span>:</span></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relax</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Boy</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relax</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"playing basketball"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Girl</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relax</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"watching TV"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">boy = Boy()</span><br><span class="line">girl = Girl()</span><br><span class="line">boy.talk()  <span class="comment"># playing basketball</span></span><br><span class="line">girl.talk()  <span class="comment"># watching TV</span></span><br></pre></td></tr></table></figure><h1 id="3-属性封装"><a href="#3-属性封装" class="headerlink" title="3. __属性封装"></a>3. __属性封装</h1><h2 id="3-1-私有静态属性、私有方法"><a href="#3-1-私有静态属性、私有方法" class="headerlink" title="3.1 私有静态属性、私有方法"></a>3.1 私有静态属性、私有方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># __属性封装</span></span><br><span class="line"><span class="comment"># 私有静态属性、私有方法</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 私有静态属性</span></span><br><span class="line">    __kind = <span class="string">"private kind"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用私有静态属性</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_kind</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> Dog.__kind</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 私有方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__func"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用私有方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.__func()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"><span class="comment"># 如下调用错误,因为需要在类内调用</span></span><br><span class="line"><span class="comment"># print(Dog.__kind)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提倡如下调用方式</span></span><br><span class="line">d = Dog()</span><br><span class="line">print(d.get_kind())</span><br><span class="line">print(d.func())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不提倡如下调用方式</span></span><br><span class="line"><span class="comment"># d._Dog__func()</span></span><br><span class="line"><span class="comment"># print(Dog.__dict__)</span></span><br><span class="line"><span class="comment"># print(Dog._Dog__kind)</span></span><br><span class="line"><span class="comment"># print(Dog._Dog__func)</span></span><br></pre></td></tr></table></figure><h2 id="3-2-私有对象属性"><a href="#3-2-私有对象属性" class="headerlink" title="3.2 私有对象属性"></a>3.2 私有对象属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># 私有对象属性</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, weight)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__weight</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">room = Dog(<span class="string">"doggy"</span>, <span class="number">5</span>)</span><br><span class="line">print(room.name)  <span class="comment"># doggy</span></span><br><span class="line">print(room.get_weight())  <span class="comment"># 5</span></span><br><span class="line"><span class="comment"># 不能如下方法调用私有对象属性</span></span><br><span class="line"><span class="comment"># print(room.__weight)</span></span><br></pre></td></tr></table></figure><h2 id="3-3-私有属性不被继承"><a href="#3-3-私有属性不被继承" class="headerlink" title="3.3 私有属性不被继承"></a>3.3 私有属性不被继承</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2018/11/20 10:11</span></span><br><span class="line"><span class="comment"># @File     : test_interface.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"><span class="comment"># @Desc     :</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="comment"># 私有属性不能被继承</span></span><br><span class="line"><span class="comment"># #########################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogParent</span><span class="params">(object)</span>:</span></span><br><span class="line">__private = <span class="string">'PRIVATE'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.__name = name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__DogParent func"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogChild</span><span class="params">(DogParent)</span>:</span></span><br><span class="line">    <span class="comment"># 如下的方法是错误的</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_private</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> DogParent.__private</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">dog_parent = DogParent(<span class="string">"Tom"</span>)</span><br><span class="line">print(dir(dog_parent))</span><br><span class="line">print(<span class="string">"-------------"</span>)</span><br><span class="line">dog_child = DogChild(<span class="string">"Tommy"</span>)</span><br><span class="line">print(dir(dog_child))</span><br><span class="line"><span class="comment"># 调用报错AttributeError: type object 'DogChild' has no attribute '_DogChild__private'</span></span><br><span class="line"><span class="comment"># print(dog_child.get_private())</span></span><br></pre></td></tr></table></figure><h1 id="4-类中的常见修饰器"><a href="#4-类中的常见修饰器" class="headerlink" title="4. 类中的常见修饰器"></a>4. 类中的常见修饰器</h1><p>主要介绍最常见的装饰器，classmethod, staticmethod和property</p><h2 id="4-1-classmethod"><a href="#4-1-classmethod" class="headerlink" title="4.1 classmethod"></a>4.1 classmethod</h2><p>@classmethod<br>不需要self参数，但是classmethod方法的第一个参数是需要表示自身类的cls 参数；不管是从类本身调用还是从实例化后的对象调用，都用第一个参数把类传进来。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogParent</span><span class="params">(object)</span>:</span></span><br><span class="line">__private = <span class="string">'PRIVATE'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.__name = name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__DogParent func"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类方法</span></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(cls, new_name)</span>:</span></span><br><span class="line">cls.__name = new_name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls.__name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 普通方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_name2</span><span class="params">(self, new_name)</span>:</span></span><br><span class="line">        self.__name = new_name</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_name2</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">DogParent.change_name(DogParent, <span class="string">"Tom2"</span>)</span><br><span class="line">print(DogParent.get_name(DogParent))</span><br><span class="line"></span><br><span class="line">DogParent.change_name2(<span class="string">"Tom3"</span>)</span><br><span class="line">print(DogParent.get_name2())</span><br></pre></td></tr></table></figure></p><h2 id="4-2-staticmethod"><a href="#4-2-staticmethod" class="headerlink" title="4.2 staticmethod"></a>4.2 staticmethod</h2><p>staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用普通的函数一样;这样有一个好处：</p><ul><li>有利于我们代码的优雅，把某些应该属于某个类的函数给放到那个类里去，同时有利于命名空间的整洁</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogParent</span><span class="params">(object)</span>:</span></span><br><span class="line">__private = <span class="string">'PRIVATE'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.__name = name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__func</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"__DogParent func"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类方法</span></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(cls, new_name)</span>:</span></span><br><span class="line">cls.__name = new_name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls.__name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 普通方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_name2</span><span class="params">(self, new_name)</span>:</span></span><br><span class="line">        self.__name = new_name</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_name2</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 静态方法</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_nickname</span><span class="params">(nickname)</span>:</span></span><br><span class="line">print(<span class="string">"nickname: &#123;&#125;"</span>.format(nickname))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">DogParent.set_nickname(<span class="string">"tom's nickname~"</span>)</span><br></pre></td></tr></table></figure><h2 id="4-3-property"><a href="#4-3-property" class="headerlink" title="4.3 property"></a>4.3 property</h2><p>@property 把一个方法伪装成一个属性,这个属性的值，是这个方法的返回值；这个方法不能有参数，类不能调用，只能对象调用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, height, weight)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.height = height</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bmi</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.weight / (self.height ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"method"</span>)</span><br></pre></td></tr></table></figure></p><p>其实，property的作用不仅于此。简单点讲，@property的本质其实就是实现了get，set，delete三种方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, nickname)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.nickname = nickname</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nickname</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="comment"># 相当于实现了get方法</span></span><br><span class="line">        print(<span class="string">"nickname: &#123;&#125;"</span>.self.nickname)</span><br><span class="line"></span><br><span class="line"><span class="meta">@property.setter</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nickname</span><span class="params">(self, new_nickname)</span>:</span></span><br><span class="line"><span class="comment"># 相当于实现了set方法</span></span><br><span class="line">self.nickname = new_nickname</span><br><span class="line">print(<span class="string">"new nickname: &#123;&#125;"</span>.format(new_nickname))</span><br><span class="line"></span><br><span class="line"><span class="meta">@property.deleter</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nickname</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="comment"># 相当于实现了delete方法</span></span><br><span class="line"><span class="keyword">del</span> Person.nickname</span><br><span class="line">print(<span class="string">"deleted nickname"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">person = Person(<span class="string">"Tom"</span>, <span class="string">'tommmy'</span>)</span><br><span class="line"><span class="comment"># get</span></span><br><span class="line">person.nickname()</span><br><span class="line"></span><br><span class="line"><span class="comment"># setter </span></span><br><span class="line">person.nickname = <span class="string">'new_tommmy'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># deleter</span></span><br><span class="line"><span class="keyword">del</span> person.nickname</span><br><span class="line"></span><br><span class="line"><span class="comment">#删除完毕后,再次调用报如下错误</span></span><br><span class="line"><span class="comment"># AttributeError: type object 'person' has no attribute 'nickname'</span></span><br><span class="line"><span class="comment"># person.nickname</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;主要介绍了在python中，抽象类的定义、多态的概念、类中属性的封装以及类中常见的修饰器。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="Python" scheme="https://buracagyang.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>单层感知器为什么不能解决异或(XOR)问题</title>
    <link href="https://buracagyang.github.io/2019/05/29/single-layer-perceptron/"/>
    <id>https://buracagyang.github.io/2019/05/29/single-layer-perceptron/</id>
    <published>2019-05-29T09:05:20.000Z</published>
    <updated>2019-06-03T10:51:33.221Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>单层感知器为什么不能解决异或问题(XOR)问题？给出两个思路去考虑这个小问题~</p><a id="more"></a><p>最近翻到了自己在印象笔记中学习记录的一些知识点，后续准备系统地整理放在自己的博客上，还请各位不吝指教。</p><h1 id="1-感知器模型"><a href="#1-感知器模型" class="headerlink" title="1. 感知器模型"></a>1. 感知器模型</h1><ul><li><p>感知器模型是美国学者罗森勃拉特（Frank Rosenblatt）为研究大脑的存储、学习和认知过程而提出的一类具有自学习能力的神经网络模型，它把神经网络的研究从纯理论探讨引向了从工程上的实现。</p></li><li><p>Rosenblatt提出的感知器模型是一个只有单层计算单元的前向神经网络，称为单层感知器。</p></li></ul><h1 id="2-单层感知器模型算法概述"><a href="#2-单层感知器模型算法概述" class="headerlink" title="2. 单层感知器模型算法概述"></a>2. 单层感知器模型算法概述</h1><p>在学习基础的NN知识的时候，单个神经元的结构必定是最先提出来的，单层感知器模型算法与神经元结构类似；</p><p>大概思想是：首先把<strong>连接权</strong>和<strong>阈值</strong>初始化为较小的非零随机数，然后把有n个连接权值的输入送入网络，经加权运算处理，得到的输出如果与所期望的输出有较大的差别(对比神经元模型中的激活函数)，就对连接权值参数进行自动调整，经过多次反复，直到所得到的输出与所期望的输出间的差别满足要求为止。</p><p>如下为简单起见，仅考虑只有一个输出的简单情况。设$x_i(t)$是时刻$t$感知器的输入（i=1,2,……,n），$ω_i(t)$是相应的连接权值，$y(t)$是实际的输出，$d(t)$是所期望的输出，且感知器的输出或者为1，或者为0。</p><h1 id="3-线性不可分问题"><a href="#3-线性不可分问题" class="headerlink" title="3. 线性不可分问题 "></a>3. 线性不可分问题 </h1><p>单层感知器不能表达的问题被称为线性不可分问题。 1969年，明斯基证明了“异或”问题是线性不可分问题。</p><h1 id="4-“与”、”或”、”非”问题的证明"><a href="#4-“与”、”或”、”非”问题的证明" class="headerlink" title="4. “与”、”或”、”非”问题的证明"></a>4. “与”、”或”、”非”问题的证明</h1><ul><li>由于单层感知器的输出为：</li></ul><p>$$ y(x1,x2) = f(ω1 <em> x1 + ω2 </em> x2 - θ) $$</p><p>所以，用感知器实现简单逻辑运算的情况如下：</p><ul><li><p>“与”运算（And, x1∧x2）<br>令 ω1 = ω2 = 1，θ = 1.5，则: y = f(1 <em> x1 + 1 </em> x2 - 1.5)<br>显然，当x1和x2均为1时，y的值1；而当x1和x2有一个为0时，y的值就为0.</p></li><li><p>“或”运算（Or, x1∨x2）<br>令ω1 = ω2=1, θ = 0.5，则: y=f(1 <em> x1 + 1 </em> x2 - 0.5)<br>显然，只要x1和x2中有一个为1，则y的值就为1；只有当x1和x2都为0时，y的值才为0。</p></li><li><p>“非”运算（Not, ～X1）<br>令ω1 = -1， ω2 = O， θ = -0.5，则:   y = f((-1) <em> x1 + 1 </em> x2 + 0.5)<br>显然，无论x2为何值，x1为1时，y的值都为0；x1为0时，y的值为1。即y总等于～x1。</p></li><li><p>“异或”运算（x1 XOR x2）</p></li></ul><h1 id="5-“异或”问题的证明"><a href="#5-“异或”问题的证明" class="headerlink" title="5. “异或”问题的证明"></a>5. “异或”问题的证明</h1><h2 id="5-1-单层感知机不能解决”异或”问题证明方法一"><a href="#5-1-单层感知机不能解决”异或”问题证明方法一" class="headerlink" title="5.1 单层感知机不能解决”异或”问题证明方法一"></a>5.1 单层感知机不能解决”异或”问题证明方法一</h2><p>如果“异或”（XOR）问题能用单层感知器解决，则由XOR的真值映射关系如下：</p><table><thead><tr><th style="text-align:center">(x1, x2)</th><th style="text-align:center">y</th></tr></thead><tbody><tr><td style="text-align:center">(0, 0)</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">(0, 1)</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">(1, 0)</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">(1, 1)</td><td style="text-align:center">0</td></tr></tbody></table><p>则ω1、 ω2 和θ 必须满足如下方程组：<br>1). ω1 + ω2 - θ ＜ 0    –&gt;   θ &gt; ω1 + ω2<br>2). ω1 + 0 - θ ≥ 0      –&gt;   0 ≥ θ - ω1<br>3). 0 + 0 - θ ＜ 0      –&gt;   θ &gt; 0<br>4). 0 + ω2 - θ ≥ 0      –&gt;   0 ≥ θ - ω2<br>显然，该方程组是矛盾的，无解！这就说明单层感知器是无法解决异或问题的。</p><h2 id="5-2-单层感知机不能解决”异或”问题证明方法二"><a href="#5-2-单层感知机不能解决”异或”问题证明方法二" class="headerlink" title="5.2 单层感知机不能解决”异或”问题证明方法二"></a>5.2 单层感知机不能解决”异或”问题证明方法二</h2><p>首先需要证明以下定理：</p><blockquote><p>样本集线性可分的充分必要条件是正实例点集所构成的凸壳与负实例点集所构成的凸壳互不相交    </p></blockquote><ul><li><p>必要性：假设样本集T线性可分，则存在一个超平面W将数据集正实例点和负实例点完全正确地划分到超平面两侧。显然两侧的点分别构成的凸壳互不相交；</p></li><li><p>充分性：假设存在两个凸壳A、B相交，且存在超平面W将A和B线性分割，令A在B的凸壳内部的点为a，因为线性可交，则A中不存在两点之间的连线与超平面W相交，而凸壳B中任意一点与A中的点的连线均与超平面W相交，则B内部的点a也与A中任一点之间的连线不与W相交，与B壳中任一点与A中的点的连线均与超平面W相交矛盾。</p></li></ul><p><strong>故：只有正负实例点所构成的两个凸壳不相交时样本集才线性可分。</strong></p><p>显然，对于此例，负实例样本集[(0, 0), (1, 1)] 和 正实例样本集[(0, 1), (1, 0)]是二维中是不能被线性分割的。<br><img src="/2019/05/29/single-layer-perceptron/1.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;单层感知器为什么不能解决异或问题(XOR)问题？给出两个思路去考虑这个小问题~&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
  </entry>
  
  <entry>
    <title>AIC和BIC相关知识</title>
    <link href="https://buracagyang.github.io/2019/05/29/aic-and-bic/"/>
    <id>https://buracagyang.github.io/2019/05/29/aic-and-bic/</id>
    <published>2019-05-29T07:14:58.000Z</published>
    <updated>2019-07-28T08:55:35.276Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a></p><p>前面在回顾<a href="https://github.com/scikit-learn/scikit-learn" target="_blank" rel="noopener">sklearn</a>时，在广义线性模型中看到选择模型时可以采用AIC和BIC准则，特地复习了下统计学基础，简记如下，以抛砖引玉。</p><a id="more"></a><h2 id="1-模型拟合优度检验"><a href="#1-模型拟合优度检验" class="headerlink" title="1. 模型拟合优度检验"></a>1. 模型拟合优度检验</h2><p>最基础的一个模型拟合优度的检验量就是R square(方程的确定系数)。<br>已知一组样本观测值 $(X_i, Y_i)$,其中i=1,2,3,…,n得到如下样本回归方程：<br>$$<br>\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1}X_i<br>$$<br>而Y的第i个观测值与样本均值的离差 $y_i = Y_i - \bar{Y}$，其可以分解为两部分之和：<br>$$<br>y_i = Y_i - \bar{Y} = (Y_i - \hat{Y_i}) + (\hat{Y_i} - \bar{Y}) = e_i + \hat{y_i}<br>$$<br>其中 $\hat{y_i} = (\hat{Y_i} - \bar{Y})$是样本拟合值与观测值的平均值之差，可认为是由回归直线解释的部分，通常称之为”离差”；</p><p>$e_i = (Y_i - \hat{Y_i})$是实际观测值与回归拟合值之差，是回归直线不能解释的部分，通常称之为”残差”。</p><p>如果 $Y_i = \hat{Y_i}$,即实际观测值落在样本回归”线”上，则拟合最好。</p><p>对于所有样本点，<strong>可以证明</strong>：<br>$$<br>\sum{y_i}^2 = \sum{\hat{y_i}^2} + \sum{e_i^2} + 2\sum{\hat{y_i}^2e_i} = \sum{\hat{y_i}^2} + \sum{e_i^2}<br>$$<br>记:<br>$TSS = \sum{y_i^2} = \sum{(Y_i - \bar{Y})^2}$为总体平方和(Total Sum of Squares)<br>$ESS = \sum{\hat{y_i}^2} = \sum{(\hat{Y_i} - \bar{Y})^2}$为回归平方和(Explained Sum of Squares, <strong>注意有的教材又称之为Regression Sum of Squares</strong>)<br>$RSS = \sum{e_i^2} = \sum{(Y_i - \hat{Y_i})^2}$为残差平方和(Residual Sum of Squares, <strong>注意有的教材又称之为Error Sum of Squares</strong>)<br>$$<br>TSS = ESS + RSS<br>$$<br>所以Y的观测值围绕其均值的总离差(total variation)可分解为两部分：一部分来自回归线(ESS)，另一部分则来自与随机误差(RSS)</p><blockquote><p>在给定样本中，TSS不变，如果实际观测点离样本回归线越近，则ESS在TSS中占的比重越大，因此定义<strong>拟合优度：回归平方和ESS与TSS的比值。</strong></p></blockquote><p>记 $R^2 = \frac{ESS}{TSS} = 1 - \frac{RSS}{TSS}$，称 $R^2$为(样本)可决系数/判定系数</p><p>对于回归方程来说，$R^2$有以下几个意义：</p><ol><li>R square可以作为选择不同模型的标准。在拟合数据之前，不能确定数据的确定模型关系，可以对变量的不同数学形式进行拟合，再看R square的大小。</li><li>在数据的关系存在非线性可能情况下：<br>a) R squared越大不一定拟合越好；<br>b) 如何一个模型的R square很小，不一定代表数据之间没有关系，而很有可能是选择的模型不对，或者存在有其他的函数关系。</li><li><strong>当自变量个数增加时，尽管有的自变量与的线性关系不显著，其R square也会增大</strong>，对于这种情况需采用Adjusted R squared进行调整。</li></ol><h2 id="2-调整R-square"><a href="#2-调整R-square" class="headerlink" title="2. 调整R square"></a>2. 调整R square</h2><p>由于在模型中增加变量时，$R^2$没有下降，所以存在一种过度拟合模型的内在趋势，即向模型中增加变量固然可以改善数据拟合程度，但这样也会导致预测的方差正大，这时就需要用到调整 $R^2$。<br>$$<br>\bar{R_2} = 1 - \frac{n-1}{n-k}(1-R^2)<br>$$<br>调整$R^2$用作拟合优度的度量，它能够适当消除在模型中增加变量所导致的自由度损失。</p><p>调整 $R^2$对模型扩张时自由度的损失进行了弥补，但又存在一个问题，随着样本容量的增大，这种弥补是否足以保证该准则肯定能让分析者得到正确的模型，所以提出了另外两个拟合度量指标，一个是赤池信息准则(Akaike Information Criterion, AIC)，另一个是施瓦茨或贝叶斯信息准则(Bayesian Information Criterion,BIC)。</p><h2 id="3-AIC和BIC"><a href="#3-AIC和BIC" class="headerlink" title="3. AIC和BIC"></a>3. AIC和BIC</h2><p>$$<br>AIC(K) = s_y^2(1-R^2)e^{2k/n}<br>$$</p><p>$$<br>BIC(K) = s_y^2(1-R^2)n^{k/n}<br>$$</p><p>$s_y^2$中没有对自由度进行修正，虽然随着$R^2$的提高，这两个指标都有所改善(下降),但在其他条件不变的情况下，模型规模扩大又会使这两个指标恶化。与$\bar{R^2}$一样，实现同样的拟合程度，这些指标在平均每次观测使用参数个数(K/n)较少时更有效。使用对数通常更方便，多数统计软件报告度量指标是：<br>$$<br>AIC(K) = ln(\frac{e^{\prime}e}{n}) + \frac{2K}{n}<br>$$</p><p>$$<br>BIC(K) = ln(\frac{e^{\prime}e}{n}) + \frac{Kln{n}}{n}<br>$$</p><p><u><strong>更一般地：</strong></u><br>$$<br>AIC(K) = 2K - 2ln(L)<br>$$<br>其中k是模型参数个数，L为似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。</p><p>当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上市第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。</p><p>一般而言，当模型复杂度提高(k增大)时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。目标是选取AIC最小的模型，AIC不仅要提高模型拟合度(极大似然)，而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。<br>$$<br>BIC(K) = Kln{n} - 2ln(L)<br>$$<br>其中k是模型参数个数，n为样本数量，L为似然函数。与AIC类似地，引入了模型参数个数作为惩罚项，但是<strong>BIC的惩罚项比AIC的大</strong>，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高；其中 $kln{n}$惩罚项在维度过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前面在回顾&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sklearn&lt;/a&gt;时，在广义线性模型中看到选择模型时可以采用AIC和BIC准则，特地复习了下统计学基础，简记如下，以抛砖引玉。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>A/B-test显著性检验</title>
    <link href="https://buracagyang.github.io/2019/05/28/ab-test/"/>
    <id>https://buracagyang.github.io/2019/05/28/ab-test/</id>
    <published>2019-05-28T08:39:43.000Z</published>
    <updated>2019-08-01T07:27:45.658Z</updated>
    
    <content type="html"><![CDATA[<p>同步于<a href="https://blog.csdn.net/buracag_mc" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/" target="_blank" rel="noopener">音尘杂记</a>；</p><h1 id="1-A-B-test解读"><a href="#1-A-B-test解读" class="headerlink" title="1. A/B-test解读"></a>1. A/B-test解读</h1><p>A/B-test是为同一个目标制定两个方案，在同一时间维度，分别让组成成分相同（相似）的用户群组随机的使用一个方案，收集各群组的用户体验数据和业务数据，最后根据显著性检验分析评估出最好版本正式采用。</p><p>使用A/B-test首先需要建立一个待测试的版本服务，这个版本服务可能在标题、字体、排版、背景颜色、措辞等方面与原有版本服务有所不同，然后将这两个版本服务以随机的方式同时推送给测试用户。接下来分别统计两个版本的用户转化率指标，然后根据样本数据进行显著性检验。</p><a id="more"></a><h1 id="2-测试目的"><a href="#2-测试目的" class="headerlink" title="2. 测试目的"></a>2. 测试目的</h1><p>页面（版本）的某一特定更新对转化率指标（如UV-线索转化率、UV-上架转化率、UV-成交转化率或者线索-上架转化率等）的影响效果。</p><h1 id="3-A-B-test显著性检验"><a href="#3-A-B-test显著性检验" class="headerlink" title="3. A/B-test显著性检验"></a>3. A/B-test显著性检验</h1><p>随机将测试用户群分为2部分，用户群1使用A方案，用户群2使用B方案，经过一定测试时间后，根据收集到的两方案样本观测数据，根据显著性检验结果选取最好方案。</p><p>为了下文方便说明，我们不妨设A方案为参考方案（或旧方案），B方案为实验方案（或新方案）。以下我们以xx二手车的线索-车辆成交转化率为例（注：所有数据均属虚构，仅做示例说明之用），假设进行A/B-test的时间是一周。</p><h2 id="3-1-选择观测指标"><a href="#3-1-选择观测指标" class="headerlink" title="3.1 选择观测指标"></a>3.1 选择观测指标</h2><p>使用A方案的人数$N_A$，使用B方案的人数$N_B$，通常情况下$N_A = N_B = N$；由样本计算出A方案的线索-车辆成交转化率为$\hat{P}_a$，B方案的线索-车辆成交转化率 为$\hat{P}_b$；总体A的分布：$A \sim B(N, P_a)$，总体B的分布：$B \sim B(N, P_b)$；</p><p>根据中心极限定理可知，$\hat{P}_a$和$\hat{P}_b$均可认为近似服从正态分布：<br>$$<br>\begin{eqnarray}<br>\hat{P}_a \sim N(P_a, \hat{P}_a(1-\hat{P}_a) / N) \\<br>\hat{P}_b \sim N(P_b, \hat{P}_b(1-\hat{P}_b) / N)<br>\end{eqnarray} \tag{1.1}<br>$$</p><p>所以根据正态分布的性质：<br>$$<br>X = \hat{P}_b - \hat{P}_a \sim N(P_b-P_a, \hat{P}_b(1-\hat{P}_b) / N + \hat{P}_a(1-\hat{P}_a) / N) \tag{1.2}<br>$$</p><h2 id="3-2-建立原假设和备择假设"><a href="#3-2-建立原假设和备择假设" class="headerlink" title="3.2 建立原假设和备择假设"></a>3.2 建立原假设和备择假设</h2><p>由于我们的期望结果是B方案所带来的线索-车辆成交转化率高于A方案所带来的线索 -车辆成交转化率，所以原假设和备择假设如下：<br>$$<br>\begin{eqnarray}<br>H_0: X = P_b - P_a \leq 0 \\<br>H_1: X = P_b - P_a &gt; 0<br>\end{eqnarray} \tag{1.3}<br>$$</p><h2 id="3-3-构建检验统计量"><a href="#3-3-构建检验统计量" class="headerlink" title="3.3 构建检验统计量"></a>3.3 构建检验统计量</h2><p>检验统计量：<br>$$<br>Z = \frac{\hat{P}_b - \hat{P}_a}{\sqrt{\frac{\hat{P}_b(1-\hat{P}_b)}{N} + \frac{\hat{P}_a(1-\hat{P}_a)}{N}}} \tag{1.4}<br>$$</p><h2 id="3-4-显著性检验结论"><a href="#3-4-显著性检验结论" class="headerlink" title="3.4 显著性检验结论"></a>3.4 显著性检验结论</h2><p>给定显著性水平$\alpha$为。当$Z &gt; Z_{\alpha}$时，拒绝原假设，认为B方案所带来的线索-车辆成交转化率高于A方案所带来的线索-车辆成交转化率，建议可以进行推广；当$Z \leq Z_{\alpha}$时，不能拒绝原假设，即认为B方案所带来的线索-车辆成交转化率不高于A方案所带来的线索-车辆成交转化率，建议暂不建议进行推广。</p><h1 id="4-A-B-test示例"><a href="#4-A-B-test示例" class="headerlink" title="4. A/B-test示例"></a>4. A/B-test示例</h1><p>假设我们进行A/B-test一周，参考版本（通常默认是原始版本，简记为A）和实验版本（添加了特定改进的版本,简记为B），分别得到了1000个线索，A的线索-车辆成交转化率为7%，B的线索-车辆成交转化率为8%。如下表所示：</p><table><thead><tr><th>版本</th><th>总线索数</th><th>成交数(单位：辆)</th><th>转化率</th></tr></thead><tbody><tr><td>参考版本(A)</td><td>1,000</td><td>70</td><td>7.00%</td></tr><tr><td>实验版本(B)</td><td>1,000</td><td>80</td><td>8.00%</td></tr></tbody></table><p>在这儿，我们是肯定B比A版本所带来的转化率高呢，还是说这仅仅是由于一些随机的因素导致的这样的区别呢？我们严格按照A/B-test显著性检验过程进行如下计算。 </p><ul><li><p>选取测量指标：</p><p>$N_A = N_B = N = 1000$；其中$\hat{P}_a = 7%$，$\hat{P}_b = 8%$</p></li></ul><ul><li>构建原假设和备择假设：<br>$$<br>\begin{eqnarray}<br>H_0&amp;:&amp; B版本所带来的线索-车辆成交转化率不高于A版本，即X=P_b - P_a \leq 0 \\<br>H_1&amp;:&amp; B版本所带来的线索-车辆成交转化率高于A版本，即X=P_b - P_a &gt; 0<br>\end{eqnarray}<br>$$</li></ul><ul><li>构建检验统计量：<br>$$<br>Z = \frac{\hat{P}_b - \hat{P}_a}{\sqrt{\frac{\hat{P}_b(1-\hat{P}_b)}{N} + \frac{\hat{P}_a(1-\hat{P}_a)}{N}}}<br>$$<br>带入值，可以计算得到Z=0.849105726，</li></ul><ul><li><p>显著性检验结论：</p><p>如果取显著性水平$\alpha = 0.5$，则$Z_{\alpha} = 1.644854$，所以不能拒绝原假设，即认为B版本不一定比A版本所带来的线索-车辆成交转化率高。</p></li></ul><p>如果我们将A/B-test的时间拉长，如两周时长的A/B-test分别得到5000条线索量；或者说同样做一周时间的A/B-test，但是测试的比例更大，分别得到5000条线索量。即 N=5000，且线索-车辆成交转化率保持不变。计算得出$Z_{\alpha}=1.89865812$，在同样显著性水 平下，可以拒绝原假设，得出B比A版本所带来的线索-车辆成交转化率高的结论。</p><p>上述结论是符合我们的主观感受的。在小样本量时，新版所带来的线索-车辆成交转化率高于旧版本所带来的线索-车辆成交转化率，其原因也有可能是受到随机波动等因素影响，故不能肯定地说明新版要比旧版所带来的线索-车辆成交转化率高；但在大样本量时，或者说长期来看，新版本所带来的线索-车辆成交转化率都稳定地高于旧版本所带来的线索-车辆成交转化率，我们有理由相信，确实新版本所带来的线索-车辆成交转化率高于旧版本所带来的线索-车辆成交转化率。</p><h1 id="5-A-B-test样本量的确定"><a href="#5-A-B-test样本量的确定" class="headerlink" title="5. A/B-test样本量的确定"></a>5. A/B-test样本量的确定</h1><p>由上述示例可以看出，样本量的不同对于最终结果是有很大影响的。所以在进行抽样之 前的很重要一步是确定样本量；在实践中，样本量是应该在正式抽样进行A/B-test之前便确认的。放到这里讲的原因是为了通过上述示例加深我们对样本量重要性的认识。</p><p>实践中，我们对于样本量的确认，可以根据标准误（或者说我们需要检验的差异变化） 来求出，记标准误为$d$：<br>$$<br>d = Z_{\alpha} \times \hat{\sigma} \tag{1.5}<br>$$</p><p>其中$Z_{\alpha}$是在显著性水平$\alpha$下的临界值；$\hat{\sigma}$是由样本估计出的总体标准差。</p><p>显然，在给定显著性水平$\alpha$、需要检验的差异变化$d$和A版本（参考版本，旧版本）的线索-车辆成交转化率$\hat{P}_a$历史值（或经验值，或小样本预实验后得出的值[8]）后，即可推导得出我们进行A/B-test所需的样本量。</p><p>$$<br>N = \frac{Z_{\alpha}^2}{d^2}(\hat{P}_a(1-\hat{P}_a) + \hat{P}_b(1-\hat{P}_b)) \tag{1.6}<br>$$</p><h1 id="6-指标推广"><a href="#6-指标推广" class="headerlink" title="6. 指标推广"></a>6. 指标推广</h1><p>上文说明的是根据A/B-test进行新、旧版线索-车辆成交转化率的显著性检验。同理，如果需要根据A/B-test进行新、旧版本的UV-线索转化率、UV-上架转化率或者线索-上架转化率等的显著性检验，只需相应修改显著性检验过程中的观测指标($\hat{P}_a, \hat{P}_b$)即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;；&lt;/p&gt;
&lt;h1 id=&quot;1-A-B-test解读&quot;&gt;&lt;a href=&quot;#1-A-B-test解读&quot; class=&quot;headerlink&quot; title=&quot;1. A/B-test解读&quot;&gt;&lt;/a&gt;1. A/B-test解读&lt;/h1&gt;&lt;p&gt;A/B-test是为同一个目标制定两个方案，在同一时间维度，分别让组成成分相同（相似）的用户群组随机的使用一个方案，收集各群组的用户体验数据和业务数据，最后根据显著性检验分析评估出最好版本正式采用。&lt;/p&gt;
&lt;p&gt;使用A/B-test首先需要建立一个待测试的版本服务，这个版本服务可能在标题、字体、排版、背景颜色、措辞等方面与原有版本服务有所不同，然后将这两个版本服务以随机的方式同时推送给测试用户。接下来分别统计两个版本的用户转化率指标，然后根据样本数据进行显著性检验。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>SVM推导过程注解</title>
    <link href="https://buracagyang.github.io/2019/05/08/svm-proving-process/"/>
    <id>https://buracagyang.github.io/2019/05/08/svm-proving-process/</id>
    <published>2019-05-08T05:48:06.000Z</published>
    <updated>2019-07-30T09:29:41.531Z</updated>
    
    <content type="html"><![CDATA[<hr><p>同步于<a href="https://blog.csdn.net/buracag_mc/article/details/76762249" title="https://blog.csdn.net/buracag_mc/article/details/76762249" target="_blank" rel="noopener">CSDN</a>;<a href="https://www.runblog.online/2019/03/18/svm-process/" target="_blank" rel="noopener">音尘杂记</a></p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>支持向量机(Support Vector Machine)的原理其实比较简单，它是基于结构风险最小化理论之上在特征空间中建构最优分割超平面。在二维中就是线，在三维中就是面，但我们统称为超平面。</p><a id="more"></a><p>就我所看到的相关书本、论文以及网上博文情况来看，其一般步骤通常如下：</p><ul><li>在二维平面中的线性可分情况开始讲解，求解硬间隔最优化</li><li>随后放宽条件，这时可以引入松弛向量，然后求解软间隔最优化</li><li>再后面拓展到线性不可分的情况，这时引入核函数方法（kernel trick），将低维数据映射到高维特征空间，在高维特征空间中，这些训练样本便是线性可分的了。</li></ul><p>SVM在数据挖掘与统计机器学习的书中是必讲的，网上优秀的教程也很多；故这里我只是将某些一笔带过或者模棱两可的推导步骤结合自己学习过程做一些补充，错误与不尽之处还望大家不吝指教！欢迎大家使劲儿拍砖耶！</p><h1 id="求解硬间隔最优化时的相关注解"><a href="#求解硬间隔最优化时的相关注解" class="headerlink" title="求解硬间隔最优化时的相关注解"></a>求解硬间隔最优化时的相关注解</h1><ul><li><p>首先我们回忆一下初中所学的知识,两条平行线的方程分别为：<br>$ax + by = c1$<br>$ax + by = c2$           (1)<br>两条平行线的距离d为：<br>$ d = \frac{|c_1-c_2|}{\sqrt(a^2+b^2)} $ (2)</p></li><li><p>范数(norm)相关知识：<br>p-范数 $||X||_p = (|x_1|^p + |x_2|^p+…+ |x_n|^p)^{1/p}$;也即:</p><ul><li><p>1-范数 =$|x_1| + |x_2|+…+ |x_n|$</p></li><li><p>2-范数 =$ (|x_1|^2 + |x_2|^2 + …+|x_n|^2)^{1/2}$</p></li><li><p>$\infty-范数 = MAX(|x_1|, |x_2|, …, |x_n|)$</p></li></ul></li></ul><p>跟博文<a href="http://blog.csdn.net/buracag_mc/article/details/75159437" title="http://blog.csdn.net/buracag_mc/article/details/75159437" target="_blank" rel="noopener">http://blog.csdn.net/buracag_mc/article/details/75159437</a>中所讲的闵可夫斯基距离是否有些似曾相识；的确是这样的，p-范数确实满足范数的定义。其中三角不等式的证明不是平凡的，这个结论通常称为闵可夫斯基不等式。</p><p>其中2-范数简单记为||X||,也就是我们通常意义上所说的欧式距离！</p><p>先描述一下，假设我们有N个训练样本${(x_1, y_1),(x_1, y_1), …, (x_n, y_n)}$，x是2维向量，而$y_i \in {+1, -1}$是训练样本的标签，分别代表两个不同的类。这里我们需要用这些样本去训练学习一个线性分类器：$f(x)=sgn(w^Tx + b)$，sgn函数就是一个符号函数，也就是说$w^Tx+ b$大于0的时候，输出f(x) = 1，小于0的时候，f(x) = -1。而$w^Tx + b=0$就是我们要寻找的分类超平面，如下图所示：<br><img src="http://img.blog.csdn.net/20170806110734659?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>我们需要这个超平面分隔这两类的效果最好，也就是说让这个超平面到这两个类的最近的那个样本的距离相同且最大。为了更好的说明，找到两个和这个超平面平行和距离相等的超平面，其实在平面几何中我们知道这就是平行线的移动，OK,如果各移动m个单位就达到要求，即：</p><p>$H_1: y = w^Tx + b=m$<br>$H_2: y = w^Tx + b=-m$</p><p>形式是不跟教材中的不一样？没关系，这里我们只是需要方程两边同时除以一个m即可：</p><p>$H_1: y = (\frac{w}{m})^Tx + \frac{b}{m}=1$<br>$H_2: y = (\frac{w}{m})^Tx + \frac{b}{m}=-1$(4)</p><p>这里为了统一起见，我们令w = w/m, b=b/m，注意与前面所说的$w^Tx + b=0$中的w和b是有区别的。(其实对于$w^Tx + b=0$,我们可以进行同样处理$H_1: y = (\frac{w}{m})^Tx + \frac{b}{m}=\frac{0}{m}$,再令w=w/m, b=b/m,即可完全统一了)</p><p>在H1左侧的函数值大于1，所有其分类为+1；在H2右侧的函数值小于1，所有其分类为-1，<br>可以统一记为记为$y_i(W^T.x_i + b) \geq 1$<br>这样便是我们熟悉的形式了！</p><hr><p>下面大家便可以猜想到了，求$H_1$和$H_2$之间的最大距离。当然如果是在二维平面中(当然，这里是以二维特征来说的，当然就是二维平面了)，易知便是两条平行线之间的距离，根据前面所所述平行线的距离即可求出，这里我们称之为margin。<br>即：margin = 2/||W||<br>这里对于二维特征$W^T = (w_1,w_2)$，||W||便是参数W的二范数(有的教科书又称之“模”)，将上式展开表示我们熟悉的平行线的距离了$margin = \frac{2}{\sqrt(w_1^2 + w_2^2)}$</p><p>但是，在统计机器学习中，我们要让它符合更多一般的情况，美其名曰便是“泛化能力”。将特征空间拓展到多维的情况，便是用向量来进行表示了，故在多维特征空间中，我们同样求margin= 2/||W||。</p><p>要使margin最大，即需W最小，故我们设我们的目标函数：<br>$min \frac{1}{2}||W||^2$<br>$s.t. yi(W^Tx_i + b) \geq 1, \forall x_i$                                              (5)</p><p>很多人会纠结W前面的系数1/2，这里加不加1/2其实没关系，这是为了求导时消去。其实在机器学习中， 我们常见的平方损失函数便是进行了同样的处理，在前面加了个常数系数1/2。</p><p>对于(5)式，准确的讲这是一个带有不等式约束的条件极值问题，根据高等数学和基础运筹学内容可以知道，我们可以用<strong>拉格朗日方法求解</strong>。</p><p>这里我必须要补充的一点是：通过查阅教科书以及在阅读网上的优秀教程，我发现不同教科书和网上不同的教程都有不同的说法，虽然实质是不变的，但当时我遇到的坑必须给大家给填了。</p><p>首先带不等式约束的条件极值问题中会有大于号约束、小于号约束两种(这里我们暂且先不说带等号，下文将KKT条件的时候一并补充)</p><ul><li><p>第一种说法如下：将所有不等式约束条件<strong>统一为小于号约束</strong>，然后拉格朗日方程的构建规则是用约束方程乘以非负的拉格朗日系数，然后再<strong>加上</strong>目标函数即可。</p></li><li><p>第二种说法如下：将所有不等式约束条件<strong>统一为大于号约束</strong>，然后拉格朗日方程的构建规则是用约束方程乘以非负的拉格朗日系数，然后再从目标函数中<strong>减去</strong>即可。</p></li></ul><p>其实我们可以发现这两种说法是等价的！事实确实如此，但是很多博文在讲解拉格朗日函数的构建时要么说用目标函数加上约束方程乘以非负的拉格朗日系数，要么说用目标函数减去约束方程乘以非负的拉格朗日系数。</p><p>可能某些文章作者完全没有申明大前提，他们准确的说法应该是，<strong><em>当统一成小于号约束时，拉格朗日函数的构建时是用目标函数加上约束方程乘以非负的拉格朗日系数；当统一成大于号约束时，拉格朗日函数的构建时是用目标函数减去约束方程乘以非负的拉格朗日系数。</em></strong>在不提前申明不同的大前提下，可能会误导不细心以及课程学的不仔细的读者(当时包括我=_=！)，导致某些人纳闷了，咦，这个拉格朗日咋一会儿是加上约束约束乘以拉格朗日系数，一会儿又是减去约束方程乘以拉格朗日系数啊？？？</p><p>为了统一与方便说明起见，故下文我们运用的第一种规则，将不等式约束条件统一成小于号约束。于是得到拉格朗日方程如下：<br>$L(w,b,a) = \frac{1}{2}||W||^2 + \sum_{i=1}^{n}a_i(1-y_i(wx_i+b)) = \frac{1}{2}||W||^2 - \sum_{i=1}^{n}a_i(y_i(wx_i+b)) + \sum_{i=1}^{n}a_i $<br>(6)</p><p>拉格朗日函数构建好后接下来便是简单的求解问题了，分别对W和b求偏导数并令其为零，得到如下结果：<br>$W = \sum_{i=1}^{n}a_iy_ix_i$                                    (7)<br>$\sum_{i=1}^{n}a_iy_i = 0$                                                 (8)    </p><p>带入(6)式即可得到:<br>$Max.W(a) =\sum_{i=1}^{n}a_i - \frac{1}{2}\sum_{i=1,j=1}^{n}a_ia_jy_iy_jx_i^Tx_j$<br>$s.t. a_i \geq 0, \sum_{i=1}^{n}a_iy_i = 0$(9)</p><p>为什么$min \frac{1}{2}||W||^2$问题变成了<br>$Max.W(a) =\sum_{i=1}^{n}a_i - \frac{1}{2}\sum_{i=1,j=1}^{n}a_ia_jy_iy_jx_i^Tx_j$<br>当然是对偶问题的求解了！对偶问题是怎么推导过来的？很多文章仅仅只是一笔带过了这么重要的推导内容。。。导致很多人有些小困惑哈~，为什么构建拉格朗日函数后就将求最小化问题变成求最大化问题？OK，既然本文的定位是SVM推导过程中的解析及注解，必定是要把这个问题完整给推导清楚的。</p><h2 id="SVM中对偶问题的注解"><a href="#SVM中对偶问题的注解" class="headerlink" title="SVM中对偶问题的注解"></a>SVM中对偶问题的注解</h2><p>再回看(6)式，<br>$L(w,b,a) = \frac{1}{2}||W||^2 + \sum_{i=1}^{n}a_i(1-y_i(W^Tx_i+b)) = \frac{1}{2}||W||^2 - \sum_{i=1}^{n}a_i(y_i(W^Tx_i+b)) + \sum_{i=1}^{n}a_i $<br>$s.t. a_i \geq 0$</p><p>我们要处理的最优化问题最正确的表达形式其实为：<br>        <img src="http://img.blog.csdn.net/20170806113012070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">            (10)<br>上式才是严格带有不等式约束条件下的拉格朗日条件极值的表达式。我读的很多介绍SVM的文章(包括我看的书本)都是没说的！(10)式便是一个凸规划问题。</p><p>其意义是先对a求偏导，令其等于0消掉a，然后再对W和b求L的最小值。</p><p>要直接求解(10)式是有难度的，幸好这个问题可以通过拉格朗日对偶问题来解决。常说对偶问题对偶问题，现在就是真正发挥这把利器的时候了。对(10)式做一个简单的等价变换：<br>                        <img src="http://img.blog.csdn.net/20170806113254715?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">(11)</p><p><strong>上式即为对偶变换</strong>，这样就把这个凸规划问题转换成了对偶问题</p><p>其意义是：原凸规划问题可以转化为先对W和b求偏导，令两个偏导数都等于0消掉W和b，然后再对a求L的最大值。与(10)的意义是相反的，或者说是对偶的！不知我讲到这步，大家是否对对偶问题有了一个豁然开朗的感觉——啊！原来对偶问题就是这啊！！</p><p>然后将求得的(7)式和(8)式带入(6)式，得：<br>                            <img src="http://img.blog.csdn.net/20170806113534514?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">        (12)<br>将(12)式带入(11)式得：<br>                <img src="http://img.blog.csdn.net/20170806113608420?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">            (13)<br>再考虑到(8)式，对偶问题的完整表达为：<br><img src="http://img.blog.csdn.net/20170806113656054?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">                            (14)</p><p>到了这一步，我们便可以直接用数值方法计算求解拉格朗日乘数a了。求得a过后根据(7)式可以得到W，然后根据超平面方程可以求出b。最终便得到了我们想要的超平面和分类决策函数，也就是我们训练好的SVM分类器。那么对于待分类样本X，其分类为为：<br>                                      <img src="http://img.blog.csdn.net/20170806113836750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">    (15)</p><p>我们根据(15)式可以发现，对于一个待分类样本，我们先计算待分类样本和训练样本的内积然后加权就和再加上b值即可。训练样本特别大的情况下，如果对所有训练样本做运算是否太耗时了啊？很多教科书以及网上教程都是直接说根据KKT条件可知，只有支持向量的乘子(拉格朗日乘数)$a_i$不等于0，其他训练样本的乘子都为0，这样便会大大减少运算量，也是后面SVM引入核函数(kernel)的铺垫。这又会引起新的疑惑，为什么只有支持向量对应的乘子不为0呢？</p><h2 id="SVM中KKT条件注解"><a href="#SVM中KKT条件注解" class="headerlink" title="SVM中KKT条件注解"></a>SVM中KKT条件注解</h2><p>这里还是继续讨论一下带等式和不等式约束的条件极值问题。任何极值问题的约束条件不外乎3种：等式、大于号和小于号，为了统一起见，我们将不等式约束统一为小于号。<br>例如：<br>$min(max)    f(x) $<br>$s.t.     g_i(x) \leq0,i=1,2…n_1$<br>$     h_j(x) = 0,j=1,2…n_2$</p><p>那么一个极值优化问题我们转化为：<br><img src="http://img.blog.csdn.net/20170806114231142?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li>KKT条件就是函数的最优值必须满足以下条件：<ul><li>L对各个x的偏导为零</li><li>h(x) = 0</li><li>$\sum_{i=1}^{n_1}a_ig_i(x) =0 , a_i\geq0$</li></ul></li></ul><p>假设一个目标函数，3个不等式约束条件把自变量约束在一定范围，而目标函数是在这个范围内寻找最优解。<br><img src="http://img.blog.csdn.net/20170806114343592?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><p>1.函数开始也不知道该取哪一个值是吧，假设某一次取得自变量集合为x1*，发现不满足约束，然后再换呀换；</p></li><li><p>2.假设到x2<em>满足约束条件，但是这个时候函数值不是最优的，并且x2</em>使得g1(x)与g2(x)等于0了，而g3(x)还是小于0。这个时候，我们发现在x2*的基础上再寻找一组更优解要靠谁呢？当然是要靠约束条件g1(x)与g2(x)，因为他们等于0了，很极限呀，一不小心，走错了就不满足这两个约束的条件了，这个时候我们会选择g1(x)与g2(x)的梯度方向往下走，以寻找最优值解。</p></li><li><p>3.这个时候需不需要管约束条件g3(x)呢？正常来说管不管都可以，如果管，也取g3在x2<em>处的梯度的话，由于g3已经满足小于0的条件，这时候再取在x2</em>处的梯度，有可能更快得到结果，也有可能适得其反；如果不管g3，由于g1和g2已经在边缘了，只取g1和g2的梯度，是肯定会让目标函数接近解的；故我们这时候是不用考虑g3的；</p></li><li><p>4.再往下走，到了x3*处发现g2和g3等于0了，也就是说走到边了，而g1是满足约束小于0的，这时候我们重复上一步，取g2和g3的梯度方向作为变化方向，而不用管g1.</p></li><li><p>5.一直循环3(4)步，直到找到最优解。</p></li></ul><p>可以看到的是，如果如果g1、g2=0时，由于他们本身的条件是小于0的，我们是需要优化他们的，操作上便是乘以一个正常数a作为他们梯度增长的倍数(或者说学习效率)，那些暂且不需要考虑的约束，例如这里说的g3，我们可以乘以系数0，即在下一次的优化中是不用考虑这些约束的。综上所述的话：<br>$\sum_{i=1}^{n_1}a_ig_i(x) = 0, a_i\geq0$</p><p>如上，简单直观地说便是KKT条件中第三个式子的意义了。</p><p>回到SVM的推导上来，对于(6)式，我们知道其KKT条件中的第三个式子为:<br>$\sum_{i=1}^{n_1}a_i(1-y_i(W^T.x_i+b)) = 0$，</p><p>我们知道除了支持向量，对于其他训练样本有：</p><ul><li><p>$y_i(W^T.x_i + b) &gt; 1$ 也即$1 - y_i(W^T.x_i + b) &lt;0$根据前面所述的内容知道，其对应的乘子为0。</p></li><li><p>对于支持向量来说：$y_i(W^T.x_i + b) =1$ 也即$1 - y_i(W^T.x_i + b) =0$，其对应的乘子不为0。</p></li></ul><p>也就是说，新来的待分类样本只需与支持向量求内积即可，这便大大减少了计算量！这便是KKT条件在SVM关键推导中的应用。</p><p>这里我再补偿一下另外一种思路，其实本质还是KKT条件：<br>由于(5)式与(10)式等价，即：<br><img src="http://img.blog.csdn.net/20170806114946494?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYnVyYWNhZ19tYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述">        (16)</p><p>故要使(16)式成立，只有令$a_i(1-y_i(W^T.x_i+b)) = 0$成立，由此得到KKT的第三个条件：<br>$\sum_{i=1}^{n_1}a_i(1-y_i(W^T.x_i+b)) = 0$<br>同样可出结论：支持向量对应的乘子为正系数；如果一个样本不是支持向量，则其对应的乘子为0。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;同步于&lt;a href=&quot;https://blog.csdn.net/buracag_mc/article/details/76762249&quot; title=&quot;https://blog.csdn.net/buracag_mc/article/details/76762249&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;;&lt;a href=&quot;https://www.runblog.online/2019/03/18/svm-process/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;音尘杂记&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;支持向量机(Support Vector Machine)的原理其实比较简单，它是基于结构风险最小化理论之上在特征空间中建构最优分割超平面。在二维中就是线，在三维中就是面，但我们统称为超平面。&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法备忘" scheme="https://buracagyang.github.io/tags/%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
    
      <category term="技术备忘" scheme="https://buracagyang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/"/>
    
      <category term="统计学运用" scheme="https://buracagyang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E8%BF%90%E7%94%A8/"/>
    
  </entry>
  
</feed>
